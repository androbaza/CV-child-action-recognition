{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "iraqi-livestock",
   "metadata": {
    "id": "VcjSRFELVbNk",
    "tags": []
   },
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complex-allen",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bf8PpPXtVvmg",
    "outputId": "2c685a33-474b-4e71-8f98-c2533c66095e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
      "Cuda compilation tools, release 10.0, V10.0.130\n",
      "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "Copyright (C) 2017 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check nvcc version\n",
    "!nvcc -V\n",
    "# Check GCC version\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "consolidated-mystery",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5PAJ4ArzV5Ry",
    "outputId": "e48dbf61-fae0-431c-e964-04c7caaee4bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install some optional requirements\n",
    "# !pip install -r requirements/optional.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "psychological-scholar",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "No_zZAFpWC-a",
    "outputId": "1d425eea-d44e-434a-991c-01eb15abaab2",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0+cu110 True\n",
      "0.12.0\n",
      "11.0\n",
      "GCC 7.5\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMAction2 installation\n",
    "import mmaction\n",
    "print(mmaction.__version__)\n",
    "\n",
    "# Check MMCV installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/actrec/.local/lib/python3.6/site-packages/decord-0.5.3-py3.6-linux-x86_64.egg')\n",
    "import decord\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "veterinary-interest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/actrec/.virtualenvs/mmaction/mmaction2\n"
     ]
    }
   ],
   "source": [
    "# cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "golden-abraham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/actrec/DATA/.virtualenvs/mmaction/mmaction2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seven-origin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[34;42mcheckpoints\u001b[0m/           \u001b[01;32mLICENSE\u001b[0m*                \u001b[01;32mrequirements.txt\u001b[0m*\n",
      "\u001b[34;42mchildact-checkpoints\u001b[0m/  \u001b[34;42mmmaction\u001b[0m/               \u001b[01;32msetup.cfg\u001b[0m*\n",
      "\u001b[34;42mconfigs\u001b[0m/               \u001b[34;42mmmaction2.egg-info\u001b[0m/     \u001b[01;32msetup.py\u001b[0m*\n",
      "\u001b[34;42mdata\u001b[0m/                  \u001b[01;32mmmaction-adults.ipynb\u001b[0m*  \u001b[34;42mtests\u001b[0m/\n",
      "\u001b[34;42mdemo\u001b[0m/                  \u001b[01;32mmy-mmaction.ipynb\u001b[0m*      \u001b[34;42mtools\u001b[0m/\n",
      "\u001b[34;42mdocker\u001b[0m/                \u001b[01;32mREADME.md\u001b[0m*              \u001b[01;32muntitled.txt\u001b[0m*\n",
      "\u001b[34;42mdocs\u001b[0m/                  \u001b[01;32mREADME_zh-CN.md\u001b[0m*\n",
      "\u001b[34;42mdocs_zh_CN\u001b[0m/            \u001b[34;42mrequirements\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-sampling",
   "metadata": {},
   "source": [
    "# CSN no tranfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fourth-playback",
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/csn/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deluxe-absence",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlhu9byjjt-K",
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='ResNet3dCSN',\n",
      "        pretrained2d=False,\n",
      "        pretrained=\n",
      "        'https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r152_ig65m_20200807-771c4135.pth',\n",
      "        depth=152,\n",
      "        with_pool2=False,\n",
      "        bottleneck_mode='ir',\n",
      "        norm_eval=False,\n",
      "        zero_init_residual=False,\n",
      "        in_channels=2),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        num_classes=7,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "dataset_type = 'RawframeDataset'\n",
      "data_root = 'data/childact_rawframe/train/'\n",
      "data_root_val = 'data/childact_rawframe/val/'\n",
      "ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
      "ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
      "ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
      "img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
      "train_pipeline = [\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=10,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_train_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/train/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    val=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_val_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/val/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    test=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_test_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/test/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=10,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'))\n",
      "optimizer = dict(type='SGD', lr=0.000125, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    step=[32, 48],\n",
      "    warmup='linear',\n",
      "    warmup_ratio=0.1,\n",
      "    warmup_by_epoch=True,\n",
      "    warmup_iters=16)\n",
      "total_epochs = 100\n",
      "checkpoint_config = dict(interval=20)\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "log_config = dict(\n",
      "    interval=100,\n",
      "    hooks=[dict(type='TextLoggerHook'),\n",
      "           dict(type='TensorboardLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "work_dir = './childact-checkpoints/CSN-no-transfer'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "omnisource = False\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/CSN-no-transfer/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_rawframe/train/'\n",
    "cfg.data_root_val = 'data/childact_rawframe/val/'\n",
    "cfg.ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "\n",
    "# cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_rawframe/test/'\n",
    "\n",
    "# cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_rawframe/train/'\n",
    "\n",
    "# cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_rawframe/val/'\n",
    "\n",
    "cfg.data.test.modality = 'Flow'\n",
    "cfg.data.val.modality = 'Flow'\n",
    "cfg.data.train.modality = 'Flow'\n",
    "\n",
    "cfg.data.train.start_index = 0\n",
    "cfg.data.test.start_index = 0\n",
    "cfg.data.val.start_index = 0\n",
    "\n",
    "cfg.data.test.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.train.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.val.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "# cfg.load_from = 'checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/CSN-no-transfer'\n",
    "\n",
    "cfg.img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
    "\n",
    "\n",
    "cfg.val_pipeline = [\n",
    "    dict(\n",
    "        type='SampleFrames',\n",
    "        clip_len=32,\n",
    "        frame_interval=2,\n",
    "        num_clips=1,\n",
    "        test_mode=True),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "#     dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "#     dict(type='Flip', flip_ratio=0.5)\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=10, test_mode=True),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='RandomCrop', size=224),\n",
    "    dict(type='RandomResizedCrop'),\n",
    "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "#     dict(type='Flip', flip_ratio=0.5),\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
    "]\n",
    "\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.val.pipeline = cfg.val_pipeline\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "# cfg.data.videos_per_gpu = 24\n",
    "# cfg.optimizer.type = 'Adam'\n",
    "# cfg.optimizer.weight_decay=0.0001\n",
    "\n",
    "# cfg.optimizer_config.grad_clip=None\n",
    "# cfg.optimizer.lr = 0.01\n",
    "\n",
    "# cfg.lr_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(10, 1e-5),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "cfg.total_epochs = 100\n",
    "\n",
    "# cfg.momentum_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(0.85 / 0.95, 1),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 20\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.data.videos_per_gpu=8\n",
    "\n",
    "cfg.model.backbone.in_channels = 2\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interpreted-quilt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDBWkdDRk6oz",
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 08:07:16,744 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r152_ig65m_20200807-771c4135.pth\n",
      "2021-05-08 08:07:16,745 - mmaction - INFO - Use load_from_http loader\n",
      "2021-05-08 08:07:16,897 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for conv1.conv.weight: copying a param with shape torch.Size([64, 3, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 2, 3, 7, 7]).\n",
      "2021-05-08 08:07:16,976 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /media/actrec/DATA/.virtualenvs/mmaction/mmaction2/childact-checkpoints/CSN-no-transfer\n",
      "2021-05-08 08:07:16,977 - mmaction - INFO - workflow: [('train', 1)], max: 100 epochs\n",
      "2021-05-08 08:10:37,386 - mmaction - INFO - Epoch [1][100/132]\tlr: 1.777e-05, eta: 7:17:32, time: 2.004, data_time: 0.030, memory: 21787, top1_acc: 0.1562, top5_acc: 0.7050, loss_cls: 1.9500, loss: 1.9500, grad_norm: 7.9264\n",
      "2021-05-08 08:15:03,351 - mmaction - INFO - Epoch [2][100/132]\tlr: 2.480e-05, eta: 6:16:31, time: 2.038, data_time: 0.032, memory: 21787, top1_acc: 0.1675, top5_acc: 0.7400, loss_cls: 1.9350, loss: 1.9350, grad_norm: 8.4017\n",
      "2021-05-08 08:19:27,189 - mmaction - INFO - Epoch [3][100/132]\tlr: 3.184e-05, eta: 5:56:11, time: 2.019, data_time: 0.037, memory: 21787, top1_acc: 0.2437, top5_acc: 0.8187, loss_cls: 1.8812, loss: 1.8812, grad_norm: 9.9008\n",
      "2021-05-08 08:23:53,729 - mmaction - INFO - Epoch [4][100/132]\tlr: 3.887e-05, eta: 5:45:13, time: 2.027, data_time: 0.030, memory: 21787, top1_acc: 0.3425, top5_acc: 0.8812, loss_cls: 1.7964, loss: 1.7964, grad_norm: 11.4856\n",
      "2021-05-08 08:28:19,239 - mmaction - INFO - Epoch [5][100/132]\tlr: 4.590e-05, eta: 5:37:08, time: 2.017, data_time: 0.036, memory: 21787, top1_acc: 0.4500, top5_acc: 0.9387, loss_cls: 1.6297, loss: 1.6297, grad_norm: 12.2586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 15.2 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 08:29:30,214 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 08:29:30,215 - mmaction - INFO - \n",
      "top1_acc\t0.7063\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 08:29:30,216 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 08:29:30,218 - mmaction - INFO - \n",
      "mean_acc\t0.7063\n",
      "2021-05-08 08:29:32,233 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
      "2021-05-08 08:29:32,235 - mmaction - INFO - Best top1_acc is 0.7063 at 5 epoch.\n",
      "2021-05-08 08:29:32,236 - mmaction - INFO - Epoch(val) [5][132]\ttop1_acc: 0.7063, top5_acc: 1.0000, mean_class_accuracy: 0.7063\n",
      "2021-05-08 08:32:57,711 - mmaction - INFO - Epoch [6][100/132]\tlr: 5.293e-05, eta: 5:31:42, time: 2.055, data_time: 0.037, memory: 21787, top1_acc: 0.5613, top5_acc: 0.9525, loss_cls: 1.4477, loss: 1.4477, grad_norm: 13.0017\n",
      "2021-05-08 08:37:21,040 - mmaction - INFO - Epoch [7][100/132]\tlr: 5.996e-05, eta: 5:25:42, time: 2.004, data_time: 0.030, memory: 21787, top1_acc: 0.6075, top5_acc: 0.9587, loss_cls: 1.2658, loss: 1.2658, grad_norm: 14.3625\n",
      "2021-05-08 08:41:44,595 - mmaction - INFO - Epoch [8][100/132]\tlr: 6.699e-05, eta: 5:20:36, time: 2.015, data_time: 0.031, memory: 21787, top1_acc: 0.6225, top5_acc: 0.9525, loss_cls: 1.1236, loss: 1.1236, grad_norm: 16.0786\n",
      "2021-05-08 08:46:07,061 - mmaction - INFO - Epoch [9][100/132]\tlr: 7.402e-05, eta: 5:15:41, time: 2.003, data_time: 0.030, memory: 21787, top1_acc: 0.6525, top5_acc: 0.9587, loss_cls: 1.0052, loss: 1.0052, grad_norm: 18.0323\n",
      "2021-05-08 08:50:28,818 - mmaction - INFO - Epoch [10][100/132]\tlr: 8.105e-05, eta: 5:11:02, time: 1.999, data_time: 0.031, memory: 21787, top1_acc: 0.6887, top5_acc: 0.9575, loss_cls: 0.9300, loss: 0.9300, grad_norm: 17.9128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.8 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 08:51:38,717 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 08:51:38,718 - mmaction - INFO - \n",
      "top1_acc\t0.8095\n",
      "top5_acc\t0.9841\n",
      "2021-05-08 08:51:38,719 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 08:51:38,719 - mmaction - INFO - \n",
      "mean_acc\t0.8095\n",
      "2021-05-08 08:51:40,646 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_10.pth.\n",
      "2021-05-08 08:51:40,647 - mmaction - INFO - Best top1_acc is 0.8095 at 10 epoch.\n",
      "2021-05-08 08:51:40,648 - mmaction - INFO - Epoch(val) [10][132]\ttop1_acc: 0.8095, top5_acc: 0.9841, mean_class_accuracy: 0.8095\n",
      "2021-05-08 08:55:06,553 - mmaction - INFO - Epoch [11][100/132]\tlr: 8.809e-05, eta: 5:07:28, time: 2.059, data_time: 0.041, memory: 21787, top1_acc: 0.7050, top5_acc: 0.9675, loss_cls: 0.8715, loss: 0.8715, grad_norm: 18.8563\n",
      "2021-05-08 08:59:30,429 - mmaction - INFO - Epoch [12][100/132]\tlr: 9.512e-05, eta: 5:03:20, time: 2.012, data_time: 0.032, memory: 21787, top1_acc: 0.6825, top5_acc: 0.9675, loss_cls: 0.8789, loss: 0.8789, grad_norm: 20.3215\n",
      "2021-05-08 09:03:54,791 - mmaction - INFO - Epoch [13][100/132]\tlr: 1.021e-04, eta: 4:59:20, time: 2.013, data_time: 0.032, memory: 21787, top1_acc: 0.6875, top5_acc: 0.9587, loss_cls: 0.8572, loss: 0.8572, grad_norm: 18.7717\n",
      "2021-05-08 09:08:17,949 - mmaction - INFO - Epoch [14][100/132]\tlr: 1.092e-04, eta: 4:55:20, time: 2.004, data_time: 0.030, memory: 21787, top1_acc: 0.7150, top5_acc: 0.9650, loss_cls: 0.8144, loss: 0.8144, grad_norm: 19.3279\n",
      "2021-05-08 09:12:39,526 - mmaction - INFO - Epoch [15][100/132]\tlr: 1.162e-04, eta: 4:51:15, time: 1.987, data_time: 0.031, memory: 21787, top1_acc: 0.7037, top5_acc: 0.9725, loss_cls: 0.7702, loss: 0.7702, grad_norm: 20.9530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.7 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 09:13:48,515 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 09:13:48,517 - mmaction - INFO - \n",
      "top1_acc\t0.8413\n",
      "top5_acc\t0.9921\n",
      "2021-05-08 09:13:48,518 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 09:13:48,519 - mmaction - INFO - \n",
      "mean_acc\t0.8413\n",
      "2021-05-08 09:13:50,626 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_15.pth.\n",
      "2021-05-08 09:13:50,627 - mmaction - INFO - Best top1_acc is 0.8413 at 15 epoch.\n",
      "2021-05-08 09:13:50,628 - mmaction - INFO - Epoch(val) [15][132]\ttop1_acc: 0.8413, top5_acc: 0.9921, mean_class_accuracy: 0.8413\n",
      "2021-05-08 09:17:16,281 - mmaction - INFO - Epoch [16][100/132]\tlr: 1.232e-04, eta: 4:47:53, time: 2.056, data_time: 0.042, memory: 21787, top1_acc: 0.7137, top5_acc: 0.9663, loss_cls: 0.7664, loss: 0.7664, grad_norm: 19.2321\n",
      "2021-05-08 09:21:38,477 - mmaction - INFO - Epoch [17][100/132]\tlr: 1.250e-04, eta: 4:44:04, time: 2.002, data_time: 0.031, memory: 21787, top1_acc: 0.7175, top5_acc: 0.9712, loss_cls: 0.7523, loss: 0.7523, grad_norm: 22.3502\n",
      "2021-05-08 09:25:59,027 - mmaction - INFO - Epoch [18][100/132]\tlr: 1.250e-04, eta: 4:40:12, time: 1.987, data_time: 0.030, memory: 21787, top1_acc: 0.7312, top5_acc: 0.9738, loss_cls: 0.6983, loss: 0.6983, grad_norm: 19.0211\n",
      "2021-05-08 09:30:19,721 - mmaction - INFO - Epoch [19][100/132]\tlr: 1.250e-04, eta: 4:36:23, time: 1.988, data_time: 0.031, memory: 21787, top1_acc: 0.7338, top5_acc: 0.9700, loss_cls: 0.7172, loss: 0.7172, grad_norm: 21.8828\n",
      "2021-05-08 09:34:40,365 - mmaction - INFO - Epoch [20][100/132]\tlr: 1.250e-04, eta: 4:32:37, time: 1.989, data_time: 0.032, memory: 21787, top1_acc: 0.7300, top5_acc: 0.9712, loss_cls: 0.7239, loss: 0.7239, grad_norm: 20.6210\n",
      "2021-05-08 09:35:42,182 - mmaction - INFO - Saving checkpoint at 20 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 6.8 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 09:36:03,103 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 09:36:03,105 - mmaction - INFO - \n",
      "top1_acc\t0.8889\n",
      "top5_acc\t0.9921\n",
      "2021-05-08 09:36:03,106 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 09:36:03,107 - mmaction - INFO - \n",
      "mean_acc\t0.8889\n",
      "2021-05-08 09:36:05,308 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_20.pth.\n",
      "2021-05-08 09:36:05,309 - mmaction - INFO - Best top1_acc is 0.8889 at 20 epoch.\n",
      "2021-05-08 09:36:05,309 - mmaction - INFO - Epoch(val) [20][132]\ttop1_acc: 0.8889, top5_acc: 0.9921, mean_class_accuracy: 0.8889\n",
      "2021-05-08 09:39:33,771 - mmaction - INFO - Epoch [21][100/132]\tlr: 1.250e-04, eta: 4:29:31, time: 2.085, data_time: 0.034, memory: 21787, top1_acc: 0.7388, top5_acc: 0.9700, loss_cls: 0.7396, loss: 0.7396, grad_norm: 21.6458\n",
      "2021-05-08 09:44:00,076 - mmaction - INFO - Epoch [22][100/132]\tlr: 1.250e-04, eta: 4:26:08, time: 2.044, data_time: 0.035, memory: 21787, top1_acc: 0.7288, top5_acc: 0.9788, loss_cls: 0.6995, loss: 0.6995, grad_norm: 20.2555\n",
      "2021-05-08 09:48:22,575 - mmaction - INFO - Epoch [23][100/132]\tlr: 1.250e-04, eta: 4:22:32, time: 2.006, data_time: 0.033, memory: 21787, top1_acc: 0.7388, top5_acc: 0.9850, loss_cls: 0.6696, loss: 0.6696, grad_norm: 18.7628\n",
      "2021-05-08 09:52:47,320 - mmaction - INFO - Epoch [24][100/132]\tlr: 1.250e-04, eta: 4:18:58, time: 2.006, data_time: 0.030, memory: 21787, top1_acc: 0.7512, top5_acc: 0.9800, loss_cls: 0.7009, loss: 0.7009, grad_norm: 20.9417\n",
      "2021-05-08 09:57:10,766 - mmaction - INFO - Epoch [25][100/132]\tlr: 1.250e-04, eta: 4:15:27, time: 2.016, data_time: 0.031, memory: 21787, top1_acc: 0.7212, top5_acc: 0.9750, loss_cls: 0.7466, loss: 0.7466, grad_norm: 21.4970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.4 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 09:58:20,406 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 09:58:20,407 - mmaction - INFO - \n",
      "top1_acc\t0.9127\n",
      "top5_acc\t0.9921\n",
      "2021-05-08 09:58:20,408 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 09:58:20,408 - mmaction - INFO - \n",
      "mean_acc\t0.9127\n",
      "2021-05-08 09:58:22,588 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_25.pth.\n",
      "2021-05-08 09:58:22,590 - mmaction - INFO - Best top1_acc is 0.9127 at 25 epoch.\n",
      "2021-05-08 09:58:22,591 - mmaction - INFO - Epoch(val) [25][132]\ttop1_acc: 0.9127, top5_acc: 0.9921, mean_class_accuracy: 0.9127\n",
      "2021-05-08 10:01:46,704 - mmaction - INFO - Epoch [26][100/132]\tlr: 1.250e-04, eta: 4:12:05, time: 2.041, data_time: 0.031, memory: 21787, top1_acc: 0.7325, top5_acc: 0.9875, loss_cls: 0.6694, loss: 0.6694, grad_norm: 20.3484\n",
      "2021-05-08 10:06:08,021 - mmaction - INFO - Epoch [27][100/132]\tlr: 1.250e-04, eta: 4:08:28, time: 1.990, data_time: 0.032, memory: 21787, top1_acc: 0.7675, top5_acc: 0.9888, loss_cls: 0.5787, loss: 0.5787, grad_norm: 18.7692\n",
      "2021-05-08 10:10:30,162 - mmaction - INFO - Epoch [28][100/132]\tlr: 1.250e-04, eta: 4:04:56, time: 2.002, data_time: 0.031, memory: 21787, top1_acc: 0.7525, top5_acc: 0.9788, loss_cls: 0.6537, loss: 0.6537, grad_norm: 19.2181\n",
      "2021-05-08 10:14:51,453 - mmaction - INFO - Epoch [29][100/132]\tlr: 1.250e-04, eta: 4:01:21, time: 1.988, data_time: 0.031, memory: 21787, top1_acc: 0.7500, top5_acc: 0.9750, loss_cls: 0.6721, loss: 0.6721, grad_norm: 17.5892\n",
      "2021-05-08 10:19:13,208 - mmaction - INFO - Epoch [30][100/132]\tlr: 1.250e-04, eta: 3:57:50, time: 1.999, data_time: 0.030, memory: 21787, top1_acc: 0.7575, top5_acc: 0.9788, loss_cls: 0.6546, loss: 0.6546, grad_norm: 19.2377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.1 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 10:20:23,888 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 10:20:23,890 - mmaction - INFO - \n",
      "top1_acc\t0.8968\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 10:20:23,891 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 10:20:23,892 - mmaction - INFO - \n",
      "mean_acc\t0.8968\n",
      "2021-05-08 10:20:23,893 - mmaction - INFO - Epoch(val) [30][132]\ttop1_acc: 0.8968, top5_acc: 1.0000, mean_class_accuracy: 0.8968\n",
      "2021-05-08 10:23:43,983 - mmaction - INFO - Epoch [31][100/132]\tlr: 1.250e-04, eta: 3:54:19, time: 2.001, data_time: 0.032, memory: 21787, top1_acc: 0.7612, top5_acc: 0.9875, loss_cls: 0.6360, loss: 0.6360, grad_norm: 18.3479\n",
      "2021-05-08 10:28:08,090 - mmaction - INFO - Epoch [32][100/132]\tlr: 1.250e-04, eta: 3:50:52, time: 2.012, data_time: 0.032, memory: 21787, top1_acc: 0.7588, top5_acc: 0.9862, loss_cls: 0.6019, loss: 0.6019, grad_norm: 20.0158\n",
      "2021-05-08 10:32:32,543 - mmaction - INFO - Epoch [33][100/132]\tlr: 1.250e-05, eta: 3:47:25, time: 2.007, data_time: 0.030, memory: 21787, top1_acc: 0.7800, top5_acc: 0.9788, loss_cls: 0.5900, loss: 0.5900, grad_norm: 18.1371\n",
      "2021-05-08 10:36:56,815 - mmaction - INFO - Epoch [34][100/132]\tlr: 1.250e-05, eta: 3:43:57, time: 2.003, data_time: 0.031, memory: 21787, top1_acc: 0.7775, top5_acc: 0.9775, loss_cls: 0.5884, loss: 0.5884, grad_norm: 16.8042\n",
      "2021-05-08 10:41:19,959 - mmaction - INFO - Epoch [35][100/132]\tlr: 1.250e-05, eta: 3:40:29, time: 2.006, data_time: 0.030, memory: 21787, top1_acc: 0.7987, top5_acc: 0.9912, loss_cls: 0.5532, loss: 0.5532, grad_norm: 16.9086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.5 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 10:42:30,144 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 10:42:30,145 - mmaction - INFO - \n",
      "top1_acc\t0.9286\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 10:42:30,146 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 10:42:30,147 - mmaction - INFO - \n",
      "mean_acc\t0.9286\n",
      "2021-05-08 10:42:32,129 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_35.pth.\n",
      "2021-05-08 10:42:32,130 - mmaction - INFO - Best top1_acc is 0.9286 at 35 epoch.\n",
      "2021-05-08 10:42:32,131 - mmaction - INFO - Epoch(val) [35][132]\ttop1_acc: 0.9286, top5_acc: 1.0000, mean_class_accuracy: 0.9286\n",
      "2021-05-08 10:45:51,603 - mmaction - INFO - Epoch [36][100/132]\tlr: 1.250e-05, eta: 3:37:01, time: 1.995, data_time: 0.031, memory: 21787, top1_acc: 0.7925, top5_acc: 0.9825, loss_cls: 0.5527, loss: 0.5527, grad_norm: 15.7720\n",
      "2021-05-08 10:50:12,125 - mmaction - INFO - Epoch [37][100/132]\tlr: 1.250e-05, eta: 3:33:31, time: 1.987, data_time: 0.030, memory: 21787, top1_acc: 0.7913, top5_acc: 0.9900, loss_cls: 0.5237, loss: 0.5237, grad_norm: 16.8484\n",
      "2021-05-08 10:54:32,741 - mmaction - INFO - Epoch [38][100/132]\tlr: 1.250e-05, eta: 3:30:02, time: 1.989, data_time: 0.032, memory: 21787, top1_acc: 0.7738, top5_acc: 0.9862, loss_cls: 0.5750, loss: 0.5750, grad_norm: 18.2931\n",
      "2021-05-08 10:58:53,591 - mmaction - INFO - Epoch [39][100/132]\tlr: 1.250e-05, eta: 3:26:35, time: 1.991, data_time: 0.030, memory: 21787, top1_acc: 0.7775, top5_acc: 0.9875, loss_cls: 0.5701, loss: 0.5701, grad_norm: 18.2165\n",
      "2021-05-08 11:03:16,131 - mmaction - INFO - Epoch [40][100/132]\tlr: 1.250e-05, eta: 3:23:09, time: 2.001, data_time: 0.031, memory: 21787, top1_acc: 0.8050, top5_acc: 0.9950, loss_cls: 0.5112, loss: 0.5112, grad_norm: 15.4825\n",
      "2021-05-08 11:04:18,248 - mmaction - INFO - Saving checkpoint at 40 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 16.9 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 11:04:28,061 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 11:04:28,063 - mmaction - INFO - \n",
      "top1_acc\t0.9206\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 11:04:28,064 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 11:04:28,065 - mmaction - INFO - \n",
      "mean_acc\t0.9206\n",
      "2021-05-08 11:04:28,066 - mmaction - INFO - Epoch(val) [40][132]\ttop1_acc: 0.9206, top5_acc: 1.0000, mean_class_accuracy: 0.9206\n",
      "2021-05-08 11:07:47,456 - mmaction - INFO - Epoch [41][100/132]\tlr: 1.250e-05, eta: 3:19:42, time: 1.994, data_time: 0.032, memory: 21787, top1_acc: 0.7850, top5_acc: 0.9850, loss_cls: 0.5759, loss: 0.5759, grad_norm: 17.9134\n",
      "2021-05-08 11:12:13,724 - mmaction - INFO - Epoch [42][100/132]\tlr: 1.250e-05, eta: 3:16:22, time: 2.035, data_time: 0.032, memory: 21787, top1_acc: 0.8037, top5_acc: 0.9888, loss_cls: 0.5315, loss: 0.5315, grad_norm: 17.7313\n",
      "2021-05-08 11:16:37,625 - mmaction - INFO - Epoch [43][100/132]\tlr: 1.250e-05, eta: 3:12:57, time: 2.009, data_time: 0.033, memory: 21787, top1_acc: 0.8075, top5_acc: 0.9862, loss_cls: 0.5297, loss: 0.5297, grad_norm: 17.4714\n",
      "2021-05-08 11:21:01,916 - mmaction - INFO - Epoch [44][100/132]\tlr: 1.250e-05, eta: 3:09:35, time: 2.020, data_time: 0.031, memory: 21787, top1_acc: 0.7925, top5_acc: 0.9888, loss_cls: 0.5287, loss: 0.5287, grad_norm: 18.0413\n",
      "2021-05-08 11:25:24,828 - mmaction - INFO - Epoch [45][100/132]\tlr: 1.250e-05, eta: 3:06:08, time: 1.988, data_time: 0.031, memory: 21787, top1_acc: 0.7950, top5_acc: 0.9825, loss_cls: 0.5305, loss: 0.5305, grad_norm: 17.1715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.5 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 11:26:35,208 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 11:26:35,210 - mmaction - INFO - \n",
      "top1_acc\t0.9286\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 11:26:35,210 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 11:26:35,212 - mmaction - INFO - \n",
      "mean_acc\t0.9286\n",
      "2021-05-08 11:26:35,213 - mmaction - INFO - Epoch(val) [45][132]\ttop1_acc: 0.9286, top5_acc: 1.0000, mean_class_accuracy: 0.9286\n",
      "2021-05-08 11:29:55,422 - mmaction - INFO - Epoch [46][100/132]\tlr: 1.250e-05, eta: 3:02:44, time: 2.002, data_time: 0.033, memory: 21787, top1_acc: 0.8013, top5_acc: 0.9862, loss_cls: 0.5397, loss: 0.5397, grad_norm: 18.0021\n",
      "2021-05-08 11:34:17,349 - mmaction - INFO - Epoch [47][100/132]\tlr: 1.250e-05, eta: 2:59:18, time: 1.988, data_time: 0.031, memory: 21787, top1_acc: 0.8013, top5_acc: 0.9850, loss_cls: 0.5181, loss: 0.5181, grad_norm: 17.5404\n",
      "2021-05-08 11:38:37,981 - mmaction - INFO - Epoch [48][100/132]\tlr: 1.250e-05, eta: 2:55:52, time: 1.988, data_time: 0.031, memory: 21787, top1_acc: 0.8025, top5_acc: 0.9912, loss_cls: 0.5194, loss: 0.5194, grad_norm: 18.1732\n",
      "2021-05-08 11:42:58,706 - mmaction - INFO - Epoch [49][100/132]\tlr: 1.250e-06, eta: 2:52:27, time: 1.989, data_time: 0.031, memory: 21787, top1_acc: 0.7750, top5_acc: 0.9925, loss_cls: 0.5591, loss: 0.5591, grad_norm: 17.4712\n",
      "2021-05-08 11:47:19,373 - mmaction - INFO - Epoch [50][100/132]\tlr: 1.250e-06, eta: 2:49:02, time: 1.989, data_time: 0.031, memory: 21787, top1_acc: 0.7775, top5_acc: 0.9838, loss_cls: 0.5735, loss: 0.5735, grad_norm: 18.5203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.7 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 11:48:28,349 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 11:48:28,352 - mmaction - INFO - \n",
      "top1_acc\t0.9365\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 11:48:28,353 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 11:48:28,355 - mmaction - INFO - \n",
      "mean_acc\t0.9365\n",
      "2021-05-08 11:48:30,568 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_50.pth.\n",
      "2021-05-08 11:48:30,569 - mmaction - INFO - Best top1_acc is 0.9365 at 50 epoch.\n",
      "2021-05-08 11:48:30,570 - mmaction - INFO - Epoch(val) [50][132]\ttop1_acc: 0.9365, top5_acc: 1.0000, mean_class_accuracy: 0.9365\n",
      "2021-05-08 11:51:52,106 - mmaction - INFO - Epoch [51][100/132]\tlr: 1.250e-06, eta: 2:45:40, time: 2.015, data_time: 0.035, memory: 21787, top1_acc: 0.7863, top5_acc: 0.9900, loss_cls: 0.5662, loss: 0.5662, grad_norm: 18.5681\n",
      "2021-05-08 11:56:15,634 - mmaction - INFO - Epoch [52][100/132]\tlr: 1.250e-06, eta: 2:42:17, time: 2.005, data_time: 0.037, memory: 21787, top1_acc: 0.7875, top5_acc: 0.9825, loss_cls: 0.5439, loss: 0.5439, grad_norm: 17.4091\n",
      "2021-05-08 12:00:37,266 - mmaction - INFO - Epoch [53][100/132]\tlr: 1.250e-06, eta: 2:38:52, time: 1.989, data_time: 0.032, memory: 21787, top1_acc: 0.7712, top5_acc: 0.9850, loss_cls: 0.5810, loss: 0.5810, grad_norm: 18.3593\n",
      "2021-05-08 12:04:57,845 - mmaction - INFO - Epoch [54][100/132]\tlr: 1.250e-06, eta: 2:35:28, time: 1.988, data_time: 0.031, memory: 21787, top1_acc: 0.8025, top5_acc: 0.9900, loss_cls: 0.5311, loss: 0.5311, grad_norm: 18.0350\n",
      "2021-05-08 12:09:18,533 - mmaction - INFO - Epoch [55][100/132]\tlr: 1.250e-06, eta: 2:32:04, time: 1.989, data_time: 0.031, memory: 21787, top1_acc: 0.7987, top5_acc: 0.9912, loss_cls: 0.5130, loss: 0.5130, grad_norm: 16.9976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.4 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 12:10:27,678 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 12:10:27,680 - mmaction - INFO - \n",
      "top1_acc\t0.9603\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 12:10:27,681 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 12:10:27,682 - mmaction - INFO - \n",
      "mean_acc\t0.9603\n",
      "2021-05-08 12:10:29,835 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_55.pth.\n",
      "2021-05-08 12:10:29,837 - mmaction - INFO - Best top1_acc is 0.9603 at 55 epoch.\n",
      "2021-05-08 12:10:29,838 - mmaction - INFO - Epoch(val) [55][132]\ttop1_acc: 0.9603, top5_acc: 1.0000, mean_class_accuracy: 0.9603\n",
      "2021-05-08 12:13:48,868 - mmaction - INFO - Epoch [56][100/132]\tlr: 1.250e-06, eta: 2:28:40, time: 1.990, data_time: 0.033, memory: 21787, top1_acc: 0.7837, top5_acc: 0.9862, loss_cls: 0.5498, loss: 0.5498, grad_norm: 18.4053\n",
      "2021-05-08 12:18:11,103 - mmaction - INFO - Epoch [57][100/132]\tlr: 1.250e-06, eta: 2:25:17, time: 1.993, data_time: 0.031, memory: 21787, top1_acc: 0.8000, top5_acc: 0.9875, loss_cls: 0.5363, loss: 0.5363, grad_norm: 17.9373\n",
      "2021-05-08 12:22:34,454 - mmaction - INFO - Epoch [58][100/132]\tlr: 1.250e-06, eta: 2:21:54, time: 2.008, data_time: 0.034, memory: 21787, top1_acc: 0.8075, top5_acc: 0.9900, loss_cls: 0.5194, loss: 0.5194, grad_norm: 17.5829\n",
      "2021-05-08 12:26:59,886 - mmaction - INFO - Epoch [59][100/132]\tlr: 1.250e-06, eta: 2:18:33, time: 2.020, data_time: 0.032, memory: 21787, top1_acc: 0.8100, top5_acc: 0.9950, loss_cls: 0.5028, loss: 0.5028, grad_norm: 17.8553\n",
      "2021-05-08 12:31:24,968 - mmaction - INFO - Epoch [60][100/132]\tlr: 1.250e-06, eta: 2:15:12, time: 2.025, data_time: 0.030, memory: 21787, top1_acc: 0.8225, top5_acc: 0.9850, loss_cls: 0.5137, loss: 0.5137, grad_norm: 17.0531\n",
      "2021-05-08 12:32:27,074 - mmaction - INFO - Saving checkpoint at 60 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.2 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 12:32:36,570 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 12:32:36,573 - mmaction - INFO - \n",
      "top1_acc\t0.9206\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 12:32:36,574 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 12:32:36,576 - mmaction - INFO - \n",
      "mean_acc\t0.9206\n",
      "2021-05-08 12:32:36,577 - mmaction - INFO - Epoch(val) [60][132]\ttop1_acc: 0.9206, top5_acc: 1.0000, mean_class_accuracy: 0.9206\n",
      "2021-05-08 12:35:56,667 - mmaction - INFO - Epoch [61][100/132]\tlr: 1.250e-06, eta: 2:11:50, time: 2.001, data_time: 0.032, memory: 21787, top1_acc: 0.8100, top5_acc: 0.9900, loss_cls: 0.5174, loss: 0.5174, grad_norm: 17.0661\n",
      "2021-05-08 12:40:18,465 - mmaction - INFO - Epoch [62][100/132]\tlr: 1.250e-06, eta: 2:08:27, time: 1.997, data_time: 0.031, memory: 21787, top1_acc: 0.7937, top5_acc: 0.9812, loss_cls: 0.5359, loss: 0.5359, grad_norm: 17.8362\n",
      "2021-05-08 12:44:40,701 - mmaction - INFO - Epoch [63][100/132]\tlr: 1.250e-06, eta: 2:05:04, time: 2.000, data_time: 0.032, memory: 21787, top1_acc: 0.7975, top5_acc: 0.9912, loss_cls: 0.5286, loss: 0.5286, grad_norm: 16.8071\n",
      "2021-05-08 12:49:02,453 - mmaction - INFO - Epoch [64][100/132]\tlr: 1.250e-06, eta: 2:01:42, time: 1.996, data_time: 0.030, memory: 21787, top1_acc: 0.8275, top5_acc: 0.9888, loss_cls: 0.5016, loss: 0.5016, grad_norm: 16.5031\n",
      "2021-05-08 12:53:24,800 - mmaction - INFO - Epoch [65][100/132]\tlr: 1.250e-06, eta: 1:58:19, time: 1.998, data_time: 0.031, memory: 21787, top1_acc: 0.8000, top5_acc: 0.9900, loss_cls: 0.5104, loss: 0.5104, grad_norm: 16.8568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.7 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 12:54:34,131 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 12:54:34,133 - mmaction - INFO - \n",
      "top1_acc\t0.9365\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 12:54:34,134 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 12:54:34,136 - mmaction - INFO - \n",
      "mean_acc\t0.9365\n",
      "2021-05-08 12:54:34,137 - mmaction - INFO - Epoch(val) [65][132]\ttop1_acc: 0.9365, top5_acc: 1.0000, mean_class_accuracy: 0.9365\n",
      "2021-05-08 12:57:53,611 - mmaction - INFO - Epoch [66][100/132]\tlr: 1.250e-06, eta: 1:54:57, time: 1.995, data_time: 0.030, memory: 21787, top1_acc: 0.8125, top5_acc: 0.9900, loss_cls: 0.5049, loss: 0.5049, grad_norm: 18.1335\n",
      "2021-05-08 13:02:15,343 - mmaction - INFO - Epoch [67][100/132]\tlr: 1.250e-06, eta: 1:51:35, time: 1.996, data_time: 0.030, memory: 21787, top1_acc: 0.8137, top5_acc: 0.9912, loss_cls: 0.5367, loss: 0.5367, grad_norm: 16.9542\n",
      "2021-05-08 13:06:37,663 - mmaction - INFO - Epoch [68][100/132]\tlr: 1.250e-06, eta: 1:48:13, time: 2.003, data_time: 0.031, memory: 21787, top1_acc: 0.8050, top5_acc: 0.9862, loss_cls: 0.5404, loss: 0.5404, grad_norm: 17.3214\n",
      "2021-05-08 13:10:58,270 - mmaction - INFO - Epoch [69][100/132]\tlr: 1.250e-06, eta: 1:44:50, time: 1.988, data_time: 0.031, memory: 21787, top1_acc: 0.7688, top5_acc: 0.9838, loss_cls: 0.5896, loss: 0.5896, grad_norm: 19.6806\n",
      "2021-05-08 13:15:18,966 - mmaction - INFO - Epoch [70][100/132]\tlr: 1.250e-06, eta: 1:41:28, time: 1.988, data_time: 0.032, memory: 21787, top1_acc: 0.7850, top5_acc: 0.9875, loss_cls: 0.5473, loss: 0.5473, grad_norm: 18.5436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.7 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 13:16:28,366 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 13:16:28,368 - mmaction - INFO - \n",
      "top1_acc\t0.9365\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 13:16:28,369 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 13:16:28,370 - mmaction - INFO - \n",
      "mean_acc\t0.9365\n",
      "2021-05-08 13:16:28,371 - mmaction - INFO - Epoch(val) [70][132]\ttop1_acc: 0.9365, top5_acc: 1.0000, mean_class_accuracy: 0.9365\n",
      "2021-05-08 13:19:47,998 - mmaction - INFO - Epoch [71][100/132]\tlr: 1.250e-06, eta: 1:38:06, time: 1.996, data_time: 0.033, memory: 21787, top1_acc: 0.8075, top5_acc: 0.9900, loss_cls: 0.5034, loss: 0.5034, grad_norm: 16.4006\n",
      "2021-05-08 13:24:09,766 - mmaction - INFO - Epoch [72][100/132]\tlr: 1.250e-06, eta: 1:34:43, time: 1.989, data_time: 0.031, memory: 21787, top1_acc: 0.8150, top5_acc: 0.9862, loss_cls: 0.5211, loss: 0.5211, grad_norm: 18.2336\n",
      "2021-05-08 13:28:32,406 - mmaction - INFO - Epoch [73][100/132]\tlr: 1.250e-06, eta: 1:31:22, time: 2.007, data_time: 0.030, memory: 21787, top1_acc: 0.8037, top5_acc: 0.9888, loss_cls: 0.5181, loss: 0.5181, grad_norm: 18.5651\n",
      "2021-05-08 13:32:54,769 - mmaction - INFO - Epoch [74][100/132]\tlr: 1.250e-06, eta: 1:28:00, time: 1.999, data_time: 0.030, memory: 21787, top1_acc: 0.7788, top5_acc: 0.9875, loss_cls: 0.5867, loss: 0.5867, grad_norm: 18.4654\n",
      "2021-05-08 13:37:17,869 - mmaction - INFO - Epoch [75][100/132]\tlr: 1.250e-06, eta: 1:24:39, time: 2.012, data_time: 0.032, memory: 21787, top1_acc: 0.7725, top5_acc: 0.9838, loss_cls: 0.5590, loss: 0.5590, grad_norm: 18.3595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.7 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 13:38:27,718 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 13:38:27,719 - mmaction - INFO - \n",
      "top1_acc\t0.9444\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 13:38:27,720 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 13:38:27,720 - mmaction - INFO - \n",
      "mean_acc\t0.9444\n",
      "2021-05-08 13:38:27,721 - mmaction - INFO - Epoch(val) [75][132]\ttop1_acc: 0.9444, top5_acc: 1.0000, mean_class_accuracy: 0.9444\n",
      "2021-05-08 13:41:47,308 - mmaction - INFO - Epoch [76][100/132]\tlr: 1.250e-06, eta: 1:21:17, time: 1.996, data_time: 0.030, memory: 21787, top1_acc: 0.7662, top5_acc: 0.9888, loss_cls: 0.6005, loss: 0.6005, grad_norm: 19.9259\n",
      "2021-05-08 13:46:09,027 - mmaction - INFO - Epoch [77][100/132]\tlr: 1.250e-06, eta: 1:17:56, time: 1.996, data_time: 0.030, memory: 21787, top1_acc: 0.7963, top5_acc: 0.9888, loss_cls: 0.5387, loss: 0.5387, grad_norm: 18.2187\n",
      "2021-05-08 13:50:31,397 - mmaction - INFO - Epoch [78][100/132]\tlr: 1.250e-06, eta: 1:14:34, time: 1.999, data_time: 0.031, memory: 21787, top1_acc: 0.7913, top5_acc: 0.9900, loss_cls: 0.5303, loss: 0.5303, grad_norm: 17.6053\n",
      "2021-05-08 13:54:53,109 - mmaction - INFO - Epoch [79][100/132]\tlr: 1.250e-06, eta: 1:11:12, time: 1.999, data_time: 0.030, memory: 21787, top1_acc: 0.7762, top5_acc: 0.9838, loss_cls: 0.5769, loss: 0.5769, grad_norm: 18.0434\n",
      "2021-05-08 13:59:14,888 - mmaction - INFO - Epoch [80][100/132]\tlr: 1.250e-06, eta: 1:07:51, time: 1.996, data_time: 0.032, memory: 21787, top1_acc: 0.7812, top5_acc: 0.9912, loss_cls: 0.5525, loss: 0.5525, grad_norm: 18.2630\n",
      "2021-05-08 14:00:17,170 - mmaction - INFO - Saving checkpoint at 80 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.4 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 14:00:26,834 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 14:00:26,835 - mmaction - INFO - \n",
      "top1_acc\t0.9524\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 14:00:26,835 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 14:00:26,836 - mmaction - INFO - \n",
      "mean_acc\t0.9524\n",
      "2021-05-08 14:00:26,837 - mmaction - INFO - Epoch(val) [80][132]\ttop1_acc: 0.9524, top5_acc: 1.0000, mean_class_accuracy: 0.9524\n",
      "2021-05-08 14:03:45,535 - mmaction - INFO - Epoch [81][100/132]\tlr: 1.250e-06, eta: 1:04:29, time: 1.987, data_time: 0.030, memory: 21787, top1_acc: 0.7875, top5_acc: 0.9838, loss_cls: 0.5854, loss: 0.5854, grad_norm: 20.4285\n",
      "2021-05-08 14:08:06,264 - mmaction - INFO - Epoch [82][100/132]\tlr: 1.250e-06, eta: 1:01:08, time: 1.989, data_time: 0.030, memory: 21787, top1_acc: 0.7975, top5_acc: 0.9888, loss_cls: 0.5294, loss: 0.5294, grad_norm: 17.5508\n",
      "2021-05-08 14:12:28,173 - mmaction - INFO - Epoch [83][100/132]\tlr: 1.250e-06, eta: 0:57:46, time: 1.993, data_time: 0.030, memory: 21787, top1_acc: 0.7913, top5_acc: 0.9850, loss_cls: 0.5653, loss: 0.5653, grad_norm: 17.7271\n",
      "2021-05-08 14:16:49,041 - mmaction - INFO - Epoch [84][100/132]\tlr: 1.250e-06, eta: 0:54:25, time: 1.990, data_time: 0.031, memory: 21787, top1_acc: 0.7875, top5_acc: 0.9888, loss_cls: 0.5464, loss: 0.5464, grad_norm: 19.1699\n",
      "2021-05-08 14:21:09,786 - mmaction - INFO - Epoch [85][100/132]\tlr: 1.250e-06, eta: 0:51:03, time: 1.989, data_time: 0.031, memory: 21787, top1_acc: 0.7712, top5_acc: 0.9788, loss_cls: 0.5816, loss: 0.5816, grad_norm: 20.1628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.4 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 14:22:18,861 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 14:22:18,863 - mmaction - INFO - \n",
      "top1_acc\t0.9444\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 14:22:18,864 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 14:22:18,865 - mmaction - INFO - \n",
      "mean_acc\t0.9444\n",
      "2021-05-08 14:22:18,866 - mmaction - INFO - Epoch(val) [85][132]\ttop1_acc: 0.9444, top5_acc: 1.0000, mean_class_accuracy: 0.9444\n",
      "2021-05-08 14:25:38,238 - mmaction - INFO - Epoch [86][100/132]\tlr: 1.250e-06, eta: 0:47:42, time: 1.994, data_time: 0.030, memory: 21787, top1_acc: 0.7987, top5_acc: 0.9838, loss_cls: 0.5510, loss: 0.5510, grad_norm: 18.0934\n",
      "2021-05-08 14:30:01,421 - mmaction - INFO - Epoch [87][100/132]\tlr: 1.250e-06, eta: 0:44:21, time: 2.013, data_time: 0.031, memory: 21787, top1_acc: 0.7963, top5_acc: 0.9938, loss_cls: 0.5224, loss: 0.5224, grad_norm: 18.0256\n",
      "2021-05-08 14:34:24,093 - mmaction - INFO - Epoch [88][100/132]\tlr: 1.250e-06, eta: 0:41:00, time: 1.999, data_time: 0.031, memory: 21787, top1_acc: 0.8150, top5_acc: 0.9912, loss_cls: 0.4970, loss: 0.4970, grad_norm: 18.7535\n",
      "2021-05-08 14:38:44,802 - mmaction - INFO - Epoch [89][100/132]\tlr: 1.250e-06, eta: 0:37:39, time: 1.989, data_time: 0.032, memory: 21787, top1_acc: 0.8150, top5_acc: 0.9888, loss_cls: 0.5223, loss: 0.5223, grad_norm: 17.5858\n",
      "2021-05-08 14:43:05,473 - mmaction - INFO - Epoch [90][100/132]\tlr: 1.250e-06, eta: 0:34:17, time: 1.989, data_time: 0.031, memory: 21787, top1_acc: 0.7937, top5_acc: 0.9775, loss_cls: 0.5880, loss: 0.5880, grad_norm: 20.1733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.6 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 14:44:14,439 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 14:44:14,441 - mmaction - INFO - \n",
      "top1_acc\t0.9524\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 14:44:14,442 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 14:44:14,443 - mmaction - INFO - \n",
      "mean_acc\t0.9524\n",
      "2021-05-08 14:44:14,443 - mmaction - INFO - Epoch(val) [90][132]\ttop1_acc: 0.9524, top5_acc: 1.0000, mean_class_accuracy: 0.9524\n",
      "2021-05-08 14:47:33,259 - mmaction - INFO - Epoch [91][100/132]\tlr: 1.250e-06, eta: 0:30:56, time: 1.988, data_time: 0.031, memory: 21787, top1_acc: 0.7987, top5_acc: 0.9862, loss_cls: 0.5272, loss: 0.5272, grad_norm: 16.2025\n",
      "2021-05-08 14:51:53,965 - mmaction - INFO - Epoch [92][100/132]\tlr: 1.250e-06, eta: 0:27:35, time: 1.989, data_time: 0.031, memory: 21787, top1_acc: 0.7887, top5_acc: 0.9812, loss_cls: 0.5540, loss: 0.5540, grad_norm: 19.0217\n",
      "2021-05-08 14:56:14,643 - mmaction - INFO - Epoch [93][100/132]\tlr: 1.250e-06, eta: 0:24:14, time: 1.989, data_time: 0.032, memory: 21787, top1_acc: 0.7762, top5_acc: 0.9862, loss_cls: 0.5528, loss: 0.5528, grad_norm: 18.4287\n",
      "2021-05-08 15:00:35,326 - mmaction - INFO - Epoch [94][100/132]\tlr: 1.250e-06, eta: 0:20:53, time: 1.989, data_time: 0.031, memory: 21787, top1_acc: 0.8013, top5_acc: 0.9775, loss_cls: 0.5335, loss: 0.5335, grad_norm: 17.8954\n",
      "2021-05-08 15:04:56,112 - mmaction - INFO - Epoch [95][100/132]\tlr: 1.250e-06, eta: 0:17:32, time: 1.990, data_time: 0.032, memory: 21787, top1_acc: 0.8100, top5_acc: 0.9788, loss_cls: 0.5044, loss: 0.5044, grad_norm: 15.7742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.5 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 15:06:05,225 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 15:06:05,227 - mmaction - INFO - \n",
      "top1_acc\t0.9524\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 15:06:05,228 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 15:06:05,229 - mmaction - INFO - \n",
      "mean_acc\t0.9524\n",
      "2021-05-08 15:06:05,230 - mmaction - INFO - Epoch(val) [95][132]\ttop1_acc: 0.9524, top5_acc: 1.0000, mean_class_accuracy: 0.9524\n",
      "2021-05-08 15:09:24,068 - mmaction - INFO - Epoch [96][100/132]\tlr: 1.250e-06, eta: 0:14:11, time: 1.988, data_time: 0.031, memory: 21787, top1_acc: 0.8025, top5_acc: 0.9875, loss_cls: 0.5494, loss: 0.5494, grad_norm: 18.6266\n",
      "2021-05-08 15:13:44,848 - mmaction - INFO - Epoch [97][100/132]\tlr: 1.250e-06, eta: 0:10:51, time: 1.990, data_time: 0.031, memory: 21787, top1_acc: 0.7612, top5_acc: 0.9862, loss_cls: 0.5925, loss: 0.5925, grad_norm: 21.1252\n",
      "2021-05-08 15:18:05,699 - mmaction - INFO - Epoch [98][100/132]\tlr: 1.250e-06, eta: 0:07:30, time: 1.990, data_time: 0.032, memory: 21787, top1_acc: 0.7937, top5_acc: 0.9875, loss_cls: 0.5587, loss: 0.5587, grad_norm: 19.3350\n",
      "2021-05-08 15:22:26,379 - mmaction - INFO - Epoch [99][100/132]\tlr: 1.250e-06, eta: 0:04:09, time: 1.989, data_time: 0.031, memory: 21787, top1_acc: 0.8050, top5_acc: 0.9825, loss_cls: 0.5221, loss: 0.5221, grad_norm: 17.3764\n",
      "2021-05-08 15:26:47,109 - mmaction - INFO - Epoch [100][100/132]\tlr: 1.250e-06, eta: 0:00:48, time: 1.989, data_time: 0.031, memory: 21787, top1_acc: 0.8000, top5_acc: 0.9938, loss_cls: 0.5115, loss: 0.5115, grad_norm: 17.9851\n",
      "2021-05-08 15:27:48,918 - mmaction - INFO - Saving checkpoint at 100 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.3 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 15:27:58,359 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 15:27:58,360 - mmaction - INFO - \n",
      "top1_acc\t0.9524\n",
      "top5_acc\t1.0000\n",
      "2021-05-08 15:27:58,361 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 15:27:58,362 - mmaction - INFO - \n",
      "mean_acc\t0.9524\n",
      "2021-05-08 15:27:58,363 - mmaction - INFO - Epoch(val) [100][132]\ttop1_acc: 0.9524, top5_acc: 1.0000, mean_class_accuracy: 0.9524\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rapid-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model100e_ig65m\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-saturday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-still",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os.path as osp\n",
    "\n",
    "# from mmaction.datasets import build_dataset\n",
    "# from mmaction.models import build_model\n",
    "# from mmaction.apis import train_model\n",
    "# import pickle\n",
    "# import mmcv\n",
    "# # Build the dataset\n",
    "# datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# # Build the recognizer\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "# model = pickle.load(open(f\"{cfg.work_dir}/model50e\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "racial-atlas",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 0.5 task/s, elapsed: 265s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.9683\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.9683\n",
      "top1_acc: 0.9683\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.9683\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmaction.models import build_model\n",
    "from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=4,\n",
    "        workers_per_gpu=1,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wooden-modification",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'], yticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dress-asset",
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/csn/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "brown-cylinder",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='ResNet3dCSN',\n",
      "        pretrained2d=False,\n",
      "        pretrained=None,\n",
      "        depth=152,\n",
      "        with_pool2=False,\n",
      "        bottleneck_mode='ir',\n",
      "        norm_eval=False,\n",
      "        zero_init_residual=False,\n",
      "        in_channels=2),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        num_classes=7,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "dataset_type = 'RawframeDataset'\n",
      "data_root = 'data/childact_rawframe/train/'\n",
      "data_root_val = 'data/childact_rawframe/val/'\n",
      "ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
      "ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
      "ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
      "img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
      "train_pipeline = [\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=10,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_train_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/train/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    val=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_val_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/val/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    test=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_test_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/test/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=10,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'))\n",
      "optimizer = dict(type='SGD', lr=0.000125, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    step=[32, 48],\n",
      "    warmup='linear',\n",
      "    warmup_ratio=0.1,\n",
      "    warmup_by_epoch=True,\n",
      "    warmup_iters=16)\n",
      "total_epochs = 100\n",
      "checkpoint_config = dict(interval=20)\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "log_config = dict(\n",
      "    interval=100,\n",
      "    hooks=[dict(type='TextLoggerHook'),\n",
      "           dict(type='TensorboardLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "work_dir = './childact-checkpoints/CSN-no-transfer'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "omnisource = False\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/CSN-no-transfer/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "cfg.model.backbone.pretrained = None\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_rawframe/train/'\n",
    "cfg.data_root_val = 'data/childact_rawframe/val/'\n",
    "cfg.ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "\n",
    "# cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_rawframe/test/'\n",
    "\n",
    "# cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_rawframe/train/'\n",
    "\n",
    "# cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_rawframe/val/'\n",
    "\n",
    "cfg.data.test.modality = 'Flow'\n",
    "cfg.data.val.modality = 'Flow'\n",
    "cfg.data.train.modality = 'Flow'\n",
    "\n",
    "cfg.data.train.start_index = 0\n",
    "cfg.data.test.start_index = 0\n",
    "cfg.data.val.start_index = 0\n",
    "\n",
    "cfg.data.test.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.train.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.val.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "# cfg.load_from = 'checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/CSN-no-transfer'\n",
    "\n",
    "cfg.img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
    "\n",
    "\n",
    "cfg.val_pipeline = [\n",
    "    dict(\n",
    "        type='SampleFrames',\n",
    "        clip_len=32,\n",
    "        frame_interval=2,\n",
    "        num_clips=1,\n",
    "        test_mode=True),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "#     dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "#     dict(type='Flip', flip_ratio=0.5)\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=10, test_mode=True),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='RandomCrop', size=224),\n",
    "    dict(type='RandomResizedCrop'),\n",
    "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "#     dict(type='Flip', flip_ratio=0.5),\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
    "]\n",
    "\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.val.pipeline = cfg.val_pipeline\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "# cfg.data.videos_per_gpu = 24\n",
    "# cfg.optimizer.type = 'Adam'\n",
    "# cfg.optimizer.weight_decay=0.0001\n",
    "\n",
    "# cfg.optimizer_config.grad_clip=None\n",
    "# cfg.optimizer.lr = 0.01\n",
    "\n",
    "# cfg.lr_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(10, 1e-5),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "cfg.total_epochs = 100\n",
    "\n",
    "# cfg.momentum_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(0.85 / 0.95, 1),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 20\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.data.videos_per_gpu=8\n",
    "\n",
    "cfg.model.backbone.in_channels = 2\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polished-plant",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 00:46:39,676 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /media/actrec/DATA/.virtualenvs/mmaction/mmaction2/childact-checkpoints/CSN-no-transfer\n",
      "2021-05-08 00:46:39,677 - mmaction - INFO - workflow: [('train', 1)], max: 100 epochs\n",
      "/media/actrec/DATA/.virtualenvs/mmaction/mmaction2/mmaction/core/evaluation/eval_hooks.py:131: UserWarning: runner.meta is None. Creating a empty one.\n",
      "  warnings.warn('runner.meta is None. Creating a empty one.')\n",
      "2021-05-08 00:50:02,074 - mmaction - INFO - Epoch [1][100/132]\tlr: 1.777e-05, eta: 7:21:47, time: 2.024, data_time: 0.035, memory: 21787, top1_acc: 0.1350, top5_acc: 0.7238, loss_cls: 2.0598, loss: 2.0598, grad_norm: 1519.5586\n",
      "2021-05-08 00:54:23,554 - mmaction - INFO - Epoch [2][100/132]\tlr: 2.480e-05, eta: 6:14:17, time: 1.994, data_time: 0.030, memory: 21787, top1_acc: 0.1350, top5_acc: 0.7362, loss_cls: 2.0437, loss: 2.0437, grad_norm: 1457.7541\n",
      "2021-05-08 00:58:44,909 - mmaction - INFO - Epoch [3][100/132]\tlr: 3.184e-05, eta: 5:53:15, time: 1.993, data_time: 0.030, memory: 21787, top1_acc: 0.1325, top5_acc: 0.7262, loss_cls: 2.0233, loss: 2.0233, grad_norm: 1348.4679\n",
      "2021-05-08 01:03:06,631 - mmaction - INFO - Epoch [4][100/132]\tlr: 3.887e-05, eta: 5:41:48, time: 1.997, data_time: 0.033, memory: 21787, top1_acc: 0.1575, top5_acc: 0.7375, loss_cls: 2.0041, loss: 2.0041, grad_norm: 1265.8520\n",
      "2021-05-08 01:07:28,274 - mmaction - INFO - Epoch [5][100/132]\tlr: 4.590e-05, eta: 5:33:44, time: 1.996, data_time: 0.033, memory: 21787, top1_acc: 0.1812, top5_acc: 0.7275, loss_cls: 1.9743, loss: 1.9743, grad_norm: 1199.5677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 16.4 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 01:08:38,032 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 01:08:38,034 - mmaction - INFO - \n",
      "top1_acc\t0.1746\n",
      "top5_acc\t0.7698\n",
      "2021-05-08 01:08:38,034 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 01:08:38,035 - mmaction - INFO - \n",
      "mean_acc\t0.1746\n",
      "2021-05-08 01:08:40,145 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
      "2021-05-08 01:08:40,146 - mmaction - INFO - Best top1_acc is 0.1746 at 5 epoch.\n",
      "2021-05-08 01:08:40,147 - mmaction - INFO - Epoch(val) [5][132]\ttop1_acc: 0.1746, top5_acc: 0.7698, mean_class_accuracy: 0.1746\n",
      "2021-05-08 01:11:59,663 - mmaction - INFO - Epoch [6][100/132]\tlr: 5.293e-05, eta: 5:27:18, time: 1.995, data_time: 0.032, memory: 21787, top1_acc: 0.1338, top5_acc: 0.7312, loss_cls: 2.0174, loss: 2.0174, grad_norm: 1108.9898\n",
      "2021-05-08 01:16:21,267 - mmaction - INFO - Epoch [7][100/132]\tlr: 5.996e-05, eta: 5:21:49, time: 1.996, data_time: 0.032, memory: 21787, top1_acc: 0.1688, top5_acc: 0.7350, loss_cls: 1.9861, loss: 1.9861, grad_norm: 994.7122\n",
      "2021-05-08 01:20:42,888 - mmaction - INFO - Epoch [8][100/132]\tlr: 6.699e-05, eta: 5:16:52, time: 1.996, data_time: 0.032, memory: 21787, top1_acc: 0.1500, top5_acc: 0.7450, loss_cls: 1.9865, loss: 1.9865, grad_norm: 865.3867\n",
      "2021-05-08 01:25:04,488 - mmaction - INFO - Epoch [9][100/132]\tlr: 7.402e-05, eta: 5:12:18, time: 1.996, data_time: 0.032, memory: 21787, top1_acc: 0.1675, top5_acc: 0.7500, loss_cls: 1.9850, loss: 1.9850, grad_norm: 830.5805\n",
      "2021-05-08 01:29:25,915 - mmaction - INFO - Epoch [10][100/132]\tlr: 8.105e-05, eta: 5:07:58, time: 1.994, data_time: 0.032, memory: 21787, top1_acc: 0.1725, top5_acc: 0.7200, loss_cls: 1.9856, loss: 1.9856, grad_norm: 762.6980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 16.9 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 01:30:35,511 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 01:30:35,514 - mmaction - INFO - \n",
      "top1_acc\t0.2698\n",
      "top5_acc\t0.8571\n",
      "2021-05-08 01:30:35,515 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 01:30:35,517 - mmaction - INFO - \n",
      "mean_acc\t0.2698\n",
      "2021-05-08 01:30:37,657 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_10.pth.\n",
      "2021-05-08 01:30:37,659 - mmaction - INFO - Best top1_acc is 0.2698 at 10 epoch.\n",
      "2021-05-08 01:30:37,660 - mmaction - INFO - Epoch(val) [10][132]\ttop1_acc: 0.2698, top5_acc: 0.8571, mean_class_accuracy: 0.2698\n",
      "2021-05-08 01:33:58,975 - mmaction - INFO - Epoch [11][100/132]\tlr: 8.809e-05, eta: 5:04:04, time: 2.013, data_time: 0.030, memory: 21787, top1_acc: 0.1688, top5_acc: 0.7512, loss_cls: 1.9669, loss: 1.9669, grad_norm: 693.8755\n",
      "2021-05-08 01:38:21,546 - mmaction - INFO - Epoch [12][100/132]\tlr: 9.512e-05, eta: 5:00:08, time: 2.002, data_time: 0.032, memory: 21787, top1_acc: 0.1888, top5_acc: 0.7762, loss_cls: 1.9495, loss: 1.9495, grad_norm: 637.5513\n",
      "2021-05-08 01:42:44,156 - mmaction - INFO - Epoch [13][100/132]\tlr: 1.021e-04, eta: 4:56:18, time: 2.003, data_time: 0.030, memory: 21787, top1_acc: 0.1787, top5_acc: 0.7700, loss_cls: 1.9608, loss: 1.9608, grad_norm: 614.3093\n",
      "2021-05-08 01:47:07,618 - mmaction - INFO - Epoch [14][100/132]\tlr: 1.092e-04, eta: 4:52:38, time: 2.011, data_time: 0.034, memory: 21787, top1_acc: 0.2000, top5_acc: 0.7775, loss_cls: 1.9280, loss: 1.9280, grad_norm: 579.0993\n",
      "2021-05-08 01:51:30,504 - mmaction - INFO - Epoch [15][100/132]\tlr: 1.162e-04, eta: 4:48:55, time: 2.003, data_time: 0.033, memory: 21787, top1_acc: 0.1600, top5_acc: 0.7538, loss_cls: 1.9640, loss: 1.9640, grad_norm: 547.0938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 14.4 task/s, elapsed: 9s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 01:52:41,422 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 01:52:41,424 - mmaction - INFO - \n",
      "top1_acc\t0.2302\n",
      "top5_acc\t0.8889\n",
      "2021-05-08 01:52:41,425 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 01:52:41,427 - mmaction - INFO - \n",
      "mean_acc\t0.2302\n",
      "2021-05-08 01:52:41,428 - mmaction - INFO - Epoch(val) [15][132]\ttop1_acc: 0.2302, top5_acc: 0.8889, mean_class_accuracy: 0.2302\n",
      "2021-05-08 01:56:02,246 - mmaction - INFO - Epoch [16][100/132]\tlr: 1.232e-04, eta: 4:45:18, time: 2.008, data_time: 0.034, memory: 21787, top1_acc: 0.2125, top5_acc: 0.7725, loss_cls: 1.9536, loss: 1.9536, grad_norm: 514.9274\n",
      "2021-05-08 02:00:23,841 - mmaction - INFO - Epoch [17][100/132]\tlr: 1.250e-04, eta: 4:41:37, time: 1.995, data_time: 0.031, memory: 21787, top1_acc: 0.1762, top5_acc: 0.7925, loss_cls: 1.9641, loss: 1.9641, grad_norm: 477.2907\n",
      "2021-05-08 02:04:45,703 - mmaction - INFO - Epoch [18][100/132]\tlr: 1.250e-04, eta: 4:37:59, time: 1.999, data_time: 0.033, memory: 21787, top1_acc: 0.1900, top5_acc: 0.8125, loss_cls: 1.9294, loss: 1.9294, grad_norm: 439.9222\n",
      "2021-05-08 02:09:07,505 - mmaction - INFO - Epoch [19][100/132]\tlr: 1.250e-04, eta: 4:34:24, time: 1.998, data_time: 0.032, memory: 21787, top1_acc: 0.2000, top5_acc: 0.7887, loss_cls: 1.9428, loss: 1.9428, grad_norm: 417.1554\n",
      "2021-05-08 02:13:29,229 - mmaction - INFO - Epoch [20][100/132]\tlr: 1.250e-04, eta: 4:30:49, time: 1.998, data_time: 0.032, memory: 21787, top1_acc: 0.1975, top5_acc: 0.7762, loss_cls: 1.9588, loss: 1.9588, grad_norm: 396.6623\n",
      "2021-05-08 02:14:31,196 - mmaction - INFO - Saving checkpoint at 20 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 15.7 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 02:14:41,282 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 02:14:41,284 - mmaction - INFO - \n",
      "top1_acc\t0.3730\n",
      "top5_acc\t0.8889\n",
      "2021-05-08 02:14:41,285 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 02:14:41,286 - mmaction - INFO - \n",
      "mean_acc\t0.3730\n",
      "2021-05-08 02:14:43,512 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_20.pth.\n",
      "2021-05-08 02:14:43,513 - mmaction - INFO - Best top1_acc is 0.3730 at 20 epoch.\n",
      "2021-05-08 02:14:43,514 - mmaction - INFO - Epoch(val) [20][132]\ttop1_acc: 0.3730, top5_acc: 0.8889, mean_class_accuracy: 0.3730\n",
      "2021-05-08 02:18:03,550 - mmaction - INFO - Epoch [21][100/132]\tlr: 1.250e-04, eta: 4:27:17, time: 2.000, data_time: 0.032, memory: 21787, top1_acc: 0.2050, top5_acc: 0.7887, loss_cls: 1.9331, loss: 1.9331, grad_norm: 371.6902\n",
      "2021-05-08 02:22:25,252 - mmaction - INFO - Epoch [22][100/132]\tlr: 1.250e-04, eta: 4:23:46, time: 1.998, data_time: 0.034, memory: 21787, top1_acc: 0.1850, top5_acc: 0.8087, loss_cls: 1.9582, loss: 1.9582, grad_norm: 365.8664\n",
      "2021-05-08 02:26:47,031 - mmaction - INFO - Epoch [23][100/132]\tlr: 1.250e-04, eta: 4:20:15, time: 1.998, data_time: 0.033, memory: 21787, top1_acc: 0.2087, top5_acc: 0.7850, loss_cls: 1.9238, loss: 1.9238, grad_norm: 355.1432\n",
      "2021-05-08 02:31:08,594 - mmaction - INFO - Epoch [24][100/132]\tlr: 1.250e-04, eta: 4:16:44, time: 1.996, data_time: 0.033, memory: 21787, top1_acc: 0.1825, top5_acc: 0.7700, loss_cls: 1.9510, loss: 1.9510, grad_norm: 356.4780\n",
      "2021-05-08 02:35:30,630 - mmaction - INFO - Epoch [25][100/132]\tlr: 1.250e-04, eta: 4:13:16, time: 2.001, data_time: 0.035, memory: 21787, top1_acc: 0.2275, top5_acc: 0.8025, loss_cls: 1.9099, loss: 1.9099, grad_norm: 333.6370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 15.4 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 02:36:41,018 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 02:36:41,020 - mmaction - INFO - \n",
      "top1_acc\t0.3095\n",
      "top5_acc\t0.8730\n",
      "2021-05-08 02:36:41,020 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 02:36:41,023 - mmaction - INFO - \n",
      "mean_acc\t0.3095\n",
      "2021-05-08 02:36:41,024 - mmaction - INFO - Epoch(val) [25][132]\ttop1_acc: 0.3095, top5_acc: 0.8730, mean_class_accuracy: 0.3095\n",
      "2021-05-08 02:40:01,097 - mmaction - INFO - Epoch [26][100/132]\tlr: 1.250e-04, eta: 4:09:49, time: 2.001, data_time: 0.032, memory: 21787, top1_acc: 0.2062, top5_acc: 0.8150, loss_cls: 1.9103, loss: 1.9103, grad_norm: 317.6817\n",
      "2021-05-08 02:44:22,461 - mmaction - INFO - Epoch [27][100/132]\tlr: 1.250e-04, eta: 4:06:20, time: 1.994, data_time: 0.031, memory: 21787, top1_acc: 0.2075, top5_acc: 0.8063, loss_cls: 1.9188, loss: 1.9188, grad_norm: 302.1534\n",
      "2021-05-08 02:48:43,762 - mmaction - INFO - Epoch [28][100/132]\tlr: 1.250e-04, eta: 4:02:52, time: 1.994, data_time: 0.032, memory: 21787, top1_acc: 0.2013, top5_acc: 0.8063, loss_cls: 1.9218, loss: 1.9218, grad_norm: 286.9516\n",
      "2021-05-08 02:53:05,254 - mmaction - INFO - Epoch [29][100/132]\tlr: 1.250e-04, eta: 3:59:25, time: 1.995, data_time: 0.032, memory: 21787, top1_acc: 0.2475, top5_acc: 0.8337, loss_cls: 1.8619, loss: 1.8619, grad_norm: 282.5666\n",
      "2021-05-08 02:57:26,938 - mmaction - INFO - Epoch [30][100/132]\tlr: 1.250e-04, eta: 3:55:59, time: 1.997, data_time: 0.034, memory: 21787, top1_acc: 0.2062, top5_acc: 0.8137, loss_cls: 1.9289, loss: 1.9289, grad_norm: 275.5838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 15.4 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 02:58:37,119 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 02:58:37,120 - mmaction - INFO - \n",
      "top1_acc\t0.4206\n",
      "top5_acc\t0.9206\n",
      "2021-05-08 02:58:37,121 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 02:58:37,122 - mmaction - INFO - \n",
      "mean_acc\t0.4206\n",
      "2021-05-08 02:58:39,366 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_30.pth.\n",
      "2021-05-08 02:58:39,368 - mmaction - INFO - Best top1_acc is 0.4206 at 30 epoch.\n",
      "2021-05-08 02:58:39,369 - mmaction - INFO - Epoch(val) [30][132]\ttop1_acc: 0.4206, top5_acc: 0.9206, mean_class_accuracy: 0.4206\n",
      "2021-05-08 03:02:02,106 - mmaction - INFO - Epoch [31][100/132]\tlr: 1.250e-04, eta: 3:52:40, time: 2.027, data_time: 0.032, memory: 21787, top1_acc: 0.2062, top5_acc: 0.8287, loss_cls: 1.9123, loss: 1.9123, grad_norm: 264.1676\n",
      "2021-05-08 03:06:25,088 - mmaction - INFO - Epoch [32][100/132]\tlr: 1.250e-04, eta: 3:49:14, time: 1.999, data_time: 0.035, memory: 21787, top1_acc: 0.2100, top5_acc: 0.8237, loss_cls: 1.8993, loss: 1.8993, grad_norm: 262.7559\n",
      "2021-05-08 03:10:46,529 - mmaction - INFO - Epoch [33][100/132]\tlr: 1.250e-05, eta: 3:45:49, time: 1.995, data_time: 0.031, memory: 21787, top1_acc: 0.1875, top5_acc: 0.8100, loss_cls: 1.9290, loss: 1.9290, grad_norm: 262.3630\n",
      "2021-05-08 03:15:08,107 - mmaction - INFO - Epoch [34][100/132]\tlr: 1.250e-05, eta: 3:42:23, time: 1.996, data_time: 0.033, memory: 21787, top1_acc: 0.2375, top5_acc: 0.8137, loss_cls: 1.8807, loss: 1.8807, grad_norm: 266.0124\n",
      "2021-05-08 03:19:29,781 - mmaction - INFO - Epoch [35][100/132]\tlr: 1.250e-05, eta: 3:38:59, time: 1.997, data_time: 0.036, memory: 21787, top1_acc: 0.2475, top5_acc: 0.8400, loss_cls: 1.8587, loss: 1.8587, grad_norm: 261.2340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 16.8 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 03:20:39,268 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 03:20:39,270 - mmaction - INFO - \n",
      "top1_acc\t0.3810\n",
      "top5_acc\t0.9127\n",
      "2021-05-08 03:20:39,271 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 03:20:39,273 - mmaction - INFO - \n",
      "mean_acc\t0.3810\n",
      "2021-05-08 03:20:39,273 - mmaction - INFO - Epoch(val) [35][132]\ttop1_acc: 0.3810, top5_acc: 0.9127, mean_class_accuracy: 0.3810\n",
      "2021-05-08 03:23:58,931 - mmaction - INFO - Epoch [36][100/132]\tlr: 1.250e-05, eta: 3:35:34, time: 1.996, data_time: 0.032, memory: 21787, top1_acc: 0.2250, top5_acc: 0.8287, loss_cls: 1.8712, loss: 1.8712, grad_norm: 260.7389\n",
      "2021-05-08 03:28:20,284 - mmaction - INFO - Epoch [37][100/132]\tlr: 1.250e-05, eta: 3:32:09, time: 1.994, data_time: 0.030, memory: 21787, top1_acc: 0.2362, top5_acc: 0.8263, loss_cls: 1.8687, loss: 1.8687, grad_norm: 259.4808\n",
      "2021-05-08 03:32:44,133 - mmaction - INFO - Epoch [38][100/132]\tlr: 1.250e-05, eta: 3:28:49, time: 2.019, data_time: 0.032, memory: 21787, top1_acc: 0.2500, top5_acc: 0.8387, loss_cls: 1.8450, loss: 1.8450, grad_norm: 255.2180\n",
      "2021-05-08 03:37:06,141 - mmaction - INFO - Epoch [39][100/132]\tlr: 1.250e-05, eta: 3:25:26, time: 2.000, data_time: 0.032, memory: 21787, top1_acc: 0.2362, top5_acc: 0.8237, loss_cls: 1.8739, loss: 1.8739, grad_norm: 254.8574\n",
      "2021-05-08 03:41:28,248 - mmaction - INFO - Epoch [40][100/132]\tlr: 1.250e-05, eta: 3:22:02, time: 1.997, data_time: 0.035, memory: 21787, top1_acc: 0.2525, top5_acc: 0.8237, loss_cls: 1.8760, loss: 1.8760, grad_norm: 254.6249\n",
      "2021-05-08 03:42:30,199 - mmaction - INFO - Saving checkpoint at 40 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 11.9 task/s, elapsed: 11s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 03:42:43,072 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 03:42:43,074 - mmaction - INFO - \n",
      "top1_acc\t0.4048\n",
      "top5_acc\t0.9127\n",
      "2021-05-08 03:42:43,075 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 03:42:43,076 - mmaction - INFO - \n",
      "mean_acc\t0.4048\n",
      "2021-05-08 03:42:43,077 - mmaction - INFO - Epoch(val) [40][132]\ttop1_acc: 0.4048, top5_acc: 0.9127, mean_class_accuracy: 0.4048\n",
      "2021-05-08 03:46:09,486 - mmaction - INFO - Epoch [41][100/132]\tlr: 1.250e-05, eta: 3:18:48, time: 2.064, data_time: 0.030, memory: 21787, top1_acc: 0.2375, top5_acc: 0.8425, loss_cls: 1.8530, loss: 1.8530, grad_norm: 258.8275\n",
      "2021-05-08 03:50:35,223 - mmaction - INFO - Epoch [42][100/132]\tlr: 1.250e-05, eta: 3:15:29, time: 2.026, data_time: 0.039, memory: 21787, top1_acc: 0.2412, top5_acc: 0.8413, loss_cls: 1.8657, loss: 1.8657, grad_norm: 257.7501\n",
      "2021-05-08 03:54:56,790 - mmaction - INFO - Epoch [43][100/132]\tlr: 1.250e-05, eta: 3:12:05, time: 1.996, data_time: 0.032, memory: 21787, top1_acc: 0.2238, top5_acc: 0.8137, loss_cls: 1.9072, loss: 1.9072, grad_norm: 257.1562\n",
      "2021-05-08 03:59:18,466 - mmaction - INFO - Epoch [44][100/132]\tlr: 1.250e-05, eta: 3:08:42, time: 1.997, data_time: 0.033, memory: 21787, top1_acc: 0.2387, top5_acc: 0.8413, loss_cls: 1.8672, loss: 1.8672, grad_norm: 259.3032\n",
      "2021-05-08 04:03:40,010 - mmaction - INFO - Epoch [45][100/132]\tlr: 1.250e-05, eta: 3:05:18, time: 1.996, data_time: 0.031, memory: 21787, top1_acc: 0.2412, top5_acc: 0.8163, loss_cls: 1.8634, loss: 1.8634, grad_norm: 257.5002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 15.3 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 04:04:50,346 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 04:04:50,348 - mmaction - INFO - \n",
      "top1_acc\t0.4603\n",
      "top5_acc\t0.9048\n",
      "2021-05-08 04:04:50,349 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 04:04:50,350 - mmaction - INFO - \n",
      "mean_acc\t0.4603\n",
      "2021-05-08 04:04:52,457 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_45.pth.\n",
      "2021-05-08 04:04:52,458 - mmaction - INFO - Best top1_acc is 0.4603 at 45 epoch.\n",
      "2021-05-08 04:04:52,459 - mmaction - INFO - Epoch(val) [45][132]\ttop1_acc: 0.4603, top5_acc: 0.9048, mean_class_accuracy: 0.4603\n",
      "2021-05-08 04:08:27,838 - mmaction - INFO - Epoch [46][100/132]\tlr: 1.250e-05, eta: 3:02:14, time: 2.154, data_time: 0.030, memory: 21787, top1_acc: 0.2325, top5_acc: 0.8287, loss_cls: 1.8454, loss: 1.8454, grad_norm: 259.2450\n",
      "2021-05-08 04:12:50,768 - mmaction - INFO - Epoch [47][100/132]\tlr: 1.250e-05, eta: 2:58:51, time: 2.004, data_time: 0.041, memory: 21787, top1_acc: 0.2475, top5_acc: 0.8250, loss_cls: 1.8680, loss: 1.8680, grad_norm: 254.6551\n",
      "2021-05-08 04:17:12,393 - mmaction - INFO - Epoch [48][100/132]\tlr: 1.250e-05, eta: 2:55:27, time: 1.997, data_time: 0.033, memory: 21787, top1_acc: 0.2288, top5_acc: 0.8263, loss_cls: 1.8916, loss: 1.8916, grad_norm: 255.7880\n",
      "2021-05-08 04:21:34,252 - mmaction - INFO - Epoch [49][100/132]\tlr: 1.250e-06, eta: 2:52:04, time: 1.998, data_time: 0.034, memory: 21787, top1_acc: 0.2450, top5_acc: 0.8313, loss_cls: 1.8489, loss: 1.8489, grad_norm: 253.6755\n",
      "2021-05-08 04:25:56,157 - mmaction - INFO - Epoch [50][100/132]\tlr: 1.250e-06, eta: 2:48:41, time: 1.999, data_time: 0.034, memory: 21787, top1_acc: 0.2375, top5_acc: 0.8200, loss_cls: 1.8751, loss: 1.8751, grad_norm: 253.5843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 15.1 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 04:27:06,606 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 04:27:06,608 - mmaction - INFO - \n",
      "top1_acc\t0.4524\n",
      "top5_acc\t0.9127\n",
      "2021-05-08 04:27:06,608 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 04:27:06,610 - mmaction - INFO - \n",
      "mean_acc\t0.4524\n",
      "2021-05-08 04:27:06,611 - mmaction - INFO - Epoch(val) [50][132]\ttop1_acc: 0.4524, top5_acc: 0.9127, mean_class_accuracy: 0.4524\n",
      "2021-05-08 04:30:26,490 - mmaction - INFO - Epoch [51][100/132]\tlr: 1.250e-06, eta: 2:45:18, time: 1.999, data_time: 0.035, memory: 21787, top1_acc: 0.2162, top5_acc: 0.8237, loss_cls: 1.8923, loss: 1.8923, grad_norm: 253.9602\n",
      "2021-05-08 04:34:48,358 - mmaction - INFO - Epoch [52][100/132]\tlr: 1.250e-06, eta: 2:41:55, time: 1.999, data_time: 0.035, memory: 21787, top1_acc: 0.2512, top5_acc: 0.8213, loss_cls: 1.8692, loss: 1.8692, grad_norm: 254.2343\n",
      "2021-05-08 04:39:10,763 - mmaction - INFO - Epoch [53][100/132]\tlr: 1.250e-06, eta: 2:38:33, time: 2.004, data_time: 0.034, memory: 21787, top1_acc: 0.2288, top5_acc: 0.8275, loss_cls: 1.8675, loss: 1.8675, grad_norm: 256.9388\n",
      "2021-05-08 04:43:32,679 - mmaction - INFO - Epoch [54][100/132]\tlr: 1.250e-06, eta: 2:35:10, time: 1.999, data_time: 0.037, memory: 21787, top1_acc: 0.2250, top5_acc: 0.8287, loss_cls: 1.8604, loss: 1.8604, grad_norm: 257.1199\n",
      "2021-05-08 04:47:55,011 - mmaction - INFO - Epoch [55][100/132]\tlr: 1.250e-06, eta: 2:31:48, time: 2.004, data_time: 0.034, memory: 21787, top1_acc: 0.2562, top5_acc: 0.8263, loss_cls: 1.8641, loss: 1.8641, grad_norm: 255.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 12.8 task/s, elapsed: 10s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 04:49:08,312 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 04:49:08,314 - mmaction - INFO - \n",
      "top1_acc\t0.4286\n",
      "top5_acc\t0.9127\n",
      "2021-05-08 04:49:08,315 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 04:49:08,316 - mmaction - INFO - \n",
      "mean_acc\t0.4286\n",
      "2021-05-08 04:49:08,317 - mmaction - INFO - Epoch(val) [55][132]\ttop1_acc: 0.4286, top5_acc: 0.9127, mean_class_accuracy: 0.4286\n",
      "2021-05-08 04:52:29,039 - mmaction - INFO - Epoch [56][100/132]\tlr: 1.250e-06, eta: 2:28:26, time: 2.007, data_time: 0.035, memory: 21787, top1_acc: 0.2213, top5_acc: 0.8213, loss_cls: 1.8746, loss: 1.8746, grad_norm: 253.0581\n",
      "2021-05-08 04:56:52,004 - mmaction - INFO - Epoch [57][100/132]\tlr: 1.250e-06, eta: 2:25:04, time: 2.001, data_time: 0.031, memory: 21787, top1_acc: 0.2400, top5_acc: 0.7963, loss_cls: 1.8938, loss: 1.8938, grad_norm: 262.8867\n",
      "2021-05-08 05:01:14,701 - mmaction - INFO - Epoch [58][100/132]\tlr: 1.250e-06, eta: 2:21:42, time: 2.007, data_time: 0.037, memory: 21787, top1_acc: 0.2437, top5_acc: 0.8387, loss_cls: 1.8439, loss: 1.8439, grad_norm: 256.5333\n",
      "2021-05-08 05:05:38,593 - mmaction - INFO - Epoch [59][100/132]\tlr: 1.250e-06, eta: 2:18:21, time: 2.014, data_time: 0.035, memory: 21787, top1_acc: 0.2238, top5_acc: 0.8100, loss_cls: 1.8917, loss: 1.8917, grad_norm: 255.9776\n",
      "2021-05-08 05:10:01,252 - mmaction - INFO - Epoch [60][100/132]\tlr: 1.250e-06, eta: 2:14:59, time: 2.007, data_time: 0.033, memory: 21787, top1_acc: 0.2188, top5_acc: 0.8150, loss_cls: 1.8752, loss: 1.8752, grad_norm: 254.8266\n",
      "2021-05-08 05:11:03,207 - mmaction - INFO - Saving checkpoint at 60 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 13.4 task/s, elapsed: 9s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 05:11:14,999 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 05:11:15,001 - mmaction - INFO - \n",
      "top1_acc\t0.4206\n",
      "top5_acc\t0.8968\n",
      "2021-05-08 05:11:15,002 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 05:11:15,004 - mmaction - INFO - \n",
      "mean_acc\t0.4206\n",
      "2021-05-08 05:11:15,005 - mmaction - INFO - Epoch(val) [60][132]\ttop1_acc: 0.4206, top5_acc: 0.8968, mean_class_accuracy: 0.4206\n",
      "2021-05-08 05:14:35,400 - mmaction - INFO - Epoch [61][100/132]\tlr: 1.250e-06, eta: 2:11:37, time: 2.004, data_time: 0.042, memory: 21787, top1_acc: 0.2437, top5_acc: 0.8237, loss_cls: 1.8706, loss: 1.8706, grad_norm: 250.4366\n",
      "2021-05-08 05:18:57,336 - mmaction - INFO - Epoch [62][100/132]\tlr: 1.250e-06, eta: 2:08:15, time: 2.000, data_time: 0.035, memory: 21787, top1_acc: 0.2425, top5_acc: 0.8275, loss_cls: 1.8782, loss: 1.8782, grad_norm: 254.9917\n",
      "2021-05-08 05:23:19,426 - mmaction - INFO - Epoch [63][100/132]\tlr: 1.250e-06, eta: 2:04:53, time: 2.002, data_time: 0.034, memory: 21787, top1_acc: 0.2250, top5_acc: 0.8237, loss_cls: 1.8770, loss: 1.8770, grad_norm: 258.8574\n",
      "2021-05-08 05:27:40,796 - mmaction - INFO - Epoch [64][100/132]\tlr: 1.250e-06, eta: 2:01:31, time: 1.995, data_time: 0.032, memory: 21787, top1_acc: 0.2437, top5_acc: 0.8337, loss_cls: 1.8303, loss: 1.8303, grad_norm: 251.8627\n",
      "2021-05-08 05:32:02,084 - mmaction - INFO - Epoch [65][100/132]\tlr: 1.250e-06, eta: 1:58:09, time: 1.994, data_time: 0.032, memory: 21787, top1_acc: 0.2250, top5_acc: 0.8400, loss_cls: 1.8590, loss: 1.8590, grad_norm: 254.2199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 16.0 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 05:33:12,036 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 05:33:12,039 - mmaction - INFO - \n",
      "top1_acc\t0.4048\n",
      "top5_acc\t0.9048\n",
      "2021-05-08 05:33:12,040 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 05:33:12,041 - mmaction - INFO - \n",
      "mean_acc\t0.4048\n",
      "2021-05-08 05:33:12,043 - mmaction - INFO - Epoch(val) [65][132]\ttop1_acc: 0.4048, top5_acc: 0.9048, mean_class_accuracy: 0.4048\n",
      "2021-05-08 05:36:31,560 - mmaction - INFO - Epoch [66][100/132]\tlr: 1.250e-06, eta: 1:54:47, time: 1.995, data_time: 0.033, memory: 21787, top1_acc: 0.2250, top5_acc: 0.8413, loss_cls: 1.8667, loss: 1.8667, grad_norm: 257.5629\n",
      "2021-05-08 05:40:53,544 - mmaction - INFO - Epoch [67][100/132]\tlr: 1.250e-06, eta: 1:51:25, time: 2.000, data_time: 0.034, memory: 21787, top1_acc: 0.2425, top5_acc: 0.8337, loss_cls: 1.8624, loss: 1.8624, grad_norm: 255.7543\n",
      "2021-05-08 05:45:15,371 - mmaction - INFO - Epoch [68][100/132]\tlr: 1.250e-06, eta: 1:48:04, time: 1.999, data_time: 0.033, memory: 21787, top1_acc: 0.2475, top5_acc: 0.8375, loss_cls: 1.8519, loss: 1.8519, grad_norm: 256.0165\n",
      "2021-05-08 05:49:37,246 - mmaction - INFO - Epoch [69][100/132]\tlr: 1.250e-06, eta: 1:44:42, time: 1.999, data_time: 0.034, memory: 21787, top1_acc: 0.2275, top5_acc: 0.8125, loss_cls: 1.8917, loss: 1.8917, grad_norm: 256.1268\n",
      "2021-05-08 05:53:58,868 - mmaction - INFO - Epoch [70][100/132]\tlr: 1.250e-06, eta: 1:41:20, time: 1.997, data_time: 0.034, memory: 21787, top1_acc: 0.2500, top5_acc: 0.8550, loss_cls: 1.8432, loss: 1.8432, grad_norm: 253.1811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 16.6 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 05:55:08,471 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 05:55:08,472 - mmaction - INFO - \n",
      "top1_acc\t0.4683\n",
      "top5_acc\t0.9048\n",
      "2021-05-08 05:55:08,472 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 05:55:08,473 - mmaction - INFO - \n",
      "mean_acc\t0.4683\n",
      "2021-05-08 05:55:10,525 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_70.pth.\n",
      "2021-05-08 05:55:10,526 - mmaction - INFO - Best top1_acc is 0.4683 at 70 epoch.\n",
      "2021-05-08 05:55:10,527 - mmaction - INFO - Epoch(val) [70][132]\ttop1_acc: 0.4683, top5_acc: 0.9048, mean_class_accuracy: 0.4683\n",
      "2021-05-08 05:58:37,916 - mmaction - INFO - Epoch [71][100/132]\tlr: 1.250e-06, eta: 1:38:02, time: 2.074, data_time: 0.038, memory: 21787, top1_acc: 0.2512, top5_acc: 0.8200, loss_cls: 1.8634, loss: 1.8634, grad_norm: 251.7808\n",
      "2021-05-08 06:03:02,664 - mmaction - INFO - Epoch [72][100/132]\tlr: 1.250e-06, eta: 1:34:41, time: 2.028, data_time: 0.044, memory: 21787, top1_acc: 0.2387, top5_acc: 0.8275, loss_cls: 1.8464, loss: 1.8464, grad_norm: 256.8809\n",
      "2021-05-08 06:07:25,702 - mmaction - INFO - Epoch [73][100/132]\tlr: 1.250e-06, eta: 1:31:20, time: 2.011, data_time: 0.034, memory: 21787, top1_acc: 0.2562, top5_acc: 0.8075, loss_cls: 1.8700, loss: 1.8700, grad_norm: 256.5678\n",
      "2021-05-08 06:11:47,754 - mmaction - INFO - Epoch [74][100/132]\tlr: 1.250e-06, eta: 1:27:59, time: 2.001, data_time: 0.038, memory: 21787, top1_acc: 0.2587, top5_acc: 0.8350, loss_cls: 1.8581, loss: 1.8581, grad_norm: 257.1797\n",
      "2021-05-08 06:16:09,662 - mmaction - INFO - Epoch [75][100/132]\tlr: 1.250e-06, eta: 1:24:37, time: 1.999, data_time: 0.034, memory: 21787, top1_acc: 0.2400, top5_acc: 0.8263, loss_cls: 1.8806, loss: 1.8806, grad_norm: 258.8631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 15.1 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 06:17:19,948 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 06:17:19,949 - mmaction - INFO - \n",
      "top1_acc\t0.4365\n",
      "top5_acc\t0.8968\n",
      "2021-05-08 06:17:19,950 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 06:17:19,951 - mmaction - INFO - \n",
      "mean_acc\t0.4365\n",
      "2021-05-08 06:17:19,951 - mmaction - INFO - Epoch(val) [75][132]\ttop1_acc: 0.4365, top5_acc: 0.8968, mean_class_accuracy: 0.4365\n",
      "2021-05-08 06:20:39,622 - mmaction - INFO - Epoch [76][100/132]\tlr: 1.250e-06, eta: 1:21:15, time: 1.997, data_time: 0.033, memory: 21787, top1_acc: 0.2362, top5_acc: 0.8400, loss_cls: 1.8638, loss: 1.8638, grad_norm: 258.5788\n",
      "2021-05-08 06:25:01,351 - mmaction - INFO - Epoch [77][100/132]\tlr: 1.250e-06, eta: 1:17:54, time: 1.998, data_time: 0.033, memory: 21787, top1_acc: 0.2475, top5_acc: 0.8387, loss_cls: 1.8642, loss: 1.8642, grad_norm: 255.0980\n",
      "2021-05-08 06:29:22,938 - mmaction - INFO - Epoch [78][100/132]\tlr: 1.250e-06, eta: 1:14:32, time: 1.997, data_time: 0.035, memory: 21787, top1_acc: 0.2575, top5_acc: 0.8350, loss_cls: 1.8545, loss: 1.8545, grad_norm: 254.7380\n",
      "2021-05-08 06:33:44,361 - mmaction - INFO - Epoch [79][100/132]\tlr: 1.250e-06, eta: 1:11:11, time: 1.995, data_time: 0.033, memory: 21787, top1_acc: 0.2263, top5_acc: 0.8237, loss_cls: 1.8654, loss: 1.8654, grad_norm: 253.5066\n",
      "2021-05-08 06:38:05,724 - mmaction - INFO - Epoch [80][100/132]\tlr: 1.250e-06, eta: 1:07:49, time: 1.994, data_time: 0.030, memory: 21787, top1_acc: 0.2050, top5_acc: 0.8050, loss_cls: 1.9137, loss: 1.9137, grad_norm: 255.7978\n",
      "2021-05-08 06:39:07,675 - mmaction - INFO - Saving checkpoint at 80 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 11.8 task/s, elapsed: 11s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 06:39:20,504 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 06:39:20,506 - mmaction - INFO - \n",
      "top1_acc\t0.4286\n",
      "top5_acc\t0.8968\n",
      "2021-05-08 06:39:20,507 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 06:39:20,509 - mmaction - INFO - \n",
      "mean_acc\t0.4286\n",
      "2021-05-08 06:39:20,510 - mmaction - INFO - Epoch(val) [80][132]\ttop1_acc: 0.4286, top5_acc: 0.8968, mean_class_accuracy: 0.4286\n",
      "2021-05-08 06:42:40,156 - mmaction - INFO - Epoch [81][100/132]\tlr: 1.250e-06, eta: 1:04:28, time: 1.996, data_time: 0.032, memory: 21787, top1_acc: 0.1963, top5_acc: 0.8087, loss_cls: 1.9209, loss: 1.9209, grad_norm: 259.2693\n",
      "2021-05-08 06:47:02,362 - mmaction - INFO - Epoch [82][100/132]\tlr: 1.250e-06, eta: 1:01:07, time: 2.003, data_time: 0.035, memory: 21787, top1_acc: 0.2400, top5_acc: 0.8375, loss_cls: 1.8596, loss: 1.8596, grad_norm: 252.6249\n",
      "2021-05-08 06:51:24,357 - mmaction - INFO - Epoch [83][100/132]\tlr: 1.250e-06, eta: 0:57:45, time: 2.001, data_time: 0.034, memory: 21787, top1_acc: 0.2487, top5_acc: 0.8550, loss_cls: 1.8472, loss: 1.8472, grad_norm: 253.0772\n",
      "2021-05-08 06:55:46,042 - mmaction - INFO - Epoch [84][100/132]\tlr: 1.250e-06, eta: 0:54:24, time: 1.997, data_time: 0.030, memory: 21787, top1_acc: 0.2500, top5_acc: 0.8363, loss_cls: 1.8437, loss: 1.8437, grad_norm: 257.1502\n",
      "2021-05-08 07:00:07,979 - mmaction - INFO - Epoch [85][100/132]\tlr: 1.250e-06, eta: 0:51:03, time: 1.999, data_time: 0.034, memory: 21787, top1_acc: 0.2425, top5_acc: 0.8400, loss_cls: 1.8638, loss: 1.8638, grad_norm: 253.6622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 16.2 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 07:01:17,698 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 07:01:17,699 - mmaction - INFO - \n",
      "top1_acc\t0.4365\n",
      "top5_acc\t0.9127\n",
      "2021-05-08 07:01:17,699 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 07:01:17,700 - mmaction - INFO - \n",
      "mean_acc\t0.4365\n",
      "2021-05-08 07:01:17,701 - mmaction - INFO - Epoch(val) [85][132]\ttop1_acc: 0.4365, top5_acc: 0.9127, mean_class_accuracy: 0.4365\n",
      "2021-05-08 07:04:37,382 - mmaction - INFO - Epoch [86][100/132]\tlr: 1.250e-06, eta: 0:47:42, time: 1.997, data_time: 0.034, memory: 21787, top1_acc: 0.2175, top5_acc: 0.8375, loss_cls: 1.8636, loss: 1.8636, grad_norm: 254.3374\n",
      "2021-05-08 07:08:59,175 - mmaction - INFO - Epoch [87][100/132]\tlr: 1.250e-06, eta: 0:44:21, time: 1.998, data_time: 0.031, memory: 21787, top1_acc: 0.2437, top5_acc: 0.8475, loss_cls: 1.8298, loss: 1.8298, grad_norm: 256.1563\n",
      "2021-05-08 07:13:20,917 - mmaction - INFO - Epoch [88][100/132]\tlr: 1.250e-06, eta: 0:41:00, time: 1.998, data_time: 0.034, memory: 21787, top1_acc: 0.2412, top5_acc: 0.8488, loss_cls: 1.8527, loss: 1.8527, grad_norm: 250.3309\n",
      "2021-05-08 07:17:42,596 - mmaction - INFO - Epoch [89][100/132]\tlr: 1.250e-06, eta: 0:37:38, time: 1.998, data_time: 0.033, memory: 21787, top1_acc: 0.2200, top5_acc: 0.8037, loss_cls: 1.9112, loss: 1.9112, grad_norm: 259.0273\n",
      "2021-05-08 07:22:04,582 - mmaction - INFO - Epoch [90][100/132]\tlr: 1.250e-06, eta: 0:34:17, time: 2.000, data_time: 0.033, memory: 21787, top1_acc: 0.2275, top5_acc: 0.8100, loss_cls: 1.8938, loss: 1.8938, grad_norm: 259.8973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 15.7 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 07:23:14,633 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 07:23:14,635 - mmaction - INFO - \n",
      "top1_acc\t0.5079\n",
      "top5_acc\t0.9048\n",
      "2021-05-08 07:23:14,635 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 07:23:14,637 - mmaction - INFO - \n",
      "mean_acc\t0.5079\n",
      "2021-05-08 07:23:16,917 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_90.pth.\n",
      "2021-05-08 07:23:16,918 - mmaction - INFO - Best top1_acc is 0.5079 at 90 epoch.\n",
      "2021-05-08 07:23:16,919 - mmaction - INFO - Epoch(val) [90][132]\ttop1_acc: 0.5079, top5_acc: 0.9048, mean_class_accuracy: 0.5079\n",
      "2021-05-08 07:26:38,586 - mmaction - INFO - Epoch [91][100/132]\tlr: 1.250e-06, eta: 0:30:57, time: 2.017, data_time: 0.032, memory: 21787, top1_acc: 0.2213, top5_acc: 0.8063, loss_cls: 1.9045, loss: 1.9045, grad_norm: 258.6824\n",
      "2021-05-08 07:31:01,528 - mmaction - INFO - Epoch [92][100/132]\tlr: 1.250e-06, eta: 0:27:36, time: 1.995, data_time: 0.031, memory: 21787, top1_acc: 0.2300, top5_acc: 0.8488, loss_cls: 1.8442, loss: 1.8442, grad_norm: 250.0055\n",
      "2021-05-08 07:35:23,160 - mmaction - INFO - Epoch [93][100/132]\tlr: 1.250e-06, eta: 0:24:15, time: 1.997, data_time: 0.032, memory: 21787, top1_acc: 0.2338, top5_acc: 0.8000, loss_cls: 1.8803, loss: 1.8803, grad_norm: 251.5403\n",
      "2021-05-08 07:39:44,413 - mmaction - INFO - Epoch [94][100/132]\tlr: 1.250e-06, eta: 0:20:54, time: 1.993, data_time: 0.031, memory: 21787, top1_acc: 0.2325, top5_acc: 0.8413, loss_cls: 1.8603, loss: 1.8603, grad_norm: 256.0547\n",
      "2021-05-08 07:44:06,008 - mmaction - INFO - Epoch [95][100/132]\tlr: 1.250e-06, eta: 0:17:33, time: 1.996, data_time: 0.031, memory: 21787, top1_acc: 0.2362, top5_acc: 0.8013, loss_cls: 1.8991, loss: 1.8991, grad_norm: 260.0779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 15.8 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 07:45:15,924 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 07:45:15,926 - mmaction - INFO - \n",
      "top1_acc\t0.4444\n",
      "top5_acc\t0.8889\n",
      "2021-05-08 07:45:15,927 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 07:45:15,929 - mmaction - INFO - \n",
      "mean_acc\t0.4444\n",
      "2021-05-08 07:45:15,930 - mmaction - INFO - Epoch(val) [95][132]\ttop1_acc: 0.4444, top5_acc: 0.8889, mean_class_accuracy: 0.4444\n",
      "2021-05-08 07:48:35,510 - mmaction - INFO - Epoch [96][100/132]\tlr: 1.250e-06, eta: 0:14:12, time: 1.996, data_time: 0.031, memory: 21787, top1_acc: 0.2525, top5_acc: 0.8287, loss_cls: 1.8477, loss: 1.8477, grad_norm: 254.0920\n",
      "2021-05-08 07:52:56,971 - mmaction - INFO - Epoch [97][100/132]\tlr: 1.250e-06, eta: 0:10:51, time: 1.995, data_time: 0.030, memory: 21787, top1_acc: 0.2412, top5_acc: 0.8325, loss_cls: 1.8744, loss: 1.8744, grad_norm: 256.2244\n",
      "2021-05-08 07:57:18,408 - mmaction - INFO - Epoch [98][100/132]\tlr: 1.250e-06, eta: 0:07:30, time: 1.994, data_time: 0.030, memory: 21787, top1_acc: 0.2400, top5_acc: 0.8187, loss_cls: 1.8620, loss: 1.8620, grad_norm: 255.2843\n",
      "2021-05-08 08:01:39,668 - mmaction - INFO - Epoch [99][100/132]\tlr: 1.250e-06, eta: 0:04:09, time: 1.994, data_time: 0.031, memory: 21787, top1_acc: 0.2387, top5_acc: 0.8250, loss_cls: 1.8572, loss: 1.8572, grad_norm: 254.9616\n",
      "2021-05-08 08:06:01,270 - mmaction - INFO - Epoch [100][100/132]\tlr: 1.250e-06, eta: 0:00:48, time: 1.996, data_time: 0.030, memory: 21787, top1_acc: 0.2412, top5_acc: 0.8488, loss_cls: 1.8398, loss: 1.8398, grad_norm: 253.3165\n",
      "2021-05-08 08:07:03,173 - mmaction - INFO - Saving checkpoint at 100 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 16.3 task/s, elapsed: 8s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 08:07:13,134 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-05-08 08:07:13,136 - mmaction - INFO - \n",
      "top1_acc\t0.4762\n",
      "top5_acc\t0.9127\n",
      "2021-05-08 08:07:13,137 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-05-08 08:07:13,140 - mmaction - INFO - \n",
      "mean_acc\t0.4762\n",
      "2021-05-08 08:07:13,141 - mmaction - INFO - Epoch(val) [100][132]\ttop1_acc: 0.4762, top5_acc: 0.9127, mean_class_accuracy: 0.4762\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "anticipated-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model100e\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "victorian-wrestling",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "import pickle\n",
    "import mmcv\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "model = pickle.load(open(f\"{cfg.work_dir}/model100e\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "persistent-bidder",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 0.5 task/s, elapsed: 278s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.5238\n",
      "top5_acc\t0.9683\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.5238\n",
      "top1_acc: 0.5238\n",
      "top5_acc: 0.9683\n",
      "mean_class_accuracy: 0.5238\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmaction.models import build_model\n",
    "from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=4,\n",
    "        workers_per_gpu=1,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "recorded-tactics",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'], yticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-syria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "imposed-thought",
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/csn/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "social-vinyl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='ResNet3dCSN',\n",
      "        pretrained2d=False,\n",
      "        pretrained=None,\n",
      "        depth=50,\n",
      "        with_pool2=False,\n",
      "        bottleneck_mode='ir',\n",
      "        norm_eval=False,\n",
      "        zero_init_residual=False,\n",
      "        in_channels=2),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        num_classes=7,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "dataset_type = 'RawframeDataset'\n",
      "data_root = 'data/childact_rawframe/train/'\n",
      "data_root_val = 'data/childact_rawframe/val/'\n",
      "ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
      "ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
      "ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
      "img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
      "train_pipeline = [\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=10,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_train_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/train/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    val=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_val_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/val/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    test=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_test_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/test/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=10,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'))\n",
      "optimizer = dict(type='SGD', lr=0.000125, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    step=[32, 48],\n",
      "    warmup='linear',\n",
      "    warmup_ratio=0.1,\n",
      "    warmup_by_epoch=True,\n",
      "    warmup_iters=16)\n",
      "total_epochs = 200\n",
      "checkpoint_config = dict(interval=20)\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "log_config = dict(\n",
      "    interval=100,\n",
      "    hooks=[dict(type='TextLoggerHook'),\n",
      "           dict(type='TensorboardLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "work_dir = './childact-checkpoints/CSN-no-transfer'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "omnisource = False\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/CSN-no-transfer/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "cfg.model.backbone.pretrained = None\n",
    "cfg.model.backbone.depth = 50\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_rawframe/train/'\n",
    "cfg.data_root_val = 'data/childact_rawframe/val/'\n",
    "cfg.ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "\n",
    "# cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_rawframe/test/'\n",
    "\n",
    "# cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_rawframe/train/'\n",
    "\n",
    "# cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_rawframe/val/'\n",
    "\n",
    "cfg.data.test.modality = 'Flow'\n",
    "cfg.data.val.modality = 'Flow'\n",
    "cfg.data.train.modality = 'Flow'\n",
    "\n",
    "cfg.data.train.start_index = 0\n",
    "cfg.data.test.start_index = 0\n",
    "cfg.data.val.start_index = 0\n",
    "\n",
    "cfg.data.test.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.train.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.val.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "# cfg.load_from = 'checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/CSN-no-transfer-d50'\n",
    "\n",
    "cfg.img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
    "\n",
    "\n",
    "cfg.val_pipeline = [\n",
    "    dict(\n",
    "        type='SampleFrames',\n",
    "        clip_len=32,\n",
    "        frame_interval=2,\n",
    "        num_clips=1,\n",
    "        test_mode=True),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "#     dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "#     dict(type='Flip', flip_ratio=0.5)\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=10, test_mode=True),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='RandomCrop', size=224),\n",
    "    dict(type='RandomResizedCrop'),\n",
    "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "#     dict(type='Flip', flip_ratio=0.5),\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
    "]\n",
    "\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.val.pipeline = cfg.val_pipeline\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "# cfg.data.videos_per_gpu = 24\n",
    "# cfg.optimizer.type = 'Adam'\n",
    "# cfg.optimizer.weight_decay=0.0001\n",
    "\n",
    "# cfg.optimizer_config.grad_clip=None\n",
    "# cfg.optimizer.lr = 0.01\n",
    "\n",
    "# cfg.lr_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(10, 1e-5),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "cfg.total_epochs = 200\n",
    "\n",
    "# cfg.momentum_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(0.85 / 0.95, 1),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 20\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.data.videos_per_gpu=8\n",
    "\n",
    "cfg.model.backbone.in_channels = 2\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "boring-reality",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-08 16:09:38,142 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /media/actrec/DATA/.virtualenvs/mmaction/mmaction2/childact-checkpoints/CSN-no-transfer\n",
      "2021-05-08 16:09:38,143 - mmaction - INFO - workflow: [('train', 1)], max: 200 epochs\n",
      "/media/actrec/DATA/.virtualenvs/mmaction/mmaction2/mmaction/core/evaluation/eval_hooks.py:131: UserWarning: runner.meta is None. Creating a empty one.\n",
      "  warnings.warn('runner.meta is None. Creating a empty one.')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-be92e24cff32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Create work_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir_or_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/actrec/DATA/.virtualenvs/mmaction/mmaction2/mmaction/apis/train.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0momnisource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mrunner_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrunner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/mmaction/lib/python3.6/site-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                     \u001b[0mepoch_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait for some hooks like loggers to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mmaction/lib/python3.6/site-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mmaction/lib/python3.6/site-packages/mmcv/runner/base_runner.py\u001b[0m in \u001b[0;36mcall_hook\u001b[0;34m(self, fn_name)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mmaction/lib/python3.6/site-packages/mmcv/runner/hooks/optimizer.py\u001b[0m in \u001b[0;36mafter_train_iter\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mafter_train_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_clip\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mmaction/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mmaction/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indonesian-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model100e\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "early-enlargement",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "import pickle\n",
    "import mmcv\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "model = pickle.load(open(f\"{cfg.work_dir}/model100e\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "independent-horizontal",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 0.5 task/s, elapsed: 278s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.5238\n",
      "top5_acc\t0.9683\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.5238\n",
      "top1_acc: 0.5238\n",
      "top5_acc: 0.9683\n",
      "mean_class_accuracy: 0.5238\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmaction.models import build_model\n",
    "from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=4,\n",
    "        workers_per_gpu=1,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "shaped-breathing",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'], yticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/open-mmlab/mmaction2/blob/master/demo/mmaction2_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcjSRFELVbNk",
    "tags": []
   },
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Bf8PpPXtVvmg",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2c685a33-474b-4e71-8f98-c2533c66095e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2017 NVIDIA Corporation\n",
      "Built on Fri_Nov__3_21:07:56_CDT_2017\n",
      "Cuda compilation tools, release 9.1, V9.1.85\n",
      "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "Copyright (C) 2017 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check nvcc version\n",
    "!nvcc -V\n",
    "# Check GCC version\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "5PAJ4ArzV5Ry",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "e48dbf61-fae0-431c-e964-04c7caaee4bc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting av\n",
      "  Downloading av-8.0.3-cp36-cp36m-manylinux2010_x86_64.whl (37.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.2 MB 19.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting decord>=0.4.1\n",
      "  Downloading decord-0.5.2-py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 55.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imgaug\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "\u001b[K     |████████████████████████████████| 948 kB 52.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting librosa\n",
      "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
      "\u001b[K     |████████████████████████████████| 183 kB 55.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lmdb\n",
      "  Downloading lmdb-1.1.1-cp36-cp36m-manylinux2010_x86_64.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 53.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "\u001b[K     |████████████████████████████████| 388 kB 55.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting onnx\n",
      "  Downloading onnx-1.8.1-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 49.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting onnxruntime\n",
      "  Downloading onnxruntime-1.7.0-cp36-cp36m-manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.1 MB 57.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyTurboJPEG\n",
      "  Downloading PyTurboJPEG-1.4.1.tar.gz (6.8 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from decord>=0.4.1->-r requirements/optional.txt (line 2)) (1.19.5)\n",
      "Requirement already satisfied: Pillow in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from imgaug->-r requirements/optional.txt (line 3)) (8.1.2)\n",
      "Requirement already satisfied: scipy in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.5.4)\n",
      "Requirement already satisfied: six in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from imgaug->-r requirements/optional.txt (line 3)) (1.15.0)\n",
      "Collecting scikit-image>=0.14.2\n",
      "  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 48.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Shapely\n",
      "  Downloading Shapely-1.7.1-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 52.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from imgaug->-r requirements/optional.txt (line 3)) (3.3.4)\n",
      "Requirement already satisfied: opencv-python in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from imgaug->-r requirements/optional.txt (line 3)) (4.5.1.48)\n",
      "Collecting imageio\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 52.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 54.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 52.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.0\n",
      "  Downloading networkx-2.5-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 54.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from matplotlib->imgaug->-r requirements/optional.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug->-r requirements/optional.txt (line 3)) (4.4.2)\n",
      "Collecting audioread>=2.0.0\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 59.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from librosa->-r requirements/optional.txt (line 4)) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from librosa->-r requirements/optional.txt (line 4)) (1.0.1)\n",
      "Collecting resampy>=0.2.2\n",
      "  Downloading resampy-0.2.2.tar.gz (323 kB)\n",
      "\u001b[K     |████████████████████████████████| 323 kB 48.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numba>=0.43.0\n",
      "  Downloading numba-0.53.0-cp36-cp36m-manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 52.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soundfile>=0.9.0\n",
      "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Collecting pooch>=1.0\n",
      "  Downloading pooch-1.3.0-py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 704 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from numba>=0.43.0->librosa->-r requirements/optional.txt (line 4)) (54.1.2)\n",
      "Collecting llvmlite<0.37,>=0.36.0rc1\n",
      "  Downloading llvmlite-0.36.0-cp36-cp36m-manylinux2010_x86_64.whl (25.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.3 MB 21.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting appdirs\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 6.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from pooch>=1.0->librosa->-r requirements/optional.txt (line 4)) (20.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa->-r requirements/optional.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from soundfile>=0.9.0->librosa->-r requirements/optional.txt (line 4)) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa->-r requirements/optional.txt (line 4)) (2.20)\n",
      "Collecting tqdm<5.0,>=4.11.2\n",
      "  Downloading tqdm-4.59.0-py2.py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 4.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting proglog<=1.0.0\n",
      "  Downloading proglog-0.1.9.tar.gz (10 kB)\n",
      "Collecting imageio_ffmpeg>=0.2.0\n",
      "  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.9 MB 51.6 MB/s eta 0:00:01    |██████████▋                     | 8.9 MB 51.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 56.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 58.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 49.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /home/actrec/.virtualenvs/mmaction/lib/python3.6/site-packages (from onnx->-r requirements/optional.txt (line 7)) (3.7.4.3)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-3.15.6-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 40.6 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: librosa, audioread, resampy, moviepy, proglog, PyTurboJPEG\n",
      "  Building wheel for librosa (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201375 sha256=fe069194b9c488fb6a8b51522f38d70ad75c030892c462fdc99e6f115f65e0e1\n",
      "  Stored in directory: /home/actrec/.cache/pip/wheels/32/2c/ce/86e49d4769aceba728421c24c0d726054bf4ca01175ff42bdd\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23141 sha256=38e5e456518e00c1d9ff80efb362c336ef42c962b80f8016cca83282b55b3426\n",
      "  Stored in directory: /home/actrec/.cache/pip/wheels/de/14/0a/863e4ed680b3204444cf486733e609d7ff7abe8fceafab67dc\n",
      "  Building wheel for resampy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320718 sha256=f560681a1d7d482839aff325e9bb24ff1e12666ad4e64e356204e9cd79c7d57d\n",
      "  Stored in directory: /home/actrec/.cache/pip/wheels/cf/d4/04/49d8824a42bd9f9b11d502727965b9997f0d41d2b22ae4f645\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110726 sha256=bc58ffbd63a0a37ef2b6e021126aa01c75f077ba5d7a64e55f964f357d2f750e\n",
      "  Stored in directory: /home/actrec/.cache/pip/wheels/be/dc/17/8b4d5a63bcd05dc44db7da57e193372ccd333617293f9deebe\n",
      "  Building wheel for proglog (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for proglog: filename=proglog-0.1.9-py3-none-any.whl size=6147 sha256=35a0fb2b41bd7c297c41a9da6843ff5111cefe91c0c39f8a732849b11414cb50\n",
      "  Stored in directory: /home/actrec/.cache/pip/wheels/e7/11/a0/7e65f734d33043735a557b1244569cca327353db9068158076\n",
      "  Building wheel for PyTurboJPEG (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyTurboJPEG: filename=PyTurboJPEG-1.4.1-py3-none-any.whl size=7002 sha256=04acd2046df87904de861b04d900c0f8e3f2603125683071aaf90bf41e3431a6\n",
      "  Stored in directory: /home/actrec/.cache/pip/wheels/b6/24/6d/fac7e8a57c83908da61db911bc069febee579f903f8b495b17\n",
      "Successfully built librosa audioread resampy moviepy proglog PyTurboJPEG\n",
      "Installing collected packages: urllib3, llvmlite, idna, chardet, certifi, tqdm, tifffile, requests, PyWavelets, numba, networkx, imageio, appdirs, soundfile, Shapely, scikit-image, resampy, protobuf, proglog, pooch, imageio-ffmpeg, audioread, PyTurboJPEG, onnxruntime, onnx, moviepy, lmdb, librosa, imgaug, decord, av\n",
      "Successfully installed PyTurboJPEG-1.4.1 PyWavelets-1.1.1 Shapely-1.7.1 appdirs-1.4.4 audioread-2.1.9 av-8.0.3 certifi-2020.12.5 chardet-4.0.0 decord-0.5.2 idna-2.10 imageio-2.9.0 imageio-ffmpeg-0.4.3 imgaug-0.4.0 librosa-0.8.0 llvmlite-0.36.0 lmdb-1.1.1 moviepy-1.0.3 networkx-2.5 numba-0.53.0 onnx-1.8.1 onnxruntime-1.7.0 pooch-1.3.0 proglog-0.1.9 protobuf-3.15.6 requests-2.25.1 resampy-0.2.2 scikit-image-0.17.2 soundfile-0.10.3.post1 tifffile-2020.9.3 tqdm-4.59.0 urllib3-1.26.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Install some optional requirements\n",
    "# !pip install -r requirements/optional.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "No_zZAFpWC-a",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "1d425eea-d44e-434a-991c-01eb15abaab2",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0+cu110 True\n",
      "0.12.0\n",
      "11.0\n",
      "GCC 7.5\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMAction2 installation\n",
    "import mmaction\n",
    "print(mmaction.__version__)\n",
    "\n",
    "# Check MMCV installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/actrec/.local/lib/python3.6/site-packages/decord-0.5.3-py3.6-linux-x86_64.egg')\n",
    "import decord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/actrec/.virtualenvs/mmaction/mmaction2\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;34mcheckpoints\u001b[0m/\n",
      " \u001b[01;34mconfigs\u001b[0m/\n",
      " \u001b[01;35mdemo.gif\u001b[0m\n",
      " \u001b[01;35mdemo_gradcam.gif\u001b[0m\n",
      " demo_gradcam.py\n",
      " demo.ipynb\n",
      " \u001b[01;32mdemo.mp4\u001b[0m*\n",
      " \u001b[01;35mdemo_out.mp4\u001b[0m\n",
      " demo.py\n",
      " demo_spatiotemporal_det.py\n",
      " faster_rcnn_r50_fpn_2x_coco.py\n",
      " \u001b[01;34mfuse\u001b[0m/\n",
      " label_map_ava.txt\n",
      " label_map_k400.txt\n",
      " long_video_demo.py\n",
      " mmaction2_tutorial.ipynb\n",
      " my-mmaction.ipynb\n",
      " README.md\n",
      "'Split by Folders and Annotation Files creation.ipynb'\n",
      " webcam_demo.py\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# TSN 90.48% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/tsn/tsn_r50_video_1x1x8_100e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "64CW6d_AaT-Q",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-22 01:46:07--  https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_video_1x1x8_100e_kinetics600_rgb/tsn_r50_video_1x1x8_100e_kinetics600_rgb_20201015-4db3c461.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.75.20.25\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.75.20.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 99220779 (95M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/tsn_r50_video_1x1x8_100e_kinetics600_rgb_20201015-4db3c461.pth’\n",
      "\n",
      "checkpoints/tsn_r50 100%[===================>]  94,62M  10,5MB/s    in 11s     \n",
      "\n",
      "2021-03-22 01:46:22 (8,61 MB/s) - ‘checkpoints/tsn_r50_video_1x1x8_100e_kinetics600_rgb_20201015-4db3c461.pth’ saved [99220779/99220779]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir checkpoints\n",
    "# !wget -c https://download.openmmlab.com/   .pth \\\n",
    "#       -O checkpoints/db3c461.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer2D',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        pretrained='torchvision://resnet50',\n",
      "        depth=50,\n",
      "        norm_eval=False),\n",
      "    cls_head=dict(\n",
      "        type='TSNHead',\n",
      "        num_classes=7,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        consensus=dict(type='AvgConsensus', dim=1),\n",
      "        dropout_ratio=0.4,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips=None))\n",
      "optimizer = dict(type='SGD', lr=0.0001, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(policy='step', step=[40, 80])\n",
      "total_epochs = 30\n",
      "checkpoint_config = dict(interval=2)\n",
      "log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = './childact-mm/latest.pth'\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'VideoDataset'\n",
      "data_root = 'data/childact_split/train/'\n",
      "data_root_val = 'data/childact_split/val/'\n",
      "ann_file_train = 'data/childact_split/childact_train_video.txt'\n",
      "ann_file_val = 'data/childact_split/childact_val_video.txt'\n",
      "ann_file_test = 'data/childact_split/childact_test_video.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=8),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(\n",
      "        type='MultiScaleCrop',\n",
      "        input_size=224,\n",
      "        scales=(1, 0.875, 0.75, 0.66),\n",
      "        random_crop=False,\n",
      "        max_wh_scale_gap=1),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=8,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=25,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='ThreeCrop', crop_size=256),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=32,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_train_video.txt',\n",
      "        data_prefix='data/childact_split/train/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames', clip_len=1, frame_interval=1,\n",
      "                num_clips=8),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(\n",
      "                type='MultiScaleCrop',\n",
      "                input_size=224,\n",
      "                scales=(1, 0.875, 0.75, 0.66),\n",
      "                random_crop=False,\n",
      "                max_wh_scale_gap=1),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_val_video.txt',\n",
      "        data_prefix='data/childact_split/val/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=8,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_test_video.txt',\n",
      "        data_prefix='data/childact_split/test/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=25,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='ThreeCrop', crop_size=256),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "work_dir = './childact-mm/'\n",
      "omnisource = False\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_split/train/'\n",
    "cfg.data_root_val = 'data/childact_split/val/'\n",
    "cfg.ann_file_train = 'data/childact_split/childact_train_video.txt'\n",
    "cfg.ann_file_val = 'data/childact_split/childact_val_video.txt'\n",
    "cfg.ann_file_test = 'data/childact_split/childact_test_video.txt'\n",
    "\n",
    "cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_split/childact_test_video.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_split/test/'\n",
    "\n",
    "cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_split/childact_train_video.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_split/train/'\n",
    "\n",
    "cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_split/childact_val_video.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_split/val/'\n",
    "\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "# cfg.load_from = './checkpoints/best_top1_acc_epoch_5.pth'\n",
    "cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-mm/'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.data.videos_per_gpu = 32\n",
    "cfg.optimizer.lr = 0.0001\n",
    "# cfg.lr_config.type = 'cyclic'\n",
    "cfg.total_epochs = 30\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 2\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 10\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tES-qnZ3k38Z"
   },
   "source": [
    "### Train a new recognizer\n",
    "\n",
    "Finally, lets initialize the dataset and recognizer, then train a new recognizer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 16:04:14,045 - mmaction - INFO - These parameters in pretrained checkpoint are not loaded: {'fc.bias', 'fc.weight'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_torchvision loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 16:04:16,416 - mmaction - INFO - load checkpoint from ./childact-mm/latest.pth\n",
      "2021-03-22 16:04:16,417 - mmaction - INFO - Use load_from_local loader\n",
      "2021-03-22 16:04:16,539 - mmaction - INFO - resumed epoch 12, iter 561\n",
      "2021-03-22 16:04:16,541 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /home/actrec/.virtualenvs/mmaction/mmaction2/childact-mm\n",
      "2021-03-22 16:04:16,542 - mmaction - INFO - workflow: [('train', 1)], max: 30 epochs\n",
      "/home/actrec/.virtualenvs/mmaction/mmaction2/mmaction/core/evaluation/eval_hooks.py:131: UserWarning: runner.meta is None. Creating a empty one.\n",
      "  warnings.warn('runner.meta is None. Creating a empty one.')\n",
      "2021-03-22 16:05:56,931 - mmaction - INFO - Epoch [13][10/33]\tlr: 5.000e-04, eta: 1:10:06, time: 10.039, data_time: 9.158, memory: 21448, top1_acc: 0.9375, top5_acc: 1.0000, loss_cls: 0.2199, loss: 0.2199, grad_norm: 3.0833\n",
      "2021-03-22 16:07:05,519 - mmaction - INFO - Epoch [13][20/33]\tlr: 5.000e-04, eta: 0:57:35, time: 6.859, data_time: 5.968, memory: 21448, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.2856, loss: 0.2856, grad_norm: 3.9159\n",
      "2021-03-22 16:08:40,494 - mmaction - INFO - Epoch [13][30/33]\tlr: 5.000e-04, eta: 0:58:30, time: 9.498, data_time: 8.622, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.2845, loss: 0.2845, grad_norm: 3.6887\n",
      "2021-03-22 16:10:45,688 - mmaction - INFO - Epoch [14][10/33]\tlr: 5.000e-04, eta: 0:55:00, time: 10.373, data_time: 9.495, memory: 21448, top1_acc: 0.9375, top5_acc: 1.0000, loss_cls: 0.2317, loss: 0.2317, grad_norm: 3.2582\n",
      "2021-03-22 16:11:54,243 - mmaction - INFO - Epoch [14][20/33]\tlr: 5.000e-04, eta: 0:51:34, time: 6.856, data_time: 5.979, memory: 21448, top1_acc: 0.8969, top5_acc: 1.0000, loss_cls: 0.2885, loss: 0.2885, grad_norm: 3.9673\n",
      "2021-03-22 16:13:30,616 - mmaction - INFO - Epoch [14][30/33]\tlr: 5.000e-04, eta: 0:51:34, time: 9.637, data_time: 8.756, memory: 21448, top1_acc: 0.9219, top5_acc: 1.0000, loss_cls: 0.2582, loss: 0.2582, grad_norm: 3.7690\n",
      "2021-03-22 16:13:46,849 - mmaction - INFO - Saving checkpoint at 14 epochs\n",
      "2021-03-22 16:15:31,371 - mmaction - INFO - Epoch [15][10/33]\tlr: 5.000e-04, eta: 0:49:17, time: 10.422, data_time: 9.546, memory: 21448, top1_acc: 0.9156, top5_acc: 1.0000, loss_cls: 0.2607, loss: 0.2607, grad_norm: 3.9742\n",
      "2021-03-22 16:16:36,546 - mmaction - INFO - Epoch [15][20/33]\tlr: 5.000e-04, eta: 0:46:39, time: 6.518, data_time: 5.645, memory: 21448, top1_acc: 0.8906, top5_acc: 1.0000, loss_cls: 0.2774, loss: 0.2774, grad_norm: 4.2109\n",
      "2021-03-22 16:18:12,739 - mmaction - INFO - Epoch [15][30/33]\tlr: 5.000e-04, eta: 0:46:08, time: 9.619, data_time: 8.747, memory: 21448, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2686, loss: 0.2686, grad_norm: 4.0837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 3.5 task/s, elapsed: 35s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 16:19:08,703 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-22 16:19:08,705 - mmaction - INFO - \n",
      "top1_acc\t0.8492\n",
      "top5_acc\t1.0000\n",
      "2021-03-22 16:19:08,706 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-22 16:19:08,707 - mmaction - INFO - \n",
      "mean_acc\t0.8492\n",
      "2021-03-22 16:19:09,000 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_15.pth.\n",
      "2021-03-22 16:19:09,001 - mmaction - INFO - Best top1_acc is 0.8492 at 15 epoch.\n",
      "2021-03-22 16:19:09,002 - mmaction - INFO - Epoch(val) [15][33]\ttop1_acc: 0.8492, top5_acc: 1.0000, mean_class_accuracy: 0.8492\n",
      "2021-03-22 16:20:54,290 - mmaction - INFO - Epoch [16][10/33]\tlr: 5.000e-04, eta: 0:44:12, time: 10.529, data_time: 9.656, memory: 21448, top1_acc: 0.8656, top5_acc: 1.0000, loss_cls: 0.3135, loss: 0.3135, grad_norm: 5.0392\n",
      "2021-03-22 16:22:01,583 - mmaction - INFO - Epoch [16][20/33]\tlr: 5.000e-04, eta: 0:42:08, time: 6.729, data_time: 5.830, memory: 21448, top1_acc: 0.9094, top5_acc: 0.9969, loss_cls: 0.2887, loss: 0.2887, grad_norm: 4.6742\n",
      "2021-03-22 16:23:36,416 - mmaction - INFO - Epoch [16][30/33]\tlr: 5.000e-04, eta: 0:41:18, time: 9.483, data_time: 8.587, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.2946, loss: 0.2946, grad_norm: 4.6754\n",
      "2021-03-22 16:23:49,993 - mmaction - INFO - Saving checkpoint at 16 epochs\n",
      "2021-03-22 16:25:33,204 - mmaction - INFO - Epoch [17][10/33]\tlr: 5.000e-04, eta: 0:39:21, time: 10.292, data_time: 9.408, memory: 21448, top1_acc: 0.8656, top5_acc: 1.0000, loss_cls: 0.3344, loss: 0.3344, grad_norm: 4.8666\n",
      "2021-03-22 16:26:46,080 - mmaction - INFO - Epoch [17][20/33]\tlr: 5.000e-04, eta: 0:37:42, time: 7.288, data_time: 6.408, memory: 21448, top1_acc: 0.9344, top5_acc: 1.0000, loss_cls: 0.2459, loss: 0.2459, grad_norm: 4.0389\n",
      "2021-03-22 16:28:21,720 - mmaction - INFO - Epoch [17][30/33]\tlr: 5.000e-04, eta: 0:36:43, time: 9.564, data_time: 8.689, memory: 21448, top1_acc: 0.8844, top5_acc: 1.0000, loss_cls: 0.3178, loss: 0.3178, grad_norm: 4.5435\n",
      "2021-03-22 16:30:33,123 - mmaction - INFO - Epoch [18][10/33]\tlr: 5.000e-04, eta: 0:34:58, time: 10.863, data_time: 9.958, memory: 21448, top1_acc: 0.9219, top5_acc: 1.0000, loss_cls: 0.2423, loss: 0.2423, grad_norm: 3.7765\n",
      "2021-03-22 16:31:40,469 - mmaction - INFO - Epoch [18][20/33]\tlr: 5.000e-04, eta: 0:33:15, time: 6.735, data_time: 5.828, memory: 21448, top1_acc: 0.9187, top5_acc: 1.0000, loss_cls: 0.2488, loss: 0.2488, grad_norm: 3.7101\n",
      "2021-03-22 16:33:15,571 - mmaction - INFO - Epoch [18][30/33]\tlr: 5.000e-04, eta: 0:32:09, time: 9.510, data_time: 8.597, memory: 21448, top1_acc: 0.9281, top5_acc: 1.0000, loss_cls: 0.2478, loss: 0.2478, grad_norm: 3.9696\n",
      "2021-03-22 16:33:38,128 - mmaction - INFO - Saving checkpoint at 18 epochs\n",
      "2021-03-22 16:35:26,146 - mmaction - INFO - Epoch [19][10/33]\tlr: 5.000e-04, eta: 0:30:23, time: 10.771, data_time: 9.890, memory: 21448, top1_acc: 0.9281, top5_acc: 1.0000, loss_cls: 0.2272, loss: 0.2272, grad_norm: 4.1818\n",
      "2021-03-22 16:36:30,975 - mmaction - INFO - Epoch [19][20/33]\tlr: 5.000e-04, eta: 0:28:43, time: 6.483, data_time: 5.602, memory: 21448, top1_acc: 0.9094, top5_acc: 1.0000, loss_cls: 0.2351, loss: 0.2351, grad_norm: 4.1198\n",
      "2021-03-22 16:38:01,164 - mmaction - INFO - Epoch [19][30/33]\tlr: 5.000e-04, eta: 0:27:29, time: 9.019, data_time: 8.134, memory: 21448, top1_acc: 0.9281, top5_acc: 1.0000, loss_cls: 0.2176, loss: 0.2176, grad_norm: 3.7628\n",
      "2021-03-22 16:40:05,490 - mmaction - INFO - Epoch [20][10/33]\tlr: 5.000e-04, eta: 0:25:38, time: 10.189, data_time: 9.315, memory: 21448, top1_acc: 0.8906, top5_acc: 1.0000, loss_cls: 0.3233, loss: 0.3233, grad_norm: 4.8384\n",
      "2021-03-22 16:41:11,675 - mmaction - INFO - Epoch [20][20/33]\tlr: 5.000e-04, eta: 0:24:05, time: 6.619, data_time: 5.745, memory: 21448, top1_acc: 0.9062, top5_acc: 1.0000, loss_cls: 0.2407, loss: 0.2407, grad_norm: 4.3140\n",
      "2021-03-22 16:42:46,974 - mmaction - INFO - Epoch [20][30/33]\tlr: 5.000e-04, eta: 0:22:53, time: 9.530, data_time: 8.654, memory: 21448, top1_acc: 0.9031, top5_acc: 1.0000, loss_cls: 0.2469, loss: 0.2469, grad_norm: 3.9892\n",
      "2021-03-22 16:43:06,859 - mmaction - INFO - Saving checkpoint at 20 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 3.5 task/s, elapsed: 36s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 16:43:42,967 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-22 16:43:42,969 - mmaction - INFO - \n",
      "top1_acc\t0.8571\n",
      "top5_acc\t1.0000\n",
      "2021-03-22 16:43:42,970 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-22 16:43:42,971 - mmaction - INFO - \n",
      "mean_acc\t0.8571\n",
      "2021-03-22 16:43:43,294 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_20.pth.\n",
      "2021-03-22 16:43:43,295 - mmaction - INFO - Best top1_acc is 0.8571 at 20 epoch.\n",
      "2021-03-22 16:43:43,296 - mmaction - INFO - Epoch(val) [20][33]\ttop1_acc: 0.8571, top5_acc: 1.0000, mean_class_accuracy: 0.8571\n",
      "2021-03-22 16:45:20,813 - mmaction - INFO - Epoch [21][10/33]\tlr: 5.000e-04, eta: 0:21:02, time: 9.751, data_time: 8.872, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.2959, loss: 0.2959, grad_norm: 5.2473\n",
      "2021-03-22 16:46:30,437 - mmaction - INFO - Epoch [21][20/33]\tlr: 5.000e-04, eta: 0:19:34, time: 6.962, data_time: 6.085, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.2686, loss: 0.2686, grad_norm: 4.9177\n",
      "2021-03-22 16:48:02,045 - mmaction - INFO - Epoch [21][30/33]\tlr: 5.000e-04, eta: 0:18:18, time: 9.161, data_time: 8.283, memory: 21448, top1_acc: 0.9031, top5_acc: 1.0000, loss_cls: 0.3019, loss: 0.3019, grad_norm: 4.7605\n",
      "2021-03-22 16:50:06,699 - mmaction - INFO - Epoch [22][10/33]\tlr: 5.000e-04, eta: 0:16:30, time: 10.034, data_time: 9.160, memory: 21448, top1_acc: 0.8688, top5_acc: 1.0000, loss_cls: 0.3052, loss: 0.3052, grad_norm: 5.0368\n",
      "2021-03-22 16:51:13,408 - mmaction - INFO - Epoch [22][20/33]\tlr: 5.000e-04, eta: 0:15:04, time: 6.671, data_time: 5.797, memory: 21448, top1_acc: 0.9094, top5_acc: 1.0000, loss_cls: 0.2709, loss: 0.2709, grad_norm: 5.0456\n",
      "2021-03-22 16:52:45,713 - mmaction - INFO - Epoch [22][30/33]\tlr: 5.000e-04, eta: 0:13:47, time: 9.230, data_time: 8.352, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.3308, loss: 0.3308, grad_norm: 5.8989\n",
      "2021-03-22 16:53:09,991 - mmaction - INFO - Saving checkpoint at 22 epochs\n",
      "2021-03-22 16:54:55,630 - mmaction - INFO - Epoch [23][10/33]\tlr: 5.000e-04, eta: 0:12:01, time: 10.536, data_time: 9.659, memory: 21448, top1_acc: 0.8781, top5_acc: 1.0000, loss_cls: 0.2764, loss: 0.2764, grad_norm: 4.5259\n",
      "2021-03-22 16:56:03,253 - mmaction - INFO - Epoch [23][20/33]\tlr: 5.000e-04, eta: 0:10:37, time: 6.762, data_time: 5.851, memory: 21448, top1_acc: 0.9187, top5_acc: 1.0000, loss_cls: 0.2443, loss: 0.2443, grad_norm: 4.7793\n",
      "2021-03-22 16:57:41,139 - mmaction - INFO - Epoch [23][30/33]\tlr: 5.000e-04, eta: 0:09:20, time: 9.789, data_time: 8.896, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.2643, loss: 0.2643, grad_norm: 4.7593\n",
      "2021-03-22 16:59:43,807 - mmaction - INFO - Epoch [24][10/33]\tlr: 5.000e-04, eta: 0:07:33, time: 10.066, data_time: 9.187, memory: 21448, top1_acc: 0.8844, top5_acc: 0.9969, loss_cls: 0.2928, loss: 0.2928, grad_norm: 4.9920\n",
      "2021-03-22 17:00:52,804 - mmaction - INFO - Epoch [24][20/33]\tlr: 5.000e-04, eta: 0:06:11, time: 6.900, data_time: 6.024, memory: 21448, top1_acc: 0.9094, top5_acc: 0.9969, loss_cls: 0.2648, loss: 0.2648, grad_norm: 4.4870\n",
      "2021-03-22 17:02:26,723 - mmaction - INFO - Epoch [24][30/33]\tlr: 5.000e-04, eta: 0:04:51, time: 9.392, data_time: 8.515, memory: 21448, top1_acc: 0.8938, top5_acc: 0.9969, loss_cls: 0.2742, loss: 0.2742, grad_norm: 4.9958\n",
      "2021-03-22 17:02:48,610 - mmaction - INFO - Saving checkpoint at 24 epochs\n",
      "2021-03-22 17:04:31,720 - mmaction - INFO - Epoch [25][10/33]\tlr: 5.000e-04, eta: 0:03:06, time: 10.283, data_time: 9.394, memory: 21448, top1_acc: 0.9125, top5_acc: 1.0000, loss_cls: 0.2537, loss: 0.2537, grad_norm: 4.5034\n",
      "2021-03-22 17:05:39,963 - mmaction - INFO - Epoch [25][20/33]\tlr: 5.000e-04, eta: 0:01:44, time: 6.824, data_time: 5.936, memory: 21448, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.2804, loss: 0.2804, grad_norm: 4.7272\n",
      "2021-03-22 17:07:15,466 - mmaction - INFO - Epoch [25][30/33]\tlr: 5.000e-04, eta: 0:00:24, time: 9.550, data_time: 8.677, memory: 21448, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2522, loss: 0.2522, grad_norm: 4.5856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 3.5 task/s, elapsed: 36s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 17:08:12,494 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-22 17:08:12,496 - mmaction - INFO - \n",
      "top1_acc\t0.8571\n",
      "top5_acc\t1.0000\n",
      "2021-03-22 17:08:12,496 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-22 17:08:12,497 - mmaction - INFO - \n",
      "mean_acc\t0.8571\n",
      "2021-03-22 17:08:12,497 - mmaction - INFO - Epoch(val) [25][33]\ttop1_acc: 0.8571, top5_acc: 1.0000, mean_class_accuracy: 0.8571\n",
      "2021-03-22 17:09:53,555 - mmaction - INFO - Epoch [26][10/33]\tlr: 5.000e-04, eta: -1 day, 23:58:40, time: 10.105, data_time: 9.229, memory: 21448, top1_acc: 0.8969, top5_acc: 1.0000, loss_cls: 0.2787, loss: 0.2787, grad_norm: 4.8332\n",
      "2021-03-22 17:11:02,020 - mmaction - INFO - Epoch [26][20/33]\tlr: 5.000e-04, eta: -1 day, 23:57:19, time: 6.847, data_time: 5.975, memory: 21448, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2513, loss: 0.2513, grad_norm: 5.1216\n",
      "2021-03-22 17:12:38,741 - mmaction - INFO - Epoch [26][30/33]\tlr: 5.000e-04, eta: -1 day, 23:55:57, time: 9.672, data_time: 8.776, memory: 21448, top1_acc: 0.8812, top5_acc: 1.0000, loss_cls: 0.2711, loss: 0.2711, grad_norm: 5.1664\n",
      "2021-03-22 17:12:58,372 - mmaction - INFO - Saving checkpoint at 26 epochs\n",
      "2021-03-22 17:14:39,326 - mmaction - INFO - Epoch [27][10/33]\tlr: 5.000e-04, eta: -1 day, 23:54:12, time: 10.068, data_time: 9.185, memory: 21448, top1_acc: 0.9125, top5_acc: 1.0000, loss_cls: 0.2284, loss: 0.2284, grad_norm: 4.4295\n",
      "2021-03-22 17:15:48,990 - mmaction - INFO - Epoch [27][20/33]\tlr: 5.000e-04, eta: -1 day, 23:52:53, time: 6.966, data_time: 6.081, memory: 21448, top1_acc: 0.8906, top5_acc: 1.0000, loss_cls: 0.2763, loss: 0.2763, grad_norm: 4.5929\n",
      "2021-03-22 17:17:19,566 - mmaction - INFO - Epoch [27][30/33]\tlr: 5.000e-04, eta: -1 day, 23:51:31, time: 9.058, data_time: 8.169, memory: 21448, top1_acc: 0.9062, top5_acc: 1.0000, loss_cls: 0.2449, loss: 0.2449, grad_norm: 5.1436\n",
      "2021-03-22 17:19:25,203 - mmaction - INFO - Epoch [28][10/33]\tlr: 5.000e-04, eta: -1 day, 23:49:46, time: 10.396, data_time: 9.516, memory: 21448, top1_acc: 0.8844, top5_acc: 1.0000, loss_cls: 0.2822, loss: 0.2822, grad_norm: 5.1844\n",
      "2021-03-22 17:20:36,427 - mmaction - INFO - Epoch [28][20/33]\tlr: 5.000e-04, eta: -1 day, 23:48:27, time: 7.122, data_time: 6.221, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.2617, loss: 0.2617, grad_norm: 4.6933\n",
      "2021-03-22 17:22:09,101 - mmaction - INFO - Epoch [28][30/33]\tlr: 5.000e-04, eta: -1 day, 23:47:04, time: 9.267, data_time: 8.391, memory: 21448, top1_acc: 0.8781, top5_acc: 1.0000, loss_cls: 0.2761, loss: 0.2761, grad_norm: 5.3211\n",
      "2021-03-22 17:22:29,398 - mmaction - INFO - Saving checkpoint at 28 epochs\n",
      "2021-03-22 17:24:12,905 - mmaction - INFO - Epoch [29][10/33]\tlr: 5.000e-04, eta: -1 day, 23:45:19, time: 10.320, data_time: 9.411, memory: 21448, top1_acc: 0.8906, top5_acc: 1.0000, loss_cls: 0.2990, loss: 0.2990, grad_norm: 5.5218\n",
      "2021-03-22 17:25:21,920 - mmaction - INFO - Epoch [29][20/33]\tlr: 5.000e-04, eta: -1 day, 23:44:01, time: 6.902, data_time: 6.019, memory: 21448, top1_acc: 0.8719, top5_acc: 1.0000, loss_cls: 0.2904, loss: 0.2904, grad_norm: 5.0257\n",
      "2021-03-22 17:26:59,871 - mmaction - INFO - Epoch [29][30/33]\tlr: 5.000e-04, eta: -1 day, 23:42:36, time: 9.795, data_time: 8.907, memory: 21448, top1_acc: 0.9031, top5_acc: 1.0000, loss_cls: 0.2559, loss: 0.2559, grad_norm: 5.4150\n",
      "2021-03-22 17:28:54,465 - mmaction - INFO - Epoch [30][10/33]\tlr: 5.000e-04, eta: -1 day, 23:40:52, time: 10.129, data_time: 9.256, memory: 21448, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2891, loss: 0.2891, grad_norm: 6.1167\n",
      "2021-03-22 17:30:05,159 - mmaction - INFO - Epoch [30][20/33]\tlr: 5.000e-04, eta: -1 day, 23:39:33, time: 7.069, data_time: 6.184, memory: 21448, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.2935, loss: 0.2935, grad_norm: 5.4480\n",
      "2021-03-22 17:31:41,483 - mmaction - INFO - Epoch [30][30/33]\tlr: 5.000e-04, eta: -1 day, 23:38:08, time: 9.632, data_time: 8.729, memory: 21448, top1_acc: 0.9375, top5_acc: 1.0000, loss_cls: 0.2138, loss: 0.2138, grad_norm: 4.4516\n",
      "2021-03-22 17:32:03,974 - mmaction - INFO - Saving checkpoint at 30 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 3.5 task/s, elapsed: 36s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 17:32:40,845 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-22 17:32:40,847 - mmaction - INFO - \n",
      "top1_acc\t0.8413\n",
      "top5_acc\t1.0000\n",
      "2021-03-22 17:32:40,848 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-22 17:32:40,849 - mmaction - INFO - \n",
      "mean_acc\t0.8413\n",
      "2021-03-22 17:32:40,850 - mmaction - INFO - Epoch(val) [30][33]\ttop1_acc: 0.8413, top5_acc: 1.0000, mean_class_accuracy: 0.8413\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryVoSfZVmogw",
    "tags": []
   },
   "source": [
    "## Test the trained recognizer\n",
    "\n",
    "After finetuning the recognizer, let's check the prediction results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 2.1 task/s, elapsed: 59s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.9048\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.9048\n",
      "top1_acc: 0.9048\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.9048\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=16,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SlowFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "64CW6d_AaT-Q",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-22 01:46:07--  https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_video_1x1x8_100e_kinetics600_rgb/tsn_r50_video_1x1x8_100e_kinetics600_rgb_20201015-4db3c461.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.75.20.25\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.75.20.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 99220779 (95M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/tsn_r50_video_1x1x8_100e_kinetics600_rgb_20201015-4db3c461.pth’\n",
      "\n",
      "checkpoints/tsn_r50 100%[===================>]  94,62M  10,5MB/s    in 11s     \n",
      "\n",
      "2021-03-22 01:46:22 (8,61 MB/s) - ‘checkpoints/tsn_r50_video_1x1x8_100e_kinetics600_rgb_20201015-4db3c461.pth’ saved [99220779/99220779]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/   .pth \\\n",
    "      -O checkpoints/db3c461.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/tsn/tsn_r50_video_1x1x8_100e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tc8YhFFGjp3e"
   },
   "source": [
    "Given a config that trains a TSN model on kinetics400-full dataset, we need to modify some values to use it for training TSN on Kinetics400-tiny dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer2D',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        pretrained='torchvision://resnet50',\n",
      "        depth=50,\n",
      "        norm_eval=False),\n",
      "    cls_head=dict(\n",
      "        type='TSNHead',\n",
      "        num_classes=7,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        consensus=dict(type='AvgConsensus', dim=1),\n",
      "        dropout_ratio=0.4,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips=None))\n",
      "optimizer = dict(type='SGD', lr=0.0001, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(policy='step', step=[40, 80])\n",
      "total_epochs = 30\n",
      "checkpoint_config = dict(interval=2)\n",
      "log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = './childact-mm/latest.pth'\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'VideoDataset'\n",
      "data_root = 'data/childact_split/train/'\n",
      "data_root_val = 'data/childact_split/val/'\n",
      "ann_file_train = 'data/childact_split/childact_train_video.txt'\n",
      "ann_file_val = 'data/childact_split/childact_val_video.txt'\n",
      "ann_file_test = 'data/childact_split/childact_test_video.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=8),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(\n",
      "        type='MultiScaleCrop',\n",
      "        input_size=224,\n",
      "        scales=(1, 0.875, 0.75, 0.66),\n",
      "        random_crop=False,\n",
      "        max_wh_scale_gap=1),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=8,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=25,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='ThreeCrop', crop_size=256),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=32,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_train_video.txt',\n",
      "        data_prefix='data/childact_split/train/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames', clip_len=1, frame_interval=1,\n",
      "                num_clips=8),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(\n",
      "                type='MultiScaleCrop',\n",
      "                input_size=224,\n",
      "                scales=(1, 0.875, 0.75, 0.66),\n",
      "                random_crop=False,\n",
      "                max_wh_scale_gap=1),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_val_video.txt',\n",
      "        data_prefix='data/childact_split/val/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=8,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_test_video.txt',\n",
      "        data_prefix='data/childact_split/test/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=25,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='ThreeCrop', crop_size=256),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "work_dir = './childact-mm/'\n",
      "omnisource = False\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_split/train/'\n",
    "cfg.data_root_val = 'data/childact_split/val/'\n",
    "cfg.ann_file_train = 'data/childact_split/childact_train_video.txt'\n",
    "cfg.ann_file_val = 'data/childact_split/childact_val_video.txt'\n",
    "cfg.ann_file_test = 'data/childact_split/childact_test_video.txt'\n",
    "\n",
    "cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_split/childact_test_video.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_split/test/'\n",
    "\n",
    "cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_split/childact_train_video.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_split/train/'\n",
    "\n",
    "cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_split/childact_val_video.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_split/val/'\n",
    "\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "# cfg.load_from = './checkpoints/best_top1_acc_epoch_5.pth'\n",
    "cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-mm/'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.data.videos_per_gpu = 32\n",
    "cfg.optimizer.lr = 0.0001\n",
    "# cfg.lr_config.type = 'cyclic'\n",
    "cfg.total_epochs = 30\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 2\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 10\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tES-qnZ3k38Z"
   },
   "source": [
    "### Train a new recognizer\n",
    "\n",
    "Finally, lets initialize the dataset and recognizer, then train a new recognizer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 16:04:14,045 - mmaction - INFO - These parameters in pretrained checkpoint are not loaded: {'fc.bias', 'fc.weight'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_torchvision loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 16:04:16,416 - mmaction - INFO - load checkpoint from ./childact-mm/latest.pth\n",
      "2021-03-22 16:04:16,417 - mmaction - INFO - Use load_from_local loader\n",
      "2021-03-22 16:04:16,539 - mmaction - INFO - resumed epoch 12, iter 561\n",
      "2021-03-22 16:04:16,541 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /home/actrec/.virtualenvs/mmaction/mmaction2/childact-mm\n",
      "2021-03-22 16:04:16,542 - mmaction - INFO - workflow: [('train', 1)], max: 30 epochs\n",
      "/home/actrec/.virtualenvs/mmaction/mmaction2/mmaction/core/evaluation/eval_hooks.py:131: UserWarning: runner.meta is None. Creating a empty one.\n",
      "  warnings.warn('runner.meta is None. Creating a empty one.')\n",
      "2021-03-22 16:05:56,931 - mmaction - INFO - Epoch [13][10/33]\tlr: 5.000e-04, eta: 1:10:06, time: 10.039, data_time: 9.158, memory: 21448, top1_acc: 0.9375, top5_acc: 1.0000, loss_cls: 0.2199, loss: 0.2199, grad_norm: 3.0833\n",
      "2021-03-22 16:07:05,519 - mmaction - INFO - Epoch [13][20/33]\tlr: 5.000e-04, eta: 0:57:35, time: 6.859, data_time: 5.968, memory: 21448, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.2856, loss: 0.2856, grad_norm: 3.9159\n",
      "2021-03-22 16:08:40,494 - mmaction - INFO - Epoch [13][30/33]\tlr: 5.000e-04, eta: 0:58:30, time: 9.498, data_time: 8.622, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.2845, loss: 0.2845, grad_norm: 3.6887\n",
      "2021-03-22 16:10:45,688 - mmaction - INFO - Epoch [14][10/33]\tlr: 5.000e-04, eta: 0:55:00, time: 10.373, data_time: 9.495, memory: 21448, top1_acc: 0.9375, top5_acc: 1.0000, loss_cls: 0.2317, loss: 0.2317, grad_norm: 3.2582\n",
      "2021-03-22 16:11:54,243 - mmaction - INFO - Epoch [14][20/33]\tlr: 5.000e-04, eta: 0:51:34, time: 6.856, data_time: 5.979, memory: 21448, top1_acc: 0.8969, top5_acc: 1.0000, loss_cls: 0.2885, loss: 0.2885, grad_norm: 3.9673\n",
      "2021-03-22 16:13:30,616 - mmaction - INFO - Epoch [14][30/33]\tlr: 5.000e-04, eta: 0:51:34, time: 9.637, data_time: 8.756, memory: 21448, top1_acc: 0.9219, top5_acc: 1.0000, loss_cls: 0.2582, loss: 0.2582, grad_norm: 3.7690\n",
      "2021-03-22 16:13:46,849 - mmaction - INFO - Saving checkpoint at 14 epochs\n",
      "2021-03-22 16:15:31,371 - mmaction - INFO - Epoch [15][10/33]\tlr: 5.000e-04, eta: 0:49:17, time: 10.422, data_time: 9.546, memory: 21448, top1_acc: 0.9156, top5_acc: 1.0000, loss_cls: 0.2607, loss: 0.2607, grad_norm: 3.9742\n",
      "2021-03-22 16:16:36,546 - mmaction - INFO - Epoch [15][20/33]\tlr: 5.000e-04, eta: 0:46:39, time: 6.518, data_time: 5.645, memory: 21448, top1_acc: 0.8906, top5_acc: 1.0000, loss_cls: 0.2774, loss: 0.2774, grad_norm: 4.2109\n",
      "2021-03-22 16:18:12,739 - mmaction - INFO - Epoch [15][30/33]\tlr: 5.000e-04, eta: 0:46:08, time: 9.619, data_time: 8.747, memory: 21448, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2686, loss: 0.2686, grad_norm: 4.0837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 3.5 task/s, elapsed: 35s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 16:19:08,703 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-22 16:19:08,705 - mmaction - INFO - \n",
      "top1_acc\t0.8492\n",
      "top5_acc\t1.0000\n",
      "2021-03-22 16:19:08,706 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-22 16:19:08,707 - mmaction - INFO - \n",
      "mean_acc\t0.8492\n",
      "2021-03-22 16:19:09,000 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_15.pth.\n",
      "2021-03-22 16:19:09,001 - mmaction - INFO - Best top1_acc is 0.8492 at 15 epoch.\n",
      "2021-03-22 16:19:09,002 - mmaction - INFO - Epoch(val) [15][33]\ttop1_acc: 0.8492, top5_acc: 1.0000, mean_class_accuracy: 0.8492\n",
      "2021-03-22 16:20:54,290 - mmaction - INFO - Epoch [16][10/33]\tlr: 5.000e-04, eta: 0:44:12, time: 10.529, data_time: 9.656, memory: 21448, top1_acc: 0.8656, top5_acc: 1.0000, loss_cls: 0.3135, loss: 0.3135, grad_norm: 5.0392\n",
      "2021-03-22 16:22:01,583 - mmaction - INFO - Epoch [16][20/33]\tlr: 5.000e-04, eta: 0:42:08, time: 6.729, data_time: 5.830, memory: 21448, top1_acc: 0.9094, top5_acc: 0.9969, loss_cls: 0.2887, loss: 0.2887, grad_norm: 4.6742\n",
      "2021-03-22 16:23:36,416 - mmaction - INFO - Epoch [16][30/33]\tlr: 5.000e-04, eta: 0:41:18, time: 9.483, data_time: 8.587, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.2946, loss: 0.2946, grad_norm: 4.6754\n",
      "2021-03-22 16:23:49,993 - mmaction - INFO - Saving checkpoint at 16 epochs\n",
      "2021-03-22 16:25:33,204 - mmaction - INFO - Epoch [17][10/33]\tlr: 5.000e-04, eta: 0:39:21, time: 10.292, data_time: 9.408, memory: 21448, top1_acc: 0.8656, top5_acc: 1.0000, loss_cls: 0.3344, loss: 0.3344, grad_norm: 4.8666\n",
      "2021-03-22 16:26:46,080 - mmaction - INFO - Epoch [17][20/33]\tlr: 5.000e-04, eta: 0:37:42, time: 7.288, data_time: 6.408, memory: 21448, top1_acc: 0.9344, top5_acc: 1.0000, loss_cls: 0.2459, loss: 0.2459, grad_norm: 4.0389\n",
      "2021-03-22 16:28:21,720 - mmaction - INFO - Epoch [17][30/33]\tlr: 5.000e-04, eta: 0:36:43, time: 9.564, data_time: 8.689, memory: 21448, top1_acc: 0.8844, top5_acc: 1.0000, loss_cls: 0.3178, loss: 0.3178, grad_norm: 4.5435\n",
      "2021-03-22 16:30:33,123 - mmaction - INFO - Epoch [18][10/33]\tlr: 5.000e-04, eta: 0:34:58, time: 10.863, data_time: 9.958, memory: 21448, top1_acc: 0.9219, top5_acc: 1.0000, loss_cls: 0.2423, loss: 0.2423, grad_norm: 3.7765\n",
      "2021-03-22 16:31:40,469 - mmaction - INFO - Epoch [18][20/33]\tlr: 5.000e-04, eta: 0:33:15, time: 6.735, data_time: 5.828, memory: 21448, top1_acc: 0.9187, top5_acc: 1.0000, loss_cls: 0.2488, loss: 0.2488, grad_norm: 3.7101\n",
      "2021-03-22 16:33:15,571 - mmaction - INFO - Epoch [18][30/33]\tlr: 5.000e-04, eta: 0:32:09, time: 9.510, data_time: 8.597, memory: 21448, top1_acc: 0.9281, top5_acc: 1.0000, loss_cls: 0.2478, loss: 0.2478, grad_norm: 3.9696\n",
      "2021-03-22 16:33:38,128 - mmaction - INFO - Saving checkpoint at 18 epochs\n",
      "2021-03-22 16:35:26,146 - mmaction - INFO - Epoch [19][10/33]\tlr: 5.000e-04, eta: 0:30:23, time: 10.771, data_time: 9.890, memory: 21448, top1_acc: 0.9281, top5_acc: 1.0000, loss_cls: 0.2272, loss: 0.2272, grad_norm: 4.1818\n",
      "2021-03-22 16:36:30,975 - mmaction - INFO - Epoch [19][20/33]\tlr: 5.000e-04, eta: 0:28:43, time: 6.483, data_time: 5.602, memory: 21448, top1_acc: 0.9094, top5_acc: 1.0000, loss_cls: 0.2351, loss: 0.2351, grad_norm: 4.1198\n",
      "2021-03-22 16:38:01,164 - mmaction - INFO - Epoch [19][30/33]\tlr: 5.000e-04, eta: 0:27:29, time: 9.019, data_time: 8.134, memory: 21448, top1_acc: 0.9281, top5_acc: 1.0000, loss_cls: 0.2176, loss: 0.2176, grad_norm: 3.7628\n",
      "2021-03-22 16:40:05,490 - mmaction - INFO - Epoch [20][10/33]\tlr: 5.000e-04, eta: 0:25:38, time: 10.189, data_time: 9.315, memory: 21448, top1_acc: 0.8906, top5_acc: 1.0000, loss_cls: 0.3233, loss: 0.3233, grad_norm: 4.8384\n",
      "2021-03-22 16:41:11,675 - mmaction - INFO - Epoch [20][20/33]\tlr: 5.000e-04, eta: 0:24:05, time: 6.619, data_time: 5.745, memory: 21448, top1_acc: 0.9062, top5_acc: 1.0000, loss_cls: 0.2407, loss: 0.2407, grad_norm: 4.3140\n",
      "2021-03-22 16:42:46,974 - mmaction - INFO - Epoch [20][30/33]\tlr: 5.000e-04, eta: 0:22:53, time: 9.530, data_time: 8.654, memory: 21448, top1_acc: 0.9031, top5_acc: 1.0000, loss_cls: 0.2469, loss: 0.2469, grad_norm: 3.9892\n",
      "2021-03-22 16:43:06,859 - mmaction - INFO - Saving checkpoint at 20 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 3.5 task/s, elapsed: 36s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 16:43:42,967 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-22 16:43:42,969 - mmaction - INFO - \n",
      "top1_acc\t0.8571\n",
      "top5_acc\t1.0000\n",
      "2021-03-22 16:43:42,970 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-22 16:43:42,971 - mmaction - INFO - \n",
      "mean_acc\t0.8571\n",
      "2021-03-22 16:43:43,294 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_20.pth.\n",
      "2021-03-22 16:43:43,295 - mmaction - INFO - Best top1_acc is 0.8571 at 20 epoch.\n",
      "2021-03-22 16:43:43,296 - mmaction - INFO - Epoch(val) [20][33]\ttop1_acc: 0.8571, top5_acc: 1.0000, mean_class_accuracy: 0.8571\n",
      "2021-03-22 16:45:20,813 - mmaction - INFO - Epoch [21][10/33]\tlr: 5.000e-04, eta: 0:21:02, time: 9.751, data_time: 8.872, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.2959, loss: 0.2959, grad_norm: 5.2473\n",
      "2021-03-22 16:46:30,437 - mmaction - INFO - Epoch [21][20/33]\tlr: 5.000e-04, eta: 0:19:34, time: 6.962, data_time: 6.085, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.2686, loss: 0.2686, grad_norm: 4.9177\n",
      "2021-03-22 16:48:02,045 - mmaction - INFO - Epoch [21][30/33]\tlr: 5.000e-04, eta: 0:18:18, time: 9.161, data_time: 8.283, memory: 21448, top1_acc: 0.9031, top5_acc: 1.0000, loss_cls: 0.3019, loss: 0.3019, grad_norm: 4.7605\n",
      "2021-03-22 16:50:06,699 - mmaction - INFO - Epoch [22][10/33]\tlr: 5.000e-04, eta: 0:16:30, time: 10.034, data_time: 9.160, memory: 21448, top1_acc: 0.8688, top5_acc: 1.0000, loss_cls: 0.3052, loss: 0.3052, grad_norm: 5.0368\n",
      "2021-03-22 16:51:13,408 - mmaction - INFO - Epoch [22][20/33]\tlr: 5.000e-04, eta: 0:15:04, time: 6.671, data_time: 5.797, memory: 21448, top1_acc: 0.9094, top5_acc: 1.0000, loss_cls: 0.2709, loss: 0.2709, grad_norm: 5.0456\n",
      "2021-03-22 16:52:45,713 - mmaction - INFO - Epoch [22][30/33]\tlr: 5.000e-04, eta: 0:13:47, time: 9.230, data_time: 8.352, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.3308, loss: 0.3308, grad_norm: 5.8989\n",
      "2021-03-22 16:53:09,991 - mmaction - INFO - Saving checkpoint at 22 epochs\n",
      "2021-03-22 16:54:55,630 - mmaction - INFO - Epoch [23][10/33]\tlr: 5.000e-04, eta: 0:12:01, time: 10.536, data_time: 9.659, memory: 21448, top1_acc: 0.8781, top5_acc: 1.0000, loss_cls: 0.2764, loss: 0.2764, grad_norm: 4.5259\n",
      "2021-03-22 16:56:03,253 - mmaction - INFO - Epoch [23][20/33]\tlr: 5.000e-04, eta: 0:10:37, time: 6.762, data_time: 5.851, memory: 21448, top1_acc: 0.9187, top5_acc: 1.0000, loss_cls: 0.2443, loss: 0.2443, grad_norm: 4.7793\n",
      "2021-03-22 16:57:41,139 - mmaction - INFO - Epoch [23][30/33]\tlr: 5.000e-04, eta: 0:09:20, time: 9.789, data_time: 8.896, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.2643, loss: 0.2643, grad_norm: 4.7593\n",
      "2021-03-22 16:59:43,807 - mmaction - INFO - Epoch [24][10/33]\tlr: 5.000e-04, eta: 0:07:33, time: 10.066, data_time: 9.187, memory: 21448, top1_acc: 0.8844, top5_acc: 0.9969, loss_cls: 0.2928, loss: 0.2928, grad_norm: 4.9920\n",
      "2021-03-22 17:00:52,804 - mmaction - INFO - Epoch [24][20/33]\tlr: 5.000e-04, eta: 0:06:11, time: 6.900, data_time: 6.024, memory: 21448, top1_acc: 0.9094, top5_acc: 0.9969, loss_cls: 0.2648, loss: 0.2648, grad_norm: 4.4870\n",
      "2021-03-22 17:02:26,723 - mmaction - INFO - Epoch [24][30/33]\tlr: 5.000e-04, eta: 0:04:51, time: 9.392, data_time: 8.515, memory: 21448, top1_acc: 0.8938, top5_acc: 0.9969, loss_cls: 0.2742, loss: 0.2742, grad_norm: 4.9958\n",
      "2021-03-22 17:02:48,610 - mmaction - INFO - Saving checkpoint at 24 epochs\n",
      "2021-03-22 17:04:31,720 - mmaction - INFO - Epoch [25][10/33]\tlr: 5.000e-04, eta: 0:03:06, time: 10.283, data_time: 9.394, memory: 21448, top1_acc: 0.9125, top5_acc: 1.0000, loss_cls: 0.2537, loss: 0.2537, grad_norm: 4.5034\n",
      "2021-03-22 17:05:39,963 - mmaction - INFO - Epoch [25][20/33]\tlr: 5.000e-04, eta: 0:01:44, time: 6.824, data_time: 5.936, memory: 21448, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.2804, loss: 0.2804, grad_norm: 4.7272\n",
      "2021-03-22 17:07:15,466 - mmaction - INFO - Epoch [25][30/33]\tlr: 5.000e-04, eta: 0:00:24, time: 9.550, data_time: 8.677, memory: 21448, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2522, loss: 0.2522, grad_norm: 4.5856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 3.5 task/s, elapsed: 36s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 17:08:12,494 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-22 17:08:12,496 - mmaction - INFO - \n",
      "top1_acc\t0.8571\n",
      "top5_acc\t1.0000\n",
      "2021-03-22 17:08:12,496 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-22 17:08:12,497 - mmaction - INFO - \n",
      "mean_acc\t0.8571\n",
      "2021-03-22 17:08:12,497 - mmaction - INFO - Epoch(val) [25][33]\ttop1_acc: 0.8571, top5_acc: 1.0000, mean_class_accuracy: 0.8571\n",
      "2021-03-22 17:09:53,555 - mmaction - INFO - Epoch [26][10/33]\tlr: 5.000e-04, eta: -1 day, 23:58:40, time: 10.105, data_time: 9.229, memory: 21448, top1_acc: 0.8969, top5_acc: 1.0000, loss_cls: 0.2787, loss: 0.2787, grad_norm: 4.8332\n",
      "2021-03-22 17:11:02,020 - mmaction - INFO - Epoch [26][20/33]\tlr: 5.000e-04, eta: -1 day, 23:57:19, time: 6.847, data_time: 5.975, memory: 21448, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2513, loss: 0.2513, grad_norm: 5.1216\n",
      "2021-03-22 17:12:38,741 - mmaction - INFO - Epoch [26][30/33]\tlr: 5.000e-04, eta: -1 day, 23:55:57, time: 9.672, data_time: 8.776, memory: 21448, top1_acc: 0.8812, top5_acc: 1.0000, loss_cls: 0.2711, loss: 0.2711, grad_norm: 5.1664\n",
      "2021-03-22 17:12:58,372 - mmaction - INFO - Saving checkpoint at 26 epochs\n",
      "2021-03-22 17:14:39,326 - mmaction - INFO - Epoch [27][10/33]\tlr: 5.000e-04, eta: -1 day, 23:54:12, time: 10.068, data_time: 9.185, memory: 21448, top1_acc: 0.9125, top5_acc: 1.0000, loss_cls: 0.2284, loss: 0.2284, grad_norm: 4.4295\n",
      "2021-03-22 17:15:48,990 - mmaction - INFO - Epoch [27][20/33]\tlr: 5.000e-04, eta: -1 day, 23:52:53, time: 6.966, data_time: 6.081, memory: 21448, top1_acc: 0.8906, top5_acc: 1.0000, loss_cls: 0.2763, loss: 0.2763, grad_norm: 4.5929\n",
      "2021-03-22 17:17:19,566 - mmaction - INFO - Epoch [27][30/33]\tlr: 5.000e-04, eta: -1 day, 23:51:31, time: 9.058, data_time: 8.169, memory: 21448, top1_acc: 0.9062, top5_acc: 1.0000, loss_cls: 0.2449, loss: 0.2449, grad_norm: 5.1436\n",
      "2021-03-22 17:19:25,203 - mmaction - INFO - Epoch [28][10/33]\tlr: 5.000e-04, eta: -1 day, 23:49:46, time: 10.396, data_time: 9.516, memory: 21448, top1_acc: 0.8844, top5_acc: 1.0000, loss_cls: 0.2822, loss: 0.2822, grad_norm: 5.1844\n",
      "2021-03-22 17:20:36,427 - mmaction - INFO - Epoch [28][20/33]\tlr: 5.000e-04, eta: -1 day, 23:48:27, time: 7.122, data_time: 6.221, memory: 21448, top1_acc: 0.8875, top5_acc: 1.0000, loss_cls: 0.2617, loss: 0.2617, grad_norm: 4.6933\n",
      "2021-03-22 17:22:09,101 - mmaction - INFO - Epoch [28][30/33]\tlr: 5.000e-04, eta: -1 day, 23:47:04, time: 9.267, data_time: 8.391, memory: 21448, top1_acc: 0.8781, top5_acc: 1.0000, loss_cls: 0.2761, loss: 0.2761, grad_norm: 5.3211\n",
      "2021-03-22 17:22:29,398 - mmaction - INFO - Saving checkpoint at 28 epochs\n",
      "2021-03-22 17:24:12,905 - mmaction - INFO - Epoch [29][10/33]\tlr: 5.000e-04, eta: -1 day, 23:45:19, time: 10.320, data_time: 9.411, memory: 21448, top1_acc: 0.8906, top5_acc: 1.0000, loss_cls: 0.2990, loss: 0.2990, grad_norm: 5.5218\n",
      "2021-03-22 17:25:21,920 - mmaction - INFO - Epoch [29][20/33]\tlr: 5.000e-04, eta: -1 day, 23:44:01, time: 6.902, data_time: 6.019, memory: 21448, top1_acc: 0.8719, top5_acc: 1.0000, loss_cls: 0.2904, loss: 0.2904, grad_norm: 5.0257\n",
      "2021-03-22 17:26:59,871 - mmaction - INFO - Epoch [29][30/33]\tlr: 5.000e-04, eta: -1 day, 23:42:36, time: 9.795, data_time: 8.907, memory: 21448, top1_acc: 0.9031, top5_acc: 1.0000, loss_cls: 0.2559, loss: 0.2559, grad_norm: 5.4150\n",
      "2021-03-22 17:28:54,465 - mmaction - INFO - Epoch [30][10/33]\tlr: 5.000e-04, eta: -1 day, 23:40:52, time: 10.129, data_time: 9.256, memory: 21448, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2891, loss: 0.2891, grad_norm: 6.1167\n",
      "2021-03-22 17:30:05,159 - mmaction - INFO - Epoch [30][20/33]\tlr: 5.000e-04, eta: -1 day, 23:39:33, time: 7.069, data_time: 6.184, memory: 21448, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.2935, loss: 0.2935, grad_norm: 5.4480\n",
      "2021-03-22 17:31:41,483 - mmaction - INFO - Epoch [30][30/33]\tlr: 5.000e-04, eta: -1 day, 23:38:08, time: 9.632, data_time: 8.729, memory: 21448, top1_acc: 0.9375, top5_acc: 1.0000, loss_cls: 0.2138, loss: 0.2138, grad_norm: 4.4516\n",
      "2021-03-22 17:32:03,974 - mmaction - INFO - Saving checkpoint at 30 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 3.5 task/s, elapsed: 36s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 17:32:40,845 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-22 17:32:40,847 - mmaction - INFO - \n",
      "top1_acc\t0.8413\n",
      "top5_acc\t1.0000\n",
      "2021-03-22 17:32:40,848 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-22 17:32:40,849 - mmaction - INFO - \n",
      "mean_acc\t0.8413\n",
      "2021-03-22 17:32:40,850 - mmaction - INFO - Epoch(val) [30][33]\ttop1_acc: 0.8413, top5_acc: 1.0000, mean_class_accuracy: 0.8413\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryVoSfZVmogw"
   },
   "source": [
    "## Test the trained recognizer\n",
    "\n",
    "After finetuning the recognizer, let's check the prediction results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 2.1 task/s, elapsed: 59s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.9048\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.9048\n",
      "top1_acc: 0.9048\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.9048\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=16,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MMAction2 Tutorial.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

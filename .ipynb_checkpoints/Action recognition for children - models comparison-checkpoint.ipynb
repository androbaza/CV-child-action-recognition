{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/open-mmlab/mmaction2/blob/master/demo/mmaction2_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcjSRFELVbNk",
    "tags": []
   },
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bf8PpPXtVvmg",
    "outputId": "2c685a33-474b-4e71-8f98-c2533c66095e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2017 NVIDIA Corporation\n",
      "Built on Fri_Nov__3_21:07:56_CDT_2017\n",
      "Cuda compilation tools, release 9.1, V9.1.85\n",
      "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "Copyright (C) 2017 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check nvcc version\n",
    "!nvcc -V\n",
    "# Check GCC version\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5PAJ4ArzV5Ry",
    "outputId": "e48dbf61-fae0-431c-e964-04c7caaee4bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install some optional requirements\n",
    "# !pip install -r requirements/optional.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "No_zZAFpWC-a",
    "outputId": "1d425eea-d44e-434a-991c-01eb15abaab2",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0+cu110 True\n",
      "0.12.0\n",
      "11.0\n",
      "GCC 7.5\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMAction2 installation\n",
    "import mmaction\n",
    "print(mmaction.__version__)\n",
    "\n",
    "# Check MMCV installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/actrec/.local/lib/python3.6/site-packages/decord-0.5.3-py3.6-linux-x86_64.egg')\n",
    "import decord\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/actrec/.virtualenvs/mmaction/mmaction2\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcheckpoints\u001b[0m/  \u001b[01;34mdemo\u001b[0m/        LICENSE              README.md         setup.cfg\n",
      "\u001b[01;34mchildact-mm\u001b[0m/  \u001b[01;34mdocker\u001b[0m/      \u001b[01;34mmmaction\u001b[0m/            README_zh-CN.md   setup.py\n",
      "\u001b[01;34mconfigs\u001b[0m/      \u001b[01;34mdocs\u001b[0m/        \u001b[01;34mmmaction2.egg-info\u001b[0m/  \u001b[01;34mrequirements\u001b[0m/     \u001b[01;34mtests\u001b[0m/\n",
      "\u001b[01;34mdata\u001b[0m/         \u001b[01;34mdocs_zh_CN\u001b[0m/  my-mmaction.ipynb    requirements.txt  \u001b[01;34mtools\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# TSN 94.44% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "64CW6d_AaT-Q",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-22 01:46:07--  https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_video_1x1x8_100e_kinetics600_rgb/tsn_r50_video_1x1x8_100e_kinetics600_rgb_20201015-4db3c461.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.75.20.25\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.75.20.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 99220779 (95M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/tsn_r50_video_1x1x8_100e_kinetics600_rgb_20201015-4db3c461.pth’\n",
      "\n",
      "checkpoints/tsn_r50 100%[===================>]  94,62M  10,5MB/s    in 11s     \n",
      "\n",
      "2021-03-22 01:46:22 (8,61 MB/s) - ‘checkpoints/tsn_r50_video_1x1x8_100e_kinetics600_rgb_20201015-4db3c461.pth’ saved [99220779/99220779]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir checkpoints\n",
    "# !wget -c https://download.openmmlab.com/   .pth \\\n",
    "#       -O checkpoints/db3c461.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/tsn/tsn_r50_video_1x1x8_100e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer2D',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        pretrained='torchvision://resnet50',\n",
      "        depth=50,\n",
      "        norm_eval=False),\n",
      "    cls_head=dict(\n",
      "        type='TSNHead',\n",
      "        num_classes=7,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        consensus=dict(type='AvgConsensus', dim=1),\n",
      "        dropout_ratio=0.4,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips=None))\n",
      "optimizer = dict(type='SGD', lr=0.0001, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(10, 0.0001),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "total_epochs = 40\n",
      "checkpoint_config = dict(interval=2)\n",
      "log_config = dict(interval=20, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = './childact-checkpoints/childact-tsn/epoch_30.pth'\n",
      "resume_from = './childact-checkpoints/childact-tsn/epoch_30.pth'\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'VideoDataset'\n",
      "data_root = 'data/childact_split/train/'\n",
      "data_root_val = 'data/childact_split/val/'\n",
      "ann_file_train = 'data/childact_split/childact_train_video.txt'\n",
      "ann_file_val = 'data/childact_split/childact_val_video.txt'\n",
      "ann_file_test = 'data/childact_split/childact_test_video.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=8),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(\n",
      "        type='MultiScaleCrop',\n",
      "        input_size=224,\n",
      "        scales=(1, 0.875, 0.75, 0.66),\n",
      "        random_crop=False,\n",
      "        max_wh_scale_gap=1),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=8,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=25,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='ThreeCrop', crop_size=256),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=32,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_train_video.txt',\n",
      "        data_prefix='data/childact_split/train/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames', clip_len=1, frame_interval=1,\n",
      "                num_clips=8),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(\n",
      "                type='MultiScaleCrop',\n",
      "                input_size=224,\n",
      "                scales=(1, 0.875, 0.75, 0.66),\n",
      "                random_crop=False,\n",
      "                max_wh_scale_gap=1),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_val_video.txt',\n",
      "        data_prefix='data/childact_split/val/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=8,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_test_video.txt',\n",
      "        data_prefix='data/childact_split/test/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=25,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='ThreeCrop', crop_size=256),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]))\n",
      "evaluation = dict(\n",
      "    interval=2, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "work_dir = './childact-checkpoints/childact-tsn-2/'\n",
      "omnisource = False\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/childact-tsn-2//results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_split/train/'\n",
    "cfg.data_root_val = 'data/childact_split/val/'\n",
    "cfg.ann_file_train = 'data/childact_split/childact_train_video.txt'\n",
    "cfg.ann_file_val = 'data/childact_split/childact_val_video.txt'\n",
    "cfg.ann_file_test = 'data/childact_split/childact_test_video.txt'\n",
    "\n",
    "cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_split/childact_test_video.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_split/test/'\n",
    "\n",
    "cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_split/childact_train_video.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_split/train/'\n",
    "\n",
    "cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_split/childact_val_video.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_split/val/'\n",
    "\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = './childact-checkpoints/childact-tsn/epoch_30.pth'\n",
    "cfg.resume_from = './childact-checkpoints/childact-tsn/epoch_30.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/childact-tsn-2/'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.data.videos_per_gpu = 32\n",
    "cfg.optimizer.lr = 0.0001\n",
    "# cfg.lr_config.type = 'cyclic'\n",
    "cfg.total_epochs = 40\n",
    "\n",
    "cfg.lr_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(10, 1e-4),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 2\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 20\n",
    "cfg.evaluation.interval = 2\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 14:12:39,300 - mmaction - INFO - These parameters in pretrained checkpoint are not loaded: {'fc.weight', 'fc.bias'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_torchvision loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 14:12:39,359 - mmaction - INFO - load checkpoint from ./childact-checkpoints/childact-tsn/epoch_30.pth\n",
      "2021-03-25 14:12:39,360 - mmaction - INFO - Use load_from_local loader\n",
      "2021-03-25 14:12:39,874 - mmaction - INFO - resumed epoch 30, iter 1155\n",
      "2021-03-25 14:12:39,875 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /home/actrec/.virtualenvs/mmaction/mmaction2/childact-checkpoints/childact-tsn-2\n",
      "2021-03-25 14:12:39,876 - mmaction - INFO - workflow: [('train', 1)], max: 40 epochs\n",
      "/home/actrec/.virtualenvs/mmaction/mmaction2/mmaction/core/evaluation/eval_hooks.py:131: UserWarning: runner.meta is None. Creating a empty one.\n",
      "  warnings.warn('runner.meta is None. Creating a empty one.')\n",
      "2021-03-25 14:15:28,124 - mmaction - INFO - Epoch [31][20/33]\tlr: 4.077e-04, eta: 0:20:19, time: 8.412, data_time: 7.526, memory: 21540, top1_acc: 0.9422, top5_acc: 1.0000, loss_cls: 0.1803, loss: 0.1803, grad_norm: 3.5818\n",
      "2021-03-25 14:20:14,028 - mmaction - INFO - Epoch [32][20/33]\tlr: 2.470e-04, eta: 0:11:56, time: 8.535, data_time: 7.659, memory: 21540, top1_acc: 0.9391, top5_acc: 1.0000, loss_cls: 0.1854, loss: 0.1854, grad_norm: 3.5993\n",
      "2021-03-25 14:22:03,638 - mmaction - INFO - Saving checkpoint at 32 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 3.5 task/s, elapsed: 36s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 14:22:39,733 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 14:22:39,735 - mmaction - INFO - \n",
      "top1_acc\t0.8571\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 14:22:39,736 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 14:22:39,738 - mmaction - INFO - \n",
      "mean_acc\t0.8571\n",
      "2021-03-25 14:22:40,001 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_32.pth.\n",
      "2021-03-25 14:22:40,002 - mmaction - INFO - Best top1_acc is 0.8571 at 32 epoch.\n",
      "2021-03-25 14:22:40,003 - mmaction - INFO - Epoch(val) [32][33]\ttop1_acc: 0.8571, top5_acc: 1.0000, mean_class_accuracy: 0.8571\n",
      "2021-03-25 14:25:26,258 - mmaction - INFO - Epoch [33][20/33]\tlr: 1.249e-04, eta: 0:07:44, time: 8.313, data_time: 7.438, memory: 21540, top1_acc: 0.9141, top5_acc: 1.0000, loss_cls: 0.2269, loss: 0.2269, grad_norm: 4.7388\n",
      "2021-03-25 14:30:13,231 - mmaction - INFO - Epoch [34][20/33]\tlr: 4.337e-05, eta: 0:04:21, time: 8.550, data_time: 7.676, memory: 21540, top1_acc: 0.9359, top5_acc: 0.9984, loss_cls: 0.1936, loss: 0.1936, grad_norm: 3.9073\n",
      "2021-03-25 14:32:00,443 - mmaction - INFO - Saving checkpoint at 34 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 3.5 task/s, elapsed: 36s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 14:32:36,374 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 14:32:36,376 - mmaction - INFO - \n",
      "top1_acc\t0.8651\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 14:32:36,376 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 14:32:36,378 - mmaction - INFO - \n",
      "mean_acc\t0.8651\n",
      "2021-03-25 14:32:36,670 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_34.pth.\n",
      "2021-03-25 14:32:36,671 - mmaction - INFO - Best top1_acc is 0.8651 at 34 epoch.\n",
      "2021-03-25 14:32:36,672 - mmaction - INFO - Epoch(val) [34][33]\ttop1_acc: 0.8651, top5_acc: 1.0000, mean_class_accuracy: 0.8651\n",
      "2021-03-25 14:35:22,905 - mmaction - INFO - Epoch [35][20/33]\tlr: 3.904e-06, eta: 0:01:12, time: 8.312, data_time: 7.438, memory: 21540, top1_acc: 0.8984, top5_acc: 0.9984, loss_cls: 0.2482, loss: 0.2482, grad_norm: 4.5644\n",
      "2021-03-25 14:40:10,661 - mmaction - INFO - Epoch [36][20/33]\tlr: 5.144e-04, eta: -1 day, 23:58:11, time: 8.546, data_time: 7.670, memory: 21540, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2288, loss: 0.2288, grad_norm: 4.6857\n",
      "2021-03-25 14:41:57,419 - mmaction - INFO - Saving checkpoint at 36 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 3.6 task/s, elapsed: 35s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 14:42:33,137 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 14:42:33,139 - mmaction - INFO - \n",
      "top1_acc\t0.8810\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 14:42:33,139 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 14:42:33,141 - mmaction - INFO - \n",
      "mean_acc\t0.8810\n",
      "2021-03-25 14:42:33,430 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_36.pth.\n",
      "2021-03-25 14:42:33,431 - mmaction - INFO - Best top1_acc is 0.8810 at 36 epoch.\n",
      "2021-03-25 14:42:33,431 - mmaction - INFO - Epoch(val) [36][33]\ttop1_acc: 0.8810, top5_acc: 1.0000, mean_class_accuracy: 0.8810\n",
      "2021-03-25 14:45:18,239 - mmaction - INFO - Epoch [37][20/33]\tlr: 6.068e-04, eta: -1 day, 23:55:14, time: 8.240, data_time: 7.367, memory: 21540, top1_acc: 0.9187, top5_acc: 1.0000, loss_cls: 0.2261, loss: 0.2261, grad_norm: 4.7761\n",
      "2021-03-25 14:50:03,231 - mmaction - INFO - Epoch [38][20/33]\tlr: 7.817e-04, eta: -1 day, 23:52:19, time: 8.473, data_time: 7.601, memory: 21540, top1_acc: 0.9125, top5_acc: 1.0000, loss_cls: 0.2332, loss: 0.2332, grad_norm: 4.8438\n",
      "2021-03-25 14:51:59,104 - mmaction - INFO - Saving checkpoint at 38 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 3.6 task/s, elapsed: 35s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 14:52:34,766 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 14:52:34,767 - mmaction - INFO - \n",
      "top1_acc\t0.8810\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 14:52:34,768 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 14:52:34,769 - mmaction - INFO - \n",
      "mean_acc\t0.8810\n",
      "2021-03-25 14:52:34,770 - mmaction - INFO - Epoch(val) [38][33]\ttop1_acc: 0.8810, top5_acc: 1.0000, mean_class_accuracy: 0.8810\n",
      "2021-03-25 14:55:23,918 - mmaction - INFO - Epoch [39][20/33]\tlr: 1.032e-03, eta: -1 day, 23:49:25, time: 8.457, data_time: 7.586, memory: 21540, top1_acc: 0.9187, top5_acc: 1.0000, loss_cls: 0.2099, loss: 0.2099, grad_norm: 5.1517\n",
      "2021-03-25 15:00:04,888 - mmaction - INFO - Epoch [40][20/33]\tlr: 1.349e-03, eta: -1 day, 23:46:33, time: 8.332, data_time: 7.458, memory: 21540, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2583, loss: 0.2583, grad_norm: 4.9323\n",
      "2021-03-25 15:02:03,446 - mmaction - INFO - Saving checkpoint at 40 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 3.5 task/s, elapsed: 36s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 15:02:39,524 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 15:02:39,526 - mmaction - INFO - \n",
      "top1_acc\t0.8810\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 15:02:39,526 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 15:02:39,527 - mmaction - INFO - \n",
      "mean_acc\t0.8810\n",
      "2021-03-25 15:02:39,528 - mmaction - INFO - Epoch(val) [40][33]\ttop1_acc: 0.8810, top5_acc: 1.0000, mean_class_accuracy: 0.8810\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model50e\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 2.2 task/s, elapsed: 56s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.9444\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.9444\n",
      "top1_acc: 0.9444\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=16,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'], yticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# SlowFast 91.27%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "64CW6d_AaT-Q",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-22 18:16:35--  https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_video_4x16x1_256e_kinetics400_rgb/slowfast_r50_video_4x16x1_256e_kinetics400_rgb_20200826-f85b90c5.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.254.186.225\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.254.186.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 138274276 (132M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/slowfast_r50_video_4x16x1_256e_kinetics400_rgb_20200826-f85b90c5.pth’\n",
      "\n",
      "checkpoints/slowfas 100%[===================>] 131,87M  6,72MB/s    in 17s     \n",
      "\n",
      "2021-03-22 18:16:55 (7,79 MB/s) - ‘checkpoints/slowfast_r50_video_4x16x1_256e_kinetics400_rgb_20200826-f85b90c5.pth’ saved [138274276/138274276]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_video_4x16x1_256e_kinetics400_rgb/slowfast_r50_video_4x16x1_256e_kinetics400_rgb_20200826-f85b90c5.pth \\\n",
    "      -O checkpoints/slowfast_r50_video_4x16x1_256e_kinetics400_rgb_20200826-f85b90c5.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/slowfast/slowfast_r50_video_4x16x1_256e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='ResNet3dSlowFast',\n",
      "        pretrained=None,\n",
      "        resample_rate=8,\n",
      "        speed_ratio=8,\n",
      "        channel_ratio=8,\n",
      "        slow_pathway=dict(\n",
      "            type='resnet3d',\n",
      "            depth=50,\n",
      "            pretrained=None,\n",
      "            lateral=True,\n",
      "            conv1_kernel=(1, 7, 7),\n",
      "            dilations=(1, 1, 1, 1),\n",
      "            conv1_stride_t=1,\n",
      "            pool1_stride_t=1,\n",
      "            inflate=(0, 0, 1, 1),\n",
      "            norm_eval=False),\n",
      "        fast_pathway=dict(\n",
      "            type='resnet3d',\n",
      "            depth=50,\n",
      "            pretrained=None,\n",
      "            lateral=False,\n",
      "            base_channels=8,\n",
      "            conv1_kernel=(5, 7, 7),\n",
      "            conv1_stride_t=1,\n",
      "            pool1_stride_t=1,\n",
      "            norm_eval=False)),\n",
      "    cls_head=dict(\n",
      "        type='SlowFastHead',\n",
      "        in_channels=2304,\n",
      "        num_classes=7,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "checkpoint_config = dict(interval=2)\n",
      "log_config = dict(interval=40, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = './childact-checkpoints/childact-slowfast3/best_top1_acc_epoch_5.pth'\n",
      "resume_from = './childact-checkpoints/childact-slowfast3/best_top1_acc_epoch_5.pth'\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'VideoDataset'\n",
      "data_root = 'data/childact_split/train/'\n",
      "data_root_val = 'data/childact_split/val/'\n",
      "ann_file_train = 'data/childact_split/childact_train_video.txt'\n",
      "ann_file_val = 'data/childact_split/childact_val_video.txt'\n",
      "ann_file_test = 'data/childact_split/childact_test_video.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=10,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='ThreeCrop', crop_size=256),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=16,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_train_video.txt',\n",
      "        data_prefix='data/childact_split/train/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_val_video.txt',\n",
      "        data_prefix='data/childact_split/val/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_test_video.txt',\n",
      "        data_prefix='data/childact_split/test/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=10,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='ThreeCrop', crop_size=256),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]))\n",
      "evaluation = dict(\n",
      "    interval=1, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='CosineAnnealing',\n",
      "    min_lr=0,\n",
      "    warmup='linear',\n",
      "    warmup_by_epoch=True,\n",
      "    warmup_iters=34)\n",
      "total_epochs = 11\n",
      "work_dir = './childact-checkpoints/childact-slowfast4/'\n",
      "find_unused_parameters = False\n",
      "omnisource = False\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(\n",
      "    out='./childact-checkpoints/childact-slowfast4//results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_split/train/'\n",
    "cfg.data_root_val = 'data/childact_split/val/'\n",
    "cfg.ann_file_train = 'data/childact_split/childact_train_video.txt'\n",
    "cfg.ann_file_val = 'data/childact_split/childact_val_video.txt'\n",
    "cfg.ann_file_test = 'data/childact_split/childact_test_video.txt'\n",
    "\n",
    "cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_split/childact_test_video.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_split/test/'\n",
    "\n",
    "cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_split/childact_train_video.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_split/train/'\n",
    "\n",
    "cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_split/childact_val_video.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_split/val/'\n",
    "\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = './childact-checkpoints/childact-slowfast3/best_top1_acc_epoch_5.pth'\n",
    "cfg.resume_from = './childact-checkpoints/childact-slowfast3/best_top1_acc_epoch_5.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/childact-slowfast4/'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.data.videos_per_gpu = 16\n",
    "# cfg.data.workers_per_gpu = 4\n",
    "# cfg.optimizer.type = 'Adam'\n",
    "# cfg.optimizer.weight_decay=0.0001\n",
    "\n",
    "# cfg.optimizer_config.grad_clip=None\n",
    "cfg.optimizer.lr = 0.001\n",
    "\n",
    "# cfg.lr_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(10, 1e-4),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "cfg.total_epochs = 11\n",
    "cfg.evaluation.interval = 1\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 2\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 40\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 12:40:03,663 - mmaction - INFO - load checkpoint from ./childact-checkpoints/childact-slowfast3/best_top1_acc_epoch_5.pth\n",
      "2021-03-25 12:40:03,664 - mmaction - INFO - Use load_from_local loader\n",
      "2021-03-25 12:40:03,874 - mmaction - INFO - resumed epoch 5, iter 330\n",
      "2021-03-25 12:40:03,876 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /home/actrec/.virtualenvs/mmaction/mmaction2/childact-checkpoints/childact-slowfast4\n",
      "2021-03-25 12:40:03,877 - mmaction - INFO - workflow: [('train', 1)], max: 11 epochs\n",
      "2021-03-25 12:41:36,333 - mmaction - INFO - Epoch [6][40/66]\tlr: 1.416e-02, eta: 0:13:42, time: 2.311, data_time: 1.426, memory: 12207, top1_acc: 0.7500, top5_acc: 0.9844, loss_cls: 0.6193, loss: 0.6193, grad_norm: 0.9436\n",
      "2021-03-25 12:42:28,631 - mmaction - INFO - Saving checkpoint at 6 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 6.4 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 12:42:48,742 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 12:42:48,743 - mmaction - INFO - \n",
      "top1_acc\t0.8254\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 12:42:48,744 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 12:42:48,744 - mmaction - INFO - \n",
      "mean_acc\t0.8254\n",
      "2021-03-25 12:42:49,135 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_6.pth.\n",
      "2021-03-25 12:42:49,136 - mmaction - INFO - Best top1_acc is 0.8254 at 6 epoch.\n",
      "2021-03-25 12:42:49,137 - mmaction - INFO - Epoch(val) [6][66]\ttop1_acc: 0.8254, top5_acc: 1.0000, mean_class_accuracy: 0.8254\n",
      "2021-03-25 12:44:22,536 - mmaction - INFO - Epoch [7][40/66]\tlr: 1.177e-02, eta: 0:08:28, time: 2.335, data_time: 1.443, memory: 12207, top1_acc: 0.6984, top5_acc: 0.9906, loss_cls: 0.7002, loss: 0.7002, grad_norm: 1.1397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 6.4 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 12:45:38,793 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 12:45:38,795 - mmaction - INFO - \n",
      "top1_acc\t0.7937\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 12:45:38,796 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 12:45:38,797 - mmaction - INFO - \n",
      "mean_acc\t0.7937\n",
      "2021-03-25 12:45:38,798 - mmaction - INFO - Epoch(val) [7][66]\ttop1_acc: 0.7937, top5_acc: 1.0000, mean_class_accuracy: 0.7937\n",
      "2021-03-25 12:47:09,756 - mmaction - INFO - Epoch [8][40/66]\tlr: 8.796e-03, eta: 0:06:00, time: 2.274, data_time: 1.378, memory: 12207, top1_acc: 0.7109, top5_acc: 0.9891, loss_cls: 0.7145, loss: 0.7145, grad_norm: 1.0675\n",
      "2021-03-25 12:48:02,808 - mmaction - INFO - Saving checkpoint at 8 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 6.5 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 12:48:22,782 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 12:48:22,783 - mmaction - INFO - \n",
      "top1_acc\t0.8492\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 12:48:22,784 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 12:48:22,784 - mmaction - INFO - \n",
      "mean_acc\t0.8492\n",
      "2021-03-25 12:48:23,196 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_8.pth.\n",
      "2021-03-25 12:48:23,197 - mmaction - INFO - Best top1_acc is 0.8492 at 8 epoch.\n",
      "2021-03-25 12:48:23,198 - mmaction - INFO - Epoch(val) [8][66]\ttop1_acc: 0.8492, top5_acc: 1.0000, mean_class_accuracy: 0.8492\n",
      "2021-03-25 12:49:56,477 - mmaction - INFO - Epoch [9][40/66]\tlr: 5.650e-03, eta: 0:04:05, time: 2.332, data_time: 1.436, memory: 12207, top1_acc: 0.7219, top5_acc: 0.9875, loss_cls: 0.7207, loss: 0.7207, grad_norm: 1.1247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 6.4 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 12:51:07,151 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 12:51:07,154 - mmaction - INFO - \n",
      "top1_acc\t0.8254\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 12:51:07,155 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 12:51:07,157 - mmaction - INFO - \n",
      "mean_acc\t0.8254\n",
      "2021-03-25 12:51:07,158 - mmaction - INFO - Epoch(val) [9][66]\ttop1_acc: 0.8254, top5_acc: 1.0000, mean_class_accuracy: 0.8254\n",
      "2021-03-25 12:52:37,352 - mmaction - INFO - Epoch [10][40/66]\tlr: 2.809e-03, eta: 0:02:19, time: 2.255, data_time: 1.360, memory: 12207, top1_acc: 0.7141, top5_acc: 0.9922, loss_cls: 0.6923, loss: 0.6923, grad_norm: 1.0608\n",
      "2021-03-25 12:53:32,091 - mmaction - INFO - Saving checkpoint at 10 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 6.5 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 12:53:52,057 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 12:53:52,059 - mmaction - INFO - \n",
      "top1_acc\t0.8492\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 12:53:52,059 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 12:53:52,061 - mmaction - INFO - \n",
      "mean_acc\t0.8492\n",
      "2021-03-25 12:53:52,062 - mmaction - INFO - Epoch(val) [10][66]\ttop1_acc: 0.8492, top5_acc: 1.0000, mean_class_accuracy: 0.8492\n",
      "2021-03-25 12:55:24,466 - mmaction - INFO - Epoch [11][40/66]\tlr: 7.703e-04, eta: 0:00:38, time: 2.310, data_time: 1.412, memory: 12207, top1_acc: 0.6969, top5_acc: 0.9859, loss_cls: 0.7326, loss: 0.7326, grad_norm: 1.0574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 6.4 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 12:56:38,924 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 12:56:38,926 - mmaction - INFO - \n",
      "top1_acc\t0.8333\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 12:56:38,926 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 12:56:38,928 - mmaction - INFO - \n",
      "mean_acc\t0.8333\n",
      "2021-03-25 12:56:38,928 - mmaction - INFO - Epoch(val) [11][66]\ttop1_acc: 0.8333, top5_acc: 1.0000, mean_class_accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.ipc_collect()\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "# gc.enable()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model50e\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 0.0 task/s, elapsed: 2773s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.9365\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.9365\n",
      "top1_acc: 0.9365\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.9365\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmaction.models import build_model\n",
    "from mmaction.datasets import build_dataset\n",
    "\n",
    "# checkpoint = './childact-checkpoints/childact-slowfast/best_top1_acc_epoch_50.pth'\n",
    "# modelt = init_recognizer(cfg, checkpoint, device='cuda:0')\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=2,\n",
    "        workers_per_gpu=1,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'], yticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# R(2+1)D 59.52%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "64CW6d_AaT-Q",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-24 13:44:27--  https://download.openmmlab.com/mmaction/recognition/r2plus1d/r2plus1d_r34_video_8x8x1_180e_kinetics400_rgb/r2plus1d_r34_video_8x8x1_180e_kinetics400_rgb_20200826-ab35a529.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.35\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.35|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 255320099 (243M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/r2plus1d_r34_video_8x8x1_180e_kinetics400_rgb_20200826-ab35a529.pth’\n",
      "\n",
      "checkpoints/r2plus1 100%[===================>] 243,49M  6,98MB/s    in 32s     \n",
      "\n",
      "2021-03-24 13:45:05 (7,72 MB/s) - ‘checkpoints/r2plus1d_r34_video_8x8x1_180e_kinetics400_rgb_20200826-ab35a529.pth’ saved [255320099/255320099]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/r2plus1d/r2plus1d_r34_video_8x8x1_180e_kinetics400_rgb/r2plus1d_r34_video_8x8x1_180e_kinetics400_rgb_20200826-ab35a529.pth \\\n",
    "      -O checkpoints/r2plus1d_r34_video_8x8x1_180e_kinetics400_rgb_20200826-ab35a529.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/r2plus1d/r2plus1d_r34_video_8x8x1_180e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='ResNet2Plus1d',\n",
      "        depth=34,\n",
      "        pretrained=None,\n",
      "        pretrained2d=False,\n",
      "        norm_eval=False,\n",
      "        conv_cfg=dict(type='Conv2plus1d'),\n",
      "        conv1_kernel=(3, 7, 7),\n",
      "        conv1_stride_t=1,\n",
      "        pool1_stride_t=1,\n",
      "        inflate=(1, 1, 1, 1),\n",
      "        spatial_strides=(1, 2, 2, 2),\n",
      "        temporal_strides=(1, 2, 2, 2),\n",
      "        zero_init_residual=False,\n",
      "        act_cfg=dict(type='ReLU')),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        num_classes=7,\n",
      "        in_channels=512,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "checkpoint_config = dict(interval=4)\n",
      "log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = './checkpoints/r2plus1d_r34_video_8x8x1_180e_kinetics400_rgb_20200826-ab35a529.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'VideoDataset'\n",
      "data_root = 'data/childact_split/train/'\n",
      "data_root_val = 'data/childact_split/val/'\n",
      "ann_file_train = 'data/childact_split/childact_train_video.txt'\n",
      "ann_file_val = 'data/childact_split/childact_val_video.txt'\n",
      "ann_file_test = 'data/childact_split/childact_test_video.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(type='SampleFrames', clip_len=8, frame_interval=8, num_clips=1),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=8,\n",
      "        frame_interval=8,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=8,\n",
      "        frame_interval=8,\n",
      "        num_clips=10,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='ThreeCrop', crop_size=256),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=32,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_train_video.txt',\n",
      "        data_prefix='data/childact_split/train/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames', clip_len=8, frame_interval=8,\n",
      "                num_clips=1),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_val_video.txt',\n",
      "        data_prefix='data/childact_split/val/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=8,\n",
      "                frame_interval=8,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        test_mode=True),\n",
      "    test=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_test_video.txt',\n",
      "        data_prefix='data/childact_split/test/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=8,\n",
      "                frame_interval=8,\n",
      "                num_clips=10,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='ThreeCrop', crop_size=256),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        test_mode=True))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "optimizer = dict(type='SGD', lr=0.2, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(10, 0.0001),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "total_epochs = 51\n",
      "work_dir = './childact-checkpoints/childact-r2plus1d-3'\n",
      "find_unused_parameters = False\n",
      "omnisource = False\n",
      "momentum_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(0.8947368421052632, 1),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(\n",
      "    out='./childact-checkpoints/childact-r2plus1d-3/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_split/train/'\n",
    "cfg.data_root_val = 'data/childact_split/val/'\n",
    "cfg.ann_file_train = 'data/childact_split/childact_train_video.txt'\n",
    "cfg.ann_file_val = 'data/childact_split/childact_val_video.txt'\n",
    "cfg.ann_file_test = 'data/childact_split/childact_test_video.txt'\n",
    "\n",
    "cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_split/childact_test_video.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_split/test/'\n",
    "\n",
    "cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_split/childact_train_video.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_split/train/'\n",
    "\n",
    "cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_split/childact_val_video.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_split/val/'\n",
    "\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = './checkpoints/r2plus1d_r34_video_8x8x1_180e_kinetics400_rgb_20200826-ab35a529.pth'\n",
    "# cfg.resume_from = './childact-checkpoints/childact-r2plus1d/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/childact-r2plus1d-3'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.data.videos_per_gpu = 32\n",
    "# cfg.optimizer.type = 'Adam'\n",
    "# cfg.optimizer.weight_decay=0.0001\n",
    "\n",
    "# cfg.optimizer_config.grad_clip=None\n",
    "# cfg.optimizer.lr = 0.01\n",
    "\n",
    "cfg.lr_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(10, 1e-4),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "cfg.total_epochs = 51\n",
    "\n",
    "cfg.momentum_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(0.85 / 0.95, 1),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 4\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 10\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "del cfg.model.backbone['norm_cfg']\n",
    "# cfg.model.cls_head.type = \"TSNHead\"\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 15:30:20,791 - mmaction - INFO - load checkpoint from ./checkpoints/r2plus1d_r34_video_8x8x1_180e_kinetics400_rgb_20200826-ab35a529.pth\n",
      "2021-03-25 15:30:20,792 - mmaction - INFO - Use load_from_local loader\n",
      "2021-03-25 15:30:20,949 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 512]) from checkpoint, the shape in current model is torch.Size([7, 512]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([7]).\n",
      "2021-03-25 15:30:20,956 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /home/actrec/.virtualenvs/mmaction/mmaction2/childact-checkpoints/childact-r2plus1d-3\n",
      "2021-03-25 15:30:20,956 - mmaction - INFO - workflow: [('train', 1)], max: 51 epochs\n",
      "/home/actrec/.virtualenvs/mmaction/mmaction2/mmaction/core/evaluation/eval_hooks.py:131: UserWarning: runner.meta is None. Creating a empty one.\n",
      "  warnings.warn('runner.meta is None. Creating a empty one.')\n",
      "2021-03-25 15:31:02,501 - mmaction - INFO - Epoch [1][10/33]\tlr: 2.008e-01, eta: 1:55:49, time: 4.154, data_time: 2.889, memory: 21540, top1_acc: 0.2844, top5_acc: 0.8156, loss_cls: 2.1705, loss: 2.1705, grad_norm: 7.4289\n",
      "2021-03-25 15:31:31,298 - mmaction - INFO - Epoch [1][20/33]\tlr: 2.035e-01, eta: 1:37:28, time: 2.880, data_time: 1.614, memory: 21540, top1_acc: 0.2469, top5_acc: 0.9125, loss_cls: 2.0148, loss: 2.0148, grad_norm: 3.1453\n",
      "2021-03-25 15:32:05,559 - mmaction - INFO - Epoch [1][30/33]\tlr: 2.082e-01, eta: 1:36:03, time: 3.426, data_time: 2.157, memory: 21540, top1_acc: 0.2000, top5_acc: 0.9062, loss_cls: 2.6605, loss: 2.6605, grad_norm: 2.8469\n",
      "2021-03-25 15:32:53,722 - mmaction - INFO - Epoch [2][10/33]\tlr: 2.172e-01, eta: 1:33:10, time: 4.199, data_time: 2.919, memory: 21540, top1_acc: 0.2281, top5_acc: 0.9000, loss_cls: 1.8570, loss: 1.8570, grad_norm: 1.2776\n",
      "2021-03-25 15:33:23,062 - mmaction - INFO - Epoch [2][20/33]\tlr: 2.264e-01, eta: 1:30:10, time: 2.934, data_time: 1.633, memory: 21540, top1_acc: 0.2531, top5_acc: 0.9250, loss_cls: 1.8182, loss: 1.8182, grad_norm: 0.8250\n",
      "2021-03-25 15:33:55,783 - mmaction - INFO - Epoch [2][30/33]\tlr: 2.374e-01, eta: 1:29:25, time: 3.272, data_time: 1.989, memory: 21540, top1_acc: 0.2375, top5_acc: 0.9281, loss_cls: 1.8561, loss: 1.8561, grad_norm: 0.9048\n",
      "2021-03-25 15:34:41,763 - mmaction - INFO - Epoch [3][10/33]\tlr: 2.546e-01, eta: 1:27:36, time: 3.995, data_time: 2.713, memory: 21540, top1_acc: 0.2656, top5_acc: 0.9531, loss_cls: 1.7201, loss: 1.7201, grad_norm: 0.6051\n",
      "2021-03-25 15:35:11,548 - mmaction - INFO - Epoch [3][20/33]\tlr: 2.699e-01, eta: 1:26:09, time: 2.979, data_time: 1.666, memory: 21540, top1_acc: 0.3063, top5_acc: 0.9688, loss_cls: 1.5800, loss: 1.5800, grad_norm: 0.5706\n",
      "2021-03-25 15:35:46,000 - mmaction - INFO - Epoch [3][30/33]\tlr: 2.871e-01, eta: 1:26:11, time: 3.445, data_time: 2.146, memory: 21540, top1_acc: 0.2938, top5_acc: 0.9688, loss_cls: 1.5985, loss: 1.5985, grad_norm: 0.6491\n",
      "2021-03-25 15:36:35,684 - mmaction - INFO - Epoch [4][10/33]\tlr: 3.120e-01, eta: 1:25:19, time: 4.171, data_time: 2.896, memory: 21540, top1_acc: 0.3563, top5_acc: 0.9531, loss_cls: 1.5086, loss: 1.5086, grad_norm: 0.6201\n",
      "2021-03-25 15:37:03,335 - mmaction - INFO - Epoch [4][20/33]\tlr: 3.331e-01, eta: 1:23:43, time: 2.765, data_time: 1.476, memory: 21540, top1_acc: 0.3219, top5_acc: 0.9437, loss_cls: 1.7628, loss: 1.7628, grad_norm: 0.7288\n",
      "2021-03-25 15:37:40,292 - mmaction - INFO - Epoch [4][30/33]\tlr: 3.559e-01, eta: 1:24:09, time: 3.696, data_time: 2.415, memory: 21540, top1_acc: 0.3344, top5_acc: 0.9531, loss_cls: 1.5966, loss: 1.5966, grad_norm: 0.5774\n",
      "2021-03-25 15:37:48,214 - mmaction - INFO - Saving checkpoint at 4 epochs\n",
      "2021-03-25 15:38:30,725 - mmaction - INFO - Epoch [5][10/33]\tlr: 3.880e-01, eta: 1:23:20, time: 4.167, data_time: 2.890, memory: 21540, top1_acc: 0.3094, top5_acc: 0.9500, loss_cls: 1.5623, loss: 1.5623, grad_norm: 0.4973\n",
      "2021-03-25 15:38:59,313 - mmaction - INFO - Epoch [5][20/33]\tlr: 4.145e-01, eta: 1:22:09, time: 2.859, data_time: 1.580, memory: 21540, top1_acc: 0.3406, top5_acc: 0.9469, loss_cls: 1.5454, loss: 1.5454, grad_norm: 0.6928\n",
      "2021-03-25 15:39:32,827 - mmaction - INFO - Epoch [5][30/33]\tlr: 4.424e-01, eta: 1:21:49, time: 3.351, data_time: 2.062, memory: 21540, top1_acc: 0.2687, top5_acc: 0.9531, loss_cls: 1.6012, loss: 1.6012, grad_norm: 0.6742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 7.8 task/s, elapsed: 16s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 15:39:57,043 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 15:39:57,045 - mmaction - INFO - \n",
      "top1_acc\t0.3651\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 15:39:57,046 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 15:39:57,047 - mmaction - INFO - \n",
      "mean_acc\t0.3651\n",
      "2021-03-25 15:39:57,852 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
      "2021-03-25 15:39:57,854 - mmaction - INFO - Best top1_acc is 0.3651 at 5 epoch.\n",
      "2021-03-25 15:39:57,855 - mmaction - INFO - Epoch(val) [5][33]\ttop1_acc: 0.3651, top5_acc: 1.0000, mean_class_accuracy: 0.3651\n",
      "2021-03-25 15:40:40,465 - mmaction - INFO - Epoch [6][10/33]\tlr: 4.809e-01, eta: 1:21:13, time: 4.260, data_time: 2.969, memory: 21540, top1_acc: 0.3094, top5_acc: 0.9656, loss_cls: 1.5239, loss: 1.5239, grad_norm: 0.5280\n",
      "2021-03-25 15:41:09,933 - mmaction - INFO - Epoch [6][20/33]\tlr: 5.121e-01, eta: 1:20:17, time: 2.947, data_time: 1.667, memory: 21540, top1_acc: 0.3312, top5_acc: 0.9750, loss_cls: 1.5019, loss: 1.5019, grad_norm: 0.6209\n",
      "2021-03-25 15:41:43,015 - mmaction - INFO - Epoch [6][30/33]\tlr: 5.445e-01, eta: 1:19:52, time: 3.308, data_time: 2.006, memory: 21540, top1_acc: 0.3500, top5_acc: 0.9688, loss_cls: 1.4669, loss: 1.4669, grad_norm: 0.6785\n",
      "2021-03-25 15:42:32,873 - mmaction - INFO - Epoch [7][10/33]\tlr: 5.885e-01, eta: 1:19:19, time: 4.316, data_time: 3.034, memory: 21540, top1_acc: 0.3187, top5_acc: 0.9625, loss_cls: 1.4733, loss: 1.4733, grad_norm: 0.5135\n",
      "2021-03-25 15:42:59,557 - mmaction - INFO - Epoch [7][20/33]\tlr: 6.236e-01, eta: 1:18:10, time: 2.668, data_time: 1.382, memory: 21540, top1_acc: 0.2750, top5_acc: 0.9531, loss_cls: 1.6565, loss: 1.6565, grad_norm: 0.7216\n",
      "2021-03-25 15:43:33,497 - mmaction - INFO - Epoch [7][30/33]\tlr: 6.597e-01, eta: 1:17:50, time: 3.394, data_time: 2.101, memory: 21540, top1_acc: 0.2875, top5_acc: 0.9531, loss_cls: 1.6605, loss: 1.6605, grad_norm: 0.4748\n",
      "2021-03-25 15:44:20,169 - mmaction - INFO - Epoch [8][10/33]\tlr: 7.082e-01, eta: 1:17:09, time: 4.178, data_time: 2.898, memory: 21540, top1_acc: 0.2812, top5_acc: 0.9594, loss_cls: 1.5988, loss: 1.5988, grad_norm: 0.4877\n",
      "2021-03-25 15:44:48,118 - mmaction - INFO - Epoch [8][20/33]\tlr: 7.464e-01, eta: 1:16:13, time: 2.795, data_time: 1.508, memory: 21540, top1_acc: 0.3063, top5_acc: 0.9531, loss_cls: 1.5732, loss: 1.5732, grad_norm: 0.5366\n",
      "2021-03-25 15:45:21,504 - mmaction - INFO - Epoch [8][30/33]\tlr: 7.854e-01, eta: 1:15:49, time: 3.339, data_time: 2.050, memory: 21540, top1_acc: 0.3094, top5_acc: 0.9625, loss_cls: 1.6534, loss: 1.6534, grad_norm: 0.5668\n",
      "2021-03-25 15:45:27,422 - mmaction - INFO - Saving checkpoint at 8 epochs\n",
      "2021-03-25 15:46:09,156 - mmaction - INFO - Epoch [9][10/33]\tlr: 8.371e-01, eta: 1:15:04, time: 4.092, data_time: 2.812, memory: 21540, top1_acc: 0.3156, top5_acc: 0.9594, loss_cls: 1.5707, loss: 1.5707, grad_norm: 0.4655\n",
      "2021-03-25 15:46:37,676 - mmaction - INFO - Epoch [9][20/33]\tlr: 8.776e-01, eta: 1:14:15, time: 2.852, data_time: 1.568, memory: 21540, top1_acc: 0.2875, top5_acc: 0.9625, loss_cls: 1.5536, loss: 1.5536, grad_norm: 0.4027\n",
      "2021-03-25 15:47:11,993 - mmaction - INFO - Epoch [9][30/33]\tlr: 9.185e-01, eta: 1:13:55, time: 3.432, data_time: 2.142, memory: 21540, top1_acc: 0.3438, top5_acc: 0.9656, loss_cls: 1.5327, loss: 1.5327, grad_norm: 0.4450\n",
      "2021-03-25 15:48:03,821 - mmaction - INFO - Epoch [10][10/33]\tlr: 9.723e-01, eta: 1:13:31, time: 4.556, data_time: 3.277, memory: 21540, top1_acc: 0.3219, top5_acc: 0.9344, loss_cls: 1.6519, loss: 1.6519, grad_norm: 0.4373\n",
      "2021-03-25 15:48:30,898 - mmaction - INFO - Epoch [10][20/33]\tlr: 1.014e+00, eta: 1:12:38, time: 2.708, data_time: 1.429, memory: 21540, top1_acc: 0.3344, top5_acc: 0.9594, loss_cls: 1.5237, loss: 1.5237, grad_norm: 0.4727\n",
      "2021-03-25 15:49:05,581 - mmaction - INFO - Epoch [10][30/33]\tlr: 1.056e+00, eta: 1:12:17, time: 3.468, data_time: 2.188, memory: 21540, top1_acc: 0.2969, top5_acc: 0.9531, loss_cls: 1.6167, loss: 1.6167, grad_norm: 0.4456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 7.8 task/s, elapsed: 16s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 15:49:29,166 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 15:49:29,167 - mmaction - INFO - \n",
      "top1_acc\t0.3175\n",
      "top5_acc\t0.9762\n",
      "2021-03-25 15:49:29,168 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 15:49:29,168 - mmaction - INFO - \n",
      "mean_acc\t0.3175\n",
      "2021-03-25 15:49:29,169 - mmaction - INFO - Epoch(val) [10][33]\ttop1_acc: 0.3175, top5_acc: 0.9762, mean_class_accuracy: 0.3175\n",
      "2021-03-25 15:50:15,748 - mmaction - INFO - Epoch [11][10/33]\tlr: 1.111e+00, eta: 1:11:55, time: 4.658, data_time: 3.382, memory: 21540, top1_acc: 0.3438, top5_acc: 0.9625, loss_cls: 1.5662, loss: 1.5662, grad_norm: 0.5038\n",
      "2021-03-25 15:50:44,778 - mmaction - INFO - Epoch [11][20/33]\tlr: 1.152e+00, eta: 1:11:11, time: 2.903, data_time: 1.629, memory: 21540, top1_acc: 0.3219, top5_acc: 0.9563, loss_cls: 1.5483, loss: 1.5483, grad_norm: 0.5952\n",
      "2021-03-25 15:51:14,411 - mmaction - INFO - Epoch [11][30/33]\tlr: 1.194e+00, eta: 1:10:31, time: 2.963, data_time: 1.683, memory: 21540, top1_acc: 0.2844, top5_acc: 0.9125, loss_cls: 1.7821, loss: 1.7821, grad_norm: 0.5007\n",
      "2021-03-25 15:52:04,710 - mmaction - INFO - Epoch [12][10/33]\tlr: 1.248e+00, eta: 1:09:55, time: 4.323, data_time: 3.048, memory: 21540, top1_acc: 0.3156, top5_acc: 0.9500, loss_cls: 1.6321, loss: 1.6321, grad_norm: 0.4643\n",
      "2021-03-25 15:52:31,314 - mmaction - INFO - Epoch [12][20/33]\tlr: 1.290e+00, eta: 1:09:04, time: 2.660, data_time: 1.385, memory: 21540, top1_acc: 0.3469, top5_acc: 0.9469, loss_cls: 1.5154, loss: 1.5154, grad_norm: 0.4713\n",
      "2021-03-25 15:53:06,273 - mmaction - INFO - Epoch [12][30/33]\tlr: 1.331e+00, eta: 1:08:43, time: 3.496, data_time: 2.220, memory: 21540, top1_acc: 0.2687, top5_acc: 0.9531, loss_cls: 1.6201, loss: 1.6201, grad_norm: 0.5333\n",
      "2021-03-25 15:53:11,182 - mmaction - INFO - Saving checkpoint at 12 epochs\n",
      "2021-03-25 15:53:54,373 - mmaction - INFO - Epoch [13][10/33]\tlr: 1.383e+00, eta: 1:08:04, time: 4.238, data_time: 2.959, memory: 21540, top1_acc: 0.2844, top5_acc: 0.9594, loss_cls: 1.6167, loss: 1.6167, grad_norm: 0.4886\n",
      "2021-03-25 15:54:21,622 - mmaction - INFO - Epoch [13][20/33]\tlr: 1.422e+00, eta: 1:07:17, time: 2.725, data_time: 1.443, memory: 21540, top1_acc: 0.3031, top5_acc: 0.9531, loss_cls: 1.6399, loss: 1.6399, grad_norm: 0.5734\n",
      "2021-03-25 15:54:56,608 - mmaction - INFO - Epoch [13][30/33]\tlr: 1.461e+00, eta: 1:06:55, time: 3.499, data_time: 2.206, memory: 21540, top1_acc: 0.3281, top5_acc: 0.9531, loss_cls: 1.6068, loss: 1.6068, grad_norm: 0.5718\n",
      "2021-03-25 15:55:44,090 - mmaction - INFO - Epoch [14][10/33]\tlr: 1.511e+00, eta: 1:06:19, time: 4.360, data_time: 3.075, memory: 21540, top1_acc: 0.2875, top5_acc: 0.9469, loss_cls: 1.6569, loss: 1.6569, grad_norm: 0.4681\n",
      "2021-03-25 15:56:09,282 - mmaction - INFO - Epoch [14][20/33]\tlr: 1.548e+00, eta: 1:05:28, time: 2.519, data_time: 1.239, memory: 21540, top1_acc: 0.3125, top5_acc: 0.9406, loss_cls: 1.6067, loss: 1.6067, grad_norm: 0.4975\n",
      "2021-03-25 15:56:44,415 - mmaction - INFO - Epoch [14][30/33]\tlr: 1.584e+00, eta: 1:05:05, time: 3.513, data_time: 2.233, memory: 21540, top1_acc: 0.3094, top5_acc: 0.9469, loss_cls: 1.7103, loss: 1.7103, grad_norm: 0.6207\n",
      "2021-03-25 15:57:35,040 - mmaction - INFO - Epoch [15][10/33]\tlr: 1.629e+00, eta: 1:04:32, time: 4.481, data_time: 3.195, memory: 21540, top1_acc: 0.3031, top5_acc: 0.9563, loss_cls: 1.6136, loss: 1.6136, grad_norm: 0.4809\n",
      "2021-03-25 15:58:03,388 - mmaction - INFO - Epoch [15][20/33]\tlr: 1.662e+00, eta: 1:03:51, time: 2.835, data_time: 1.556, memory: 21540, top1_acc: 0.2812, top5_acc: 0.9375, loss_cls: 1.6945, loss: 1.6945, grad_norm: 0.5643\n",
      "2021-03-25 15:58:36,623 - mmaction - INFO - Epoch [15][30/33]\tlr: 1.694e+00, eta: 1:03:23, time: 3.323, data_time: 2.042, memory: 21540, top1_acc: 0.2500, top5_acc: 0.9469, loss_cls: 1.7621, loss: 1.7621, grad_norm: 0.5227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 7.8 task/s, elapsed: 16s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 15:58:57,064 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 15:58:57,066 - mmaction - INFO - \n",
      "top1_acc\t0.1984\n",
      "top5_acc\t0.7460\n",
      "2021-03-25 15:58:57,066 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 15:58:57,067 - mmaction - INFO - \n",
      "mean_acc\t0.1984\n",
      "2021-03-25 15:58:57,068 - mmaction - INFO - Epoch(val) [15][33]\ttop1_acc: 0.1984, top5_acc: 0.7460, mean_class_accuracy: 0.1984\n",
      "2021-03-25 15:59:40,086 - mmaction - INFO - Epoch [16][10/33]\tlr: 1.734e+00, eta: 1:02:45, time: 4.301, data_time: 3.018, memory: 21540, top1_acc: 0.2938, top5_acc: 0.9437, loss_cls: 1.6775, loss: 1.6775, grad_norm: 0.4904\n",
      "2021-03-25 16:00:07,571 - mmaction - INFO - Epoch [16][20/33]\tlr: 1.763e+00, eta: 1:02:02, time: 2.748, data_time: 1.469, memory: 21540, top1_acc: 0.3063, top5_acc: 0.9719, loss_cls: 1.6790, loss: 1.6790, grad_norm: 0.4985\n",
      "2021-03-25 16:00:40,896 - mmaction - INFO - Epoch [16][30/33]\tlr: 1.791e+00, eta: 1:01:34, time: 3.332, data_time: 2.050, memory: 21540, top1_acc: 0.3031, top5_acc: 0.9500, loss_cls: 1.6984, loss: 1.6984, grad_norm: 0.5027\n",
      "2021-03-25 16:00:44,909 - mmaction - INFO - Saving checkpoint at 16 epochs\n",
      "2021-03-25 16:01:27,873 - mmaction - INFO - Epoch [17][10/33]\tlr: 1.825e+00, eta: 1:00:54, time: 4.216, data_time: 2.942, memory: 21540, top1_acc: 0.2812, top5_acc: 0.9437, loss_cls: 1.7198, loss: 1.7198, grad_norm: 0.4784\n",
      "2021-03-25 16:01:55,806 - mmaction - INFO - Epoch [17][20/33]\tlr: 1.849e+00, eta: 1:00:14, time: 2.793, data_time: 1.517, memory: 21540, top1_acc: 0.2812, top5_acc: 0.9281, loss_cls: 1.7077, loss: 1.7077, grad_norm: 0.5080\n",
      "2021-03-25 16:02:30,456 - mmaction - INFO - Epoch [17][30/33]\tlr: 1.871e+00, eta: 0:59:47, time: 3.465, data_time: 2.179, memory: 21540, top1_acc: 0.3094, top5_acc: 0.9531, loss_cls: 1.6434, loss: 1.6434, grad_norm: 0.5502\n",
      "2021-03-25 16:03:19,488 - mmaction - INFO - Epoch [18][10/33]\tlr: 1.898e+00, eta: 0:59:08, time: 4.251, data_time: 2.976, memory: 21540, top1_acc: 0.3156, top5_acc: 0.9375, loss_cls: 1.6301, loss: 1.6301, grad_norm: 0.5023\n",
      "2021-03-25 16:03:47,471 - mmaction - INFO - Epoch [18][20/33]\tlr: 1.917e+00, eta: 0:58:29, time: 2.798, data_time: 1.523, memory: 21540, top1_acc: 0.2687, top5_acc: 0.9531, loss_cls: 1.6953, loss: 1.6953, grad_norm: 0.4932\n",
      "2021-03-25 16:04:20,780 - mmaction - INFO - Epoch [18][30/33]\tlr: 1.933e+00, eta: 0:57:59, time: 3.331, data_time: 2.055, memory: 21540, top1_acc: 0.2875, top5_acc: 0.9406, loss_cls: 1.6540, loss: 1.6540, grad_norm: 0.4814\n",
      "2021-03-25 16:05:10,733 - mmaction - INFO - Epoch [19][10/33]\tlr: 1.952e+00, eta: 0:57:19, time: 4.208, data_time: 2.933, memory: 21540, top1_acc: 0.2531, top5_acc: 0.9469, loss_cls: 1.7584, loss: 1.7584, grad_norm: 0.5687\n",
      "2021-03-25 16:05:37,501 - mmaction - INFO - Epoch [19][20/33]\tlr: 1.965e+00, eta: 0:56:38, time: 2.677, data_time: 1.399, memory: 21540, top1_acc: 0.2531, top5_acc: 0.9156, loss_cls: 1.7489, loss: 1.7489, grad_norm: 0.3908\n",
      "2021-03-25 16:06:12,213 - mmaction - INFO - Epoch [19][30/33]\tlr: 1.976e+00, eta: 0:56:12, time: 3.471, data_time: 2.192, memory: 21540, top1_acc: 0.2656, top5_acc: 0.9219, loss_cls: 1.7889, loss: 1.7889, grad_norm: 0.3820\n",
      "2021-03-25 16:07:02,668 - mmaction - INFO - Epoch [20][10/33]\tlr: 1.987e+00, eta: 0:55:34, time: 4.388, data_time: 3.113, memory: 21540, top1_acc: 0.2156, top5_acc: 0.9125, loss_cls: 1.7605, loss: 1.7605, grad_norm: 0.3493\n",
      "2021-03-25 16:07:30,063 - mmaction - INFO - Epoch [20][20/33]\tlr: 1.993e+00, eta: 0:54:55, time: 2.739, data_time: 1.467, memory: 21540, top1_acc: 0.2125, top5_acc: 0.9313, loss_cls: 1.7811, loss: 1.7811, grad_norm: 0.4657\n",
      "2021-03-25 16:08:02,925 - mmaction - INFO - Epoch [20][30/33]\tlr: 1.997e+00, eta: 0:54:25, time: 3.286, data_time: 2.005, memory: 21540, top1_acc: 0.2938, top5_acc: 0.9156, loss_cls: 1.7447, loss: 1.7447, grad_norm: 0.8211\n",
      "2021-03-25 16:08:09,007 - mmaction - INFO - Saving checkpoint at 20 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 7.8 task/s, elapsed: 16s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 16:08:26,069 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 16:08:26,070 - mmaction - INFO - \n",
      "top1_acc\t0.2381\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 16:08:26,071 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 16:08:26,072 - mmaction - INFO - \n",
      "mean_acc\t0.2381\n",
      "2021-03-25 16:08:26,073 - mmaction - INFO - Epoch(val) [20][33]\ttop1_acc: 0.2381, top5_acc: 1.0000, mean_class_accuracy: 0.2381\n",
      "2021-03-25 16:09:08,179 - mmaction - INFO - Epoch [21][10/33]\tlr: 2.000e+00, eta: 0:53:45, time: 4.210, data_time: 2.933, memory: 21540, top1_acc: 0.2875, top5_acc: 0.9437, loss_cls: 1.7203, loss: 1.7203, grad_norm: 0.4388\n",
      "2021-03-25 16:09:35,054 - mmaction - INFO - Epoch [21][20/33]\tlr: 2.000e+00, eta: 0:53:06, time: 2.687, data_time: 1.415, memory: 21540, top1_acc: 0.3156, top5_acc: 0.9187, loss_cls: 1.6964, loss: 1.6964, grad_norm: 0.4517\n",
      "2021-03-25 16:10:09,760 - mmaction - INFO - Epoch [21][30/33]\tlr: 1.999e+00, eta: 0:52:38, time: 3.471, data_time: 2.192, memory: 21540, top1_acc: 0.2281, top5_acc: 0.9156, loss_cls: 1.7660, loss: 1.7660, grad_norm: 0.3907\n",
      "2021-03-25 16:11:00,239 - mmaction - INFO - Epoch [22][10/33]\tlr: 1.996e+00, eta: 0:52:00, time: 4.338, data_time: 3.055, memory: 21540, top1_acc: 0.2875, top5_acc: 0.9313, loss_cls: 1.7388, loss: 1.7388, grad_norm: 0.3903\n",
      "2021-03-25 16:11:29,629 - mmaction - INFO - Epoch [22][20/33]\tlr: 1.993e+00, eta: 0:51:24, time: 2.939, data_time: 1.668, memory: 21540, top1_acc: 0.2531, top5_acc: 0.9688, loss_cls: 1.6935, loss: 1.6935, grad_norm: 0.3204\n",
      "2021-03-25 16:12:04,397 - mmaction - INFO - Epoch [22][30/33]\tlr: 1.988e+00, eta: 0:50:57, time: 3.477, data_time: 2.202, memory: 21540, top1_acc: 0.2969, top5_acc: 0.9437, loss_cls: 1.6150, loss: 1.6150, grad_norm: 0.3260\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model50e\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 0.7 task/s, elapsed: 180s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.5952\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.5952\n",
      "top1_acc: 0.5952\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.5952\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader, load_annotations, build_dataset\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmaction.models import build_model\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=4,\n",
    "        workers_per_gpu=1,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# TSM 93.65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64CW6d_AaT-Q",
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-24 19:15:04--  https://download.openmmlab.com/mmaction/recognition/tsm/tsm_r50_video_1x1x8_100e_kinetics400_rgb/tsm_r50_video_1x1x8_100e_kinetics400_rgb_20200702-a77f4328.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.75.20.25\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.75.20.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 97579687 (93M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/tsm_r50_video_1x1x8_100e_kinetics400_rgb_20200702-a77f4328.pth’\n",
      "\n",
      "checkpoints/tsm_r50 100%[===================>]  93,06M  8,72MB/s    in 12s     \n",
      "\n",
      "2021-03-24 19:15:20 (7,71 MB/s) - ‘checkpoints/tsm_r50_video_1x1x8_100e_kinetics400_rgb_20200702-a77f4328.pth’ saved [97579687/97579687]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/tsm/tsm_r50_video_1x1x8_100e_kinetics400_rgb/tsm_r50_video_1x1x8_100e_kinetics400_rgb_20200702-a77f4328.pth \\\n",
    "      -O checkpoints/tsm_r50_video_1x1x8_100e_kinetics400_rgb_20200702-a77f4328.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/tsm/tsm_r50_video_1x1x8_50e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlhu9byjjt-K",
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer2D',\n",
      "    backbone=dict(\n",
      "        type='ResNetTSM',\n",
      "        pretrained='torchvision://resnet50',\n",
      "        depth=50,\n",
      "        norm_eval=False,\n",
      "        shift_div=8),\n",
      "    cls_head=dict(\n",
      "        type='TSMHead',\n",
      "        num_classes=7,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        consensus=dict(type='AvgConsensus', dim=1),\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.001,\n",
      "        is_shift=True),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "optimizer = dict(\n",
      "    type='SGD',\n",
      "    constructor='TSMOptimizerConstructor',\n",
      "    paramwise_cfg=dict(fc_lr5=True),\n",
      "    lr=0.02,\n",
      "    weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=20, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(10, 0.0001),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "total_epochs = 51\n",
      "checkpoint_config = dict(interval=4)\n",
      "log_config = dict(interval=25, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/tsm_r50_video_1x1x8_100e_kinetics400_rgb_20200702-a77f4328.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'VideoDataset'\n",
      "data_root = 'data/childact_split/train/'\n",
      "data_root_val = 'data/childact_split/val/'\n",
      "ann_file_train = 'data/childact_split/childact_train_video.txt'\n",
      "ann_file_val = 'data/childact_split/childact_val_video.txt'\n",
      "ann_file_test = 'data/childact_split/childact_test_video.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=8),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(\n",
      "        type='MultiScaleCrop',\n",
      "        input_size=224,\n",
      "        scales=(1, 0.875, 0.75, 0.66),\n",
      "        random_crop=False,\n",
      "        max_wh_scale_gap=1,\n",
      "        num_fixed_crops=13),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=8,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=8,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=24,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_train_video.txt',\n",
      "        data_prefix='data/childact_split/train/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames', clip_len=1, frame_interval=1,\n",
      "                num_clips=8),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(\n",
      "                type='MultiScaleCrop',\n",
      "                input_size=224,\n",
      "                scales=(1, 0.875, 0.75, 0.66),\n",
      "                random_crop=False,\n",
      "                max_wh_scale_gap=1,\n",
      "                num_fixed_crops=13),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_val_video.txt',\n",
      "        data_prefix='data/childact_split/val/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=8,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='data/childact_split/childact_test_video.txt',\n",
      "        data_prefix='data/childact_split/test/',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=8,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "work_dir = './childact-checkpoints/childact-tsm'\n",
      "omnisource = False\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/childact-tsm/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_split/train/'\n",
    "cfg.data_root_val = 'data/childact_split/val/'\n",
    "cfg.ann_file_train = 'data/childact_split/childact_train_video.txt'\n",
    "cfg.ann_file_val = 'data/childact_split/childact_val_video.txt'\n",
    "cfg.ann_file_test = 'data/childact_split/childact_test_video.txt'\n",
    "\n",
    "cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_split/childact_test_video.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_split/test/'\n",
    "\n",
    "cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_split/childact_train_video.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_split/train/'\n",
    "\n",
    "cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_split/childact_val_video.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_split/val/'\n",
    "\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = 'checkpoints/tsm_r50_video_1x1x8_100e_kinetics400_rgb_20200702-a77f4328.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/childact-tsm'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.data.videos_per_gpu = 24\n",
    "# cfg.optimizer.type = 'Adam'\n",
    "# cfg.optimizer.weight_decay=0.0001\n",
    "\n",
    "# cfg.optimizer_config.grad_clip=None\n",
    "# cfg.optimizer.lr = 0.01\n",
    "\n",
    "cfg.lr_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(10, 1e-4),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "cfg.total_epochs = 51\n",
    "\n",
    "cfg.momentum_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(0.85 / 0.95, 1),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 4\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 25\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-24 21:03:31,550 - mmaction - INFO - These parameters in pretrained checkpoint are not loaded: {'fc.weight', 'fc.bias'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_torchvision loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-24 21:03:33,980 - mmaction - INFO - load checkpoint from checkpoints/tsm_r50_video_1x1x8_100e_kinetics400_rgb_20200702-a77f4328.pth\n",
      "2021-03-24 21:03:33,982 - mmaction - INFO - Use load_from_local loader\n",
      "2021-03-24 21:03:34,081 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([7, 2048]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([7]).\n",
      "2021-03-24 21:03:34,086 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /home/actrec/.virtualenvs/mmaction/mmaction2/childact-checkpoints/childact-tsm\n",
      "2021-03-24 21:03:34,087 - mmaction - INFO - workflow: [('train', 1)], max: 51 epochs\n",
      "/home/actrec/.virtualenvs/mmaction/mmaction2/mmaction/core/evaluation/eval_hooks.py:131: UserWarning: runner.meta is None. Creating a empty one.\n",
      "  warnings.warn('runner.meta is None. Creating a empty one.')\n",
      "2021-03-24 21:06:25,694 - mmaction - INFO - Epoch [1][25/44]\tlr: 2.032e-02, eta: 4:13:51, time: 6.864, data_time: 5.883, memory: 20204, top1_acc: 0.4633, top5_acc: 0.9567, loss_cls: 1.3184, loss: 1.3184, grad_norm: 3.1978\n",
      "2021-03-24 21:11:00,838 - mmaction - INFO - Epoch [2][25/44]\tlr: 2.254e-02, eta: 3:01:16, time: 6.938, data_time: 5.963, memory: 20204, top1_acc: 0.7883, top5_acc: 0.9983, loss_cls: 0.5617, loss: 0.5617, grad_norm: 4.1688\n",
      "2021-03-24 21:15:26,642 - mmaction - INFO - Epoch [3][25/44]\tlr: 2.684e-02, eta: 2:42:07, time: 6.832, data_time: 5.857, memory: 20204, top1_acc: 0.8417, top5_acc: 1.0000, loss_cls: 0.4150, loss: 0.4150, grad_norm: 4.0095\n",
      "2021-03-24 21:19:46,715 - mmaction - INFO - Epoch [4][25/44]\tlr: 3.310e-02, eta: 2:30:22, time: 6.516, data_time: 5.540, memory: 20204, top1_acc: 0.8383, top5_acc: 0.9967, loss_cls: 0.4149, loss: 0.4149, grad_norm: 4.5450\n",
      "2021-03-24 21:21:35,996 - mmaction - INFO - Saving checkpoint at 4 epochs\n",
      "2021-03-24 21:24:21,918 - mmaction - INFO - Epoch [5][25/44]\tlr: 4.119e-02, eta: 2:23:03, time: 6.630, data_time: 5.657, memory: 20204, top1_acc: 0.8517, top5_acc: 0.9983, loss_cls: 0.3703, loss: 0.3703, grad_norm: 4.2365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 2.6 task/s, elapsed: 48s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-24 21:26:56,186 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-24 21:26:56,188 - mmaction - INFO - \n",
      "top1_acc\t0.8016\n",
      "top5_acc\t1.0000\n",
      "2021-03-24 21:26:56,188 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-24 21:26:56,190 - mmaction - INFO - \n",
      "mean_acc\t0.8016\n",
      "2021-03-24 21:26:56,341 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
      "2021-03-24 21:26:56,342 - mmaction - INFO - Best top1_acc is 0.8016 at 5 epoch.\n",
      "2021-03-24 21:26:56,343 - mmaction - INFO - Epoch(val) [5][44]\ttop1_acc: 0.8016, top5_acc: 1.0000, mean_class_accuracy: 0.8016\n",
      "2021-03-24 21:29:50,484 - mmaction - INFO - Epoch [6][25/44]\tlr: 5.091e-02, eta: 2:18:31, time: 6.965, data_time: 5.991, memory: 20204, top1_acc: 0.8633, top5_acc: 0.9983, loss_cls: 0.3578, loss: 0.3578, grad_norm: 4.3697\n",
      "2021-03-24 21:34:28,680 - mmaction - INFO - Epoch [7][25/44]\tlr: 6.203e-02, eta: 2:15:02, time: 7.168, data_time: 6.192, memory: 20204, top1_acc: 0.8700, top5_acc: 0.9983, loss_cls: 0.3594, loss: 0.3594, grad_norm: 3.4862\n",
      "2021-03-24 21:38:51,003 - mmaction - INFO - Epoch [8][25/44]\tlr: 7.429e-02, eta: 2:10:30, time: 6.668, data_time: 5.691, memory: 20204, top1_acc: 0.8433, top5_acc: 0.9983, loss_cls: 0.4086, loss: 0.4086, grad_norm: 3.8250\n",
      "2021-03-24 21:40:36,587 - mmaction - INFO - Saving checkpoint at 8 epochs\n",
      "2021-03-24 21:43:27,767 - mmaction - INFO - Epoch [9][25/44]\tlr: 8.739e-02, eta: 2:06:44, time: 6.841, data_time: 5.864, memory: 20204, top1_acc: 0.8467, top5_acc: 0.9983, loss_cls: 0.3808, loss: 0.3808, grad_norm: 3.2192\n",
      "2021-03-24 21:47:55,665 - mmaction - INFO - Epoch [10][25/44]\tlr: 1.010e-01, eta: 2:03:01, time: 6.763, data_time: 5.787, memory: 20204, top1_acc: 0.8433, top5_acc: 1.0000, loss_cls: 0.3620, loss: 0.3620, grad_norm: 3.3093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 2.6 task/s, elapsed: 48s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-24 21:50:22,735 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-24 21:50:22,737 - mmaction - INFO - \n",
      "top1_acc\t0.8492\n",
      "top5_acc\t1.0000\n",
      "2021-03-24 21:50:22,737 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-24 21:50:22,739 - mmaction - INFO - \n",
      "mean_acc\t0.8492\n",
      "2021-03-24 21:50:22,912 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_10.pth.\n",
      "2021-03-24 21:50:22,912 - mmaction - INFO - Best top1_acc is 0.8492 at 10 epoch.\n",
      "2021-03-24 21:50:22,913 - mmaction - INFO - Epoch(val) [10][44]\ttop1_acc: 0.8492, top5_acc: 1.0000, mean_class_accuracy: 0.8492\n",
      "2021-03-24 21:53:16,024 - mmaction - INFO - Epoch [11][25/44]\tlr: 1.149e-01, eta: 1:59:43, time: 6.924, data_time: 5.948, memory: 20204, top1_acc: 0.8817, top5_acc: 1.0000, loss_cls: 0.3227, loss: 0.3227, grad_norm: 2.9154\n",
      "2021-03-24 21:57:42,847 - mmaction - INFO - Epoch [12][25/44]\tlr: 1.286e-01, eta: 1:56:20, time: 6.806, data_time: 5.830, memory: 20204, top1_acc: 0.8550, top5_acc: 0.9983, loss_cls: 0.3954, loss: 0.3954, grad_norm: 3.6179\n",
      "2021-03-24 21:59:27,183 - mmaction - INFO - Saving checkpoint at 12 epochs\n",
      "2021-03-24 22:02:22,179 - mmaction - INFO - Epoch [13][25/44]\tlr: 1.419e-01, eta: 1:53:16, time: 6.994, data_time: 6.020, memory: 20204, top1_acc: 0.8467, top5_acc: 0.9967, loss_cls: 0.4247, loss: 0.4247, grad_norm: 2.8231\n",
      "2021-03-24 22:06:52,903 - mmaction - INFO - Epoch [14][25/44]\tlr: 1.545e-01, eta: 1:50:05, time: 6.867, data_time: 5.891, memory: 20204, top1_acc: 0.8617, top5_acc: 1.0000, loss_cls: 0.3434, loss: 0.3434, grad_norm: 2.8790\n",
      "2021-03-24 22:11:20,068 - mmaction - INFO - Epoch [15][25/44]\tlr: 1.659e-01, eta: 1:46:49, time: 6.736, data_time: 5.761, memory: 20204, top1_acc: 0.8483, top5_acc: 1.0000, loss_cls: 0.3807, loss: 0.3807, grad_norm: 3.1518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 2.6 task/s, elapsed: 48s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-24 22:13:51,448 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-24 22:13:51,450 - mmaction - INFO - \n",
      "top1_acc\t0.8254\n",
      "top5_acc\t1.0000\n",
      "2021-03-24 22:13:51,451 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-24 22:13:51,452 - mmaction - INFO - \n",
      "mean_acc\t0.8254\n",
      "2021-03-24 22:13:51,453 - mmaction - INFO - Epoch(val) [15][44]\ttop1_acc: 0.8254, top5_acc: 1.0000, mean_class_accuracy: 0.8254\n",
      "2021-03-24 22:16:43,943 - mmaction - INFO - Epoch [16][25/44]\tlr: 1.761e-01, eta: 1:43:45, time: 6.899, data_time: 5.905, memory: 20204, top1_acc: 0.8417, top5_acc: 1.0000, loss_cls: 0.3540, loss: 0.3540, grad_norm: 2.6687\n",
      "2021-03-24 22:18:21,773 - mmaction - INFO - Saving checkpoint at 16 epochs\n",
      "2021-03-24 22:21:12,732 - mmaction - INFO - Epoch [17][25/44]\tlr: 1.847e-01, eta: 1:40:39, time: 6.831, data_time: 5.806, memory: 20204, top1_acc: 0.8600, top5_acc: 1.0000, loss_cls: 0.3870, loss: 0.3870, grad_norm: 3.2032\n",
      "2021-03-24 22:25:49,296 - mmaction - INFO - Epoch [18][25/44]\tlr: 1.915e-01, eta: 1:37:45, time: 7.039, data_time: 6.065, memory: 20204, top1_acc: 0.8467, top5_acc: 1.0000, loss_cls: 0.3955, loss: 0.3955, grad_norm: 2.7949\n",
      "2021-03-24 22:30:21,211 - mmaction - INFO - Epoch [19][25/44]\tlr: 1.964e-01, eta: 1:34:43, time: 6.867, data_time: 5.877, memory: 20204, top1_acc: 0.8483, top5_acc: 0.9967, loss_cls: 0.4092, loss: 0.4092, grad_norm: 2.6388\n",
      "2021-03-24 22:34:51,821 - mmaction - INFO - Epoch [20][25/44]\tlr: 1.992e-01, eta: 1:31:41, time: 6.859, data_time: 5.879, memory: 20204, top1_acc: 0.8667, top5_acc: 1.0000, loss_cls: 0.3351, loss: 0.3351, grad_norm: 2.3010\n",
      "2021-03-24 22:36:29,026 - mmaction - INFO - Saving checkpoint at 20 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 2.6 task/s, elapsed: 48s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-24 22:37:17,321 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-24 22:37:17,323 - mmaction - INFO - \n",
      "top1_acc\t0.8254\n",
      "top5_acc\t1.0000\n",
      "2021-03-24 22:37:17,323 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-24 22:37:17,325 - mmaction - INFO - \n",
      "mean_acc\t0.8254\n",
      "2021-03-24 22:37:17,326 - mmaction - INFO - Epoch(val) [20][44]\ttop1_acc: 0.8254, top5_acc: 1.0000, mean_class_accuracy: 0.8254\n",
      "2021-03-24 22:40:03,624 - mmaction - INFO - Epoch [21][25/44]\tlr: 2.000e-01, eta: 1:28:33, time: 6.652, data_time: 5.674, memory: 20204, top1_acc: 0.8833, top5_acc: 1.0000, loss_cls: 0.2851, loss: 0.2851, grad_norm: 1.9111\n",
      "2021-03-24 22:44:38,747 - mmaction - INFO - Epoch [22][25/44]\tlr: 1.993e-01, eta: 1:25:35, time: 6.870, data_time: 5.893, memory: 20204, top1_acc: 0.8867, top5_acc: 1.0000, loss_cls: 0.2601, loss: 0.2601, grad_norm: 2.1638\n",
      "2021-03-24 22:49:22,392 - mmaction - INFO - Epoch [23][25/44]\tlr: 1.976e-01, eta: 1:22:50, time: 7.289, data_time: 6.287, memory: 20204, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.5038, loss: 0.5038, grad_norm: 3.5063\n",
      "2021-03-24 22:53:49,042 - mmaction - INFO - Epoch [24][25/44]\tlr: 1.948e-01, eta: 1:19:52, time: 6.871, data_time: 5.877, memory: 20204, top1_acc: 0.8867, top5_acc: 0.9983, loss_cls: 0.2872, loss: 0.2872, grad_norm: 2.0569\n",
      "2021-03-24 22:55:28,710 - mmaction - INFO - Saving checkpoint at 24 epochs\n",
      "2021-03-24 22:58:30,402 - mmaction - INFO - Epoch [25][25/44]\tlr: 1.910e-01, eta: 1:17:04, time: 7.261, data_time: 6.271, memory: 20204, top1_acc: 0.8983, top5_acc: 1.0000, loss_cls: 0.2459, loss: 0.2459, grad_norm: 2.1627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 2.6 task/s, elapsed: 48s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-24 23:00:59,644 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-24 23:00:59,647 - mmaction - INFO - \n",
      "top1_acc\t0.8175\n",
      "top5_acc\t1.0000\n",
      "2021-03-24 23:00:59,648 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-24 23:00:59,651 - mmaction - INFO - \n",
      "mean_acc\t0.8175\n",
      "2021-03-24 23:00:59,652 - mmaction - INFO - Epoch(val) [25][44]\ttop1_acc: 0.8175, top5_acc: 1.0000, mean_class_accuracy: 0.8175\n",
      "2021-03-24 23:03:51,401 - mmaction - INFO - Epoch [26][25/44]\tlr: 1.863e-01, eta: 1:14:06, time: 6.870, data_time: 5.887, memory: 20204, top1_acc: 0.8933, top5_acc: 1.0000, loss_cls: 0.2764, loss: 0.2764, grad_norm: 2.1380\n",
      "2021-03-24 23:08:27,656 - mmaction - INFO - Epoch [27][25/44]\tlr: 1.807e-01, eta: 1:11:07, time: 6.820, data_time: 5.837, memory: 20204, top1_acc: 0.8933, top5_acc: 0.9983, loss_cls: 0.2690, loss: 0.2690, grad_norm: 2.0275\n",
      "2021-03-24 23:12:53,090 - mmaction - INFO - Epoch [28][25/44]\tlr: 1.742e-01, eta: 1:08:04, time: 6.593, data_time: 5.600, memory: 20204, top1_acc: 0.9167, top5_acc: 1.0000, loss_cls: 0.2153, loss: 0.2153, grad_norm: 1.7606\n",
      "2021-03-24 23:14:46,727 - mmaction - INFO - Saving checkpoint at 28 epochs\n",
      "2021-03-24 23:17:38,587 - mmaction - INFO - Epoch [29][25/44]\tlr: 1.669e-01, eta: 1:05:08, time: 6.868, data_time: 5.887, memory: 20204, top1_acc: 0.8950, top5_acc: 1.0000, loss_cls: 0.2431, loss: 0.2431, grad_norm: 1.8443\n",
      "2021-03-24 23:22:12,771 - mmaction - INFO - Epoch [30][25/44]\tlr: 1.590e-01, eta: 1:02:12, time: 6.900, data_time: 5.912, memory: 20204, top1_acc: 0.9117, top5_acc: 1.0000, loss_cls: 0.2420, loss: 0.2420, grad_norm: 2.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 2.6 task/s, elapsed: 49s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-24 23:24:46,975 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-24 23:24:46,977 - mmaction - INFO - \n",
      "top1_acc\t0.8730\n",
      "top5_acc\t1.0000\n",
      "2021-03-24 23:24:46,977 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-24 23:24:46,979 - mmaction - INFO - \n",
      "mean_acc\t0.8730\n",
      "2021-03-24 23:24:47,130 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_30.pth.\n",
      "2021-03-24 23:24:47,131 - mmaction - INFO - Best top1_acc is 0.8730 at 30 epoch.\n",
      "2021-03-24 23:24:47,132 - mmaction - INFO - Epoch(val) [30][44]\ttop1_acc: 0.8730, top5_acc: 1.0000, mean_class_accuracy: 0.8730\n",
      "2021-03-24 23:27:36,817 - mmaction - INFO - Epoch [31][25/44]\tlr: 1.504e-01, eta: 0:59:15, time: 6.787, data_time: 5.808, memory: 20204, top1_acc: 0.9150, top5_acc: 0.9983, loss_cls: 0.2196, loss: 0.2196, grad_norm: 1.8701\n",
      "2021-03-24 23:32:14,860 - mmaction - INFO - Epoch [32][25/44]\tlr: 1.413e-01, eta: 0:56:22, time: 7.025, data_time: 6.044, memory: 20204, top1_acc: 0.9217, top5_acc: 1.0000, loss_cls: 0.1901, loss: 0.1901, grad_norm: 1.7479\n",
      "2021-03-24 23:33:52,908 - mmaction - INFO - Saving checkpoint at 32 epochs\n",
      "2021-03-24 23:36:38,792 - mmaction - INFO - Epoch [33][25/44]\tlr: 1.317e-01, eta: 0:53:23, time: 6.629, data_time: 5.654, memory: 20204, top1_acc: 0.9033, top5_acc: 0.9983, loss_cls: 0.2275, loss: 0.2275, grad_norm: 1.9888\n",
      "2021-03-24 23:41:10,659 - mmaction - INFO - Epoch [34][25/44]\tlr: 1.219e-01, eta: 0:50:26, time: 6.672, data_time: 5.694, memory: 20204, top1_acc: 0.9117, top5_acc: 1.0000, loss_cls: 0.2229, loss: 0.2229, grad_norm: 1.9745\n",
      "2021-03-24 23:45:50,226 - mmaction - INFO - Epoch [35][25/44]\tlr: 1.118e-01, eta: 0:47:31, time: 6.810, data_time: 5.810, memory: 20204, top1_acc: 0.9350, top5_acc: 1.0000, loss_cls: 0.1698, loss: 0.1698, grad_norm: 1.7408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 2.6 task/s, elapsed: 49s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-24 23:48:22,662 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-24 23:48:22,664 - mmaction - INFO - \n",
      "top1_acc\t0.8254\n",
      "top5_acc\t1.0000\n",
      "2021-03-24 23:48:22,665 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-24 23:48:22,667 - mmaction - INFO - \n",
      "mean_acc\t0.8254\n",
      "2021-03-24 23:48:22,668 - mmaction - INFO - Epoch(val) [35][44]\ttop1_acc: 0.8254, top5_acc: 1.0000, mean_class_accuracy: 0.8254\n",
      "2021-03-24 23:51:14,376 - mmaction - INFO - Epoch [36][25/44]\tlr: 1.015e-01, eta: 0:44:36, time: 6.868, data_time: 5.877, memory: 20204, top1_acc: 0.9167, top5_acc: 1.0000, loss_cls: 0.1841, loss: 0.1841, grad_norm: 2.0693\n",
      "2021-03-24 23:52:51,813 - mmaction - INFO - Saving checkpoint at 36 epochs\n",
      "2021-03-24 23:55:40,270 - mmaction - INFO - Epoch [37][25/44]\tlr: 9.127e-02, eta: 0:41:41, time: 6.732, data_time: 5.754, memory: 20204, top1_acc: 0.9533, top5_acc: 1.0000, loss_cls: 0.1247, loss: 0.1247, grad_norm: 1.3474\n",
      "2021-03-25 00:00:14,754 - mmaction - INFO - Epoch [38][25/44]\tlr: 8.111e-02, eta: 0:38:47, time: 6.818, data_time: 5.801, memory: 20204, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.1797, loss: 0.1797, grad_norm: 2.0569\n",
      "2021-03-25 00:04:50,878 - mmaction - INFO - Epoch [39][25/44]\tlr: 7.115e-02, eta: 0:35:52, time: 6.759, data_time: 5.761, memory: 20204, top1_acc: 0.9433, top5_acc: 1.0000, loss_cls: 0.1380, loss: 0.1380, grad_norm: 1.4081\n",
      "2021-03-25 00:09:30,047 - mmaction - INFO - Epoch [40][25/44]\tlr: 6.149e-02, eta: 0:32:59, time: 6.947, data_time: 5.930, memory: 20204, top1_acc: 0.9483, top5_acc: 1.0000, loss_cls: 0.1448, loss: 0.1448, grad_norm: 1.5499\n",
      "2021-03-25 00:11:11,701 - mmaction - INFO - Saving checkpoint at 40 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 2.6 task/s, elapsed: 48s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 00:11:59,894 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 00:11:59,896 - mmaction - INFO - \n",
      "top1_acc\t0.9206\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 00:11:59,897 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 00:11:59,898 - mmaction - INFO - \n",
      "mean_acc\t0.9206\n",
      "2021-03-25 00:12:00,066 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_40.pth.\n",
      "2021-03-25 00:12:00,067 - mmaction - INFO - Best top1_acc is 0.9206 at 40 epoch.\n",
      "2021-03-25 00:12:00,068 - mmaction - INFO - Epoch(val) [40][44]\ttop1_acc: 0.9206, top5_acc: 1.0000, mean_class_accuracy: 0.9206\n",
      "2021-03-25 00:15:02,371 - mmaction - INFO - Epoch [41][25/44]\tlr: 5.224e-02, eta: 0:30:08, time: 7.292, data_time: 6.300, memory: 20204, top1_acc: 0.9417, top5_acc: 1.0000, loss_cls: 0.1471, loss: 0.1471, grad_norm: 1.4060\n",
      "2021-03-25 00:19:40,726 - mmaction - INFO - Epoch [42][25/44]\tlr: 4.349e-02, eta: 0:27:16, time: 7.081, data_time: 6.099, memory: 20204, top1_acc: 0.9417, top5_acc: 0.9983, loss_cls: 0.1504, loss: 0.1504, grad_norm: 1.7364\n",
      "2021-03-25 00:24:19,106 - mmaction - INFO - Epoch [43][25/44]\tlr: 3.534e-02, eta: 0:24:23, time: 7.103, data_time: 6.101, memory: 20204, top1_acc: 0.9533, top5_acc: 0.9983, loss_cls: 0.1330, loss: 0.1330, grad_norm: 1.5412\n",
      "2021-03-25 00:29:08,938 - mmaction - INFO - Epoch [44][25/44]\tlr: 2.786e-02, eta: 0:21:32, time: 7.522, data_time: 6.529, memory: 20204, top1_acc: 0.9633, top5_acc: 1.0000, loss_cls: 0.1166, loss: 0.1166, grad_norm: 1.6169\n",
      "2021-03-25 00:31:25,146 - mmaction - INFO - Saving checkpoint at 44 epochs\n",
      "2021-03-25 00:35:51,517 - mmaction - INFO - Epoch [45][25/44]\tlr: 2.115e-02, eta: 0:18:51, time: 10.648, data_time: 9.640, memory: 20204, top1_acc: 0.9550, top5_acc: 1.0000, loss_cls: 0.1182, loss: 0.1182, grad_norm: 1.4543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 2.6 task/s, elapsed: 49s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 00:39:22,798 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 00:39:22,800 - mmaction - INFO - \n",
      "top1_acc\t0.9048\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 00:39:22,800 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 00:39:22,802 - mmaction - INFO - \n",
      "mean_acc\t0.9048\n",
      "2021-03-25 00:39:22,803 - mmaction - INFO - Epoch(val) [45][44]\ttop1_acc: 0.9048, top5_acc: 1.0000, mean_class_accuracy: 0.9048\n",
      "2021-03-25 00:42:20,754 - mmaction - INFO - Epoch [46][25/44]\tlr: 1.526e-02, eta: 0:15:56, time: 7.118, data_time: 6.136, memory: 20204, top1_acc: 0.9550, top5_acc: 1.0000, loss_cls: 0.1165, loss: 0.1165, grad_norm: 1.5267\n",
      "2021-03-25 00:46:57,192 - mmaction - INFO - Epoch [47][25/44]\tlr: 1.027e-02, eta: 0:12:59, time: 7.019, data_time: 6.046, memory: 20204, top1_acc: 0.9633, top5_acc: 1.0000, loss_cls: 0.0944, loss: 0.0944, grad_norm: 1.2650\n",
      "2021-03-25 00:51:21,230 - mmaction - INFO - Epoch [48][25/44]\tlr: 6.220e-03, eta: 0:10:03, time: 6.794, data_time: 5.818, memory: 20204, top1_acc: 0.9600, top5_acc: 1.0000, loss_cls: 0.0976, loss: 0.0976, grad_norm: 1.2563\n",
      "2021-03-25 00:53:03,163 - mmaction - INFO - Saving checkpoint at 48 epochs\n",
      "2021-03-25 00:55:47,302 - mmaction - INFO - Epoch [49][25/44]\tlr: 3.158e-03, eta: 0:07:07, time: 6.559, data_time: 5.584, memory: 20204, top1_acc: 0.9550, top5_acc: 1.0000, loss_cls: 0.1207, loss: 0.1207, grad_norm: 1.5171\n",
      "2021-03-25 01:00:24,345 - mmaction - INFO - Epoch [50][25/44]\tlr: 1.114e-03, eta: 0:04:11, time: 6.680, data_time: 5.703, memory: 20204, top1_acc: 0.9500, top5_acc: 1.0000, loss_cls: 0.1192, loss: 0.1192, grad_norm: 1.5985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 1.3 task/s, elapsed: 98s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-25 01:03:51,321 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-25 01:03:51,323 - mmaction - INFO - \n",
      "top1_acc\t0.9127\n",
      "top5_acc\t1.0000\n",
      "2021-03-25 01:03:51,324 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-25 01:03:51,326 - mmaction - INFO - \n",
      "mean_acc\t0.9127\n",
      "2021-03-25 01:03:51,327 - mmaction - INFO - Epoch(val) [50][44]\ttop1_acc: 0.9127, top5_acc: 1.0000, mean_class_accuracy: 0.9127\n",
      "2021-03-25 01:06:43,848 - mmaction - INFO - Epoch [51][25/44]\tlr: 1.108e-04, eta: 0:01:15, time: 6.901, data_time: 5.915, memory: 20204, top1_acc: 0.9583, top5_acc: 1.0000, loss_cls: 0.0970, loss: 0.0970, grad_norm: 1.2868\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model50e\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 1.1 task/s, elapsed: 120s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.9365\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.9365\n",
      "top1_acc: 0.9365\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.9365\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmaction.models import build_model\n",
    "from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=4,\n",
    "        workers_per_gpu=1,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'], yticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# CSN 97.62%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "64CW6d_AaT-Q",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-28 21:54:04--  https://download.openmmlab.com/mmaction/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.254.186.225\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.254.186.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 119580180 (114M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth’\n",
      "\n",
      "checkpoints/ircsn_i 100%[===================>] 114,04M  7,32MB/s    in 18s     \n",
      "\n",
      "2021-03-28 21:54:27 (6,46 MB/s) - ‘checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth’ saved [119580180/119580180]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth \\\n",
    "      -O checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "64CW6d_AaT-Q",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-29 21:25:47--  https://download.openmmlab.com/mmaction/recognition/csn/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb_20200803-fc66ce8d.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.254.186.225\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.254.186.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 119580092 (114M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb_20200803-fc66ce8d.pth’\n",
      "\n",
      "checkpoints/ircsn_i 100%[===================>] 114,04M  4,39MB/s    in 28s     \n",
      "\n",
      "2021-03-29 21:26:21 (4,13 MB/s) - ‘checkpoints/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb_20200803-fc66ce8d.pth’ saved [119580092/119580092]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/csn/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb_20200803-fc66ce8d.pth \\\n",
    "      -O checkpoints/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb_20200803-fc66ce8d.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from mmcv import Config\n",
    "# cfg = Config.fromfile('./configs/recognition/csn/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlhu9byjjt-K",
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='ResNet3dCSN',\n",
      "        pretrained2d=False,\n",
      "        pretrained=\n",
      "        'https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r152_ig65m_20200807-771c4135.pth',\n",
      "        depth=152,\n",
      "        with_pool2=False,\n",
      "        bottleneck_mode='ir',\n",
      "        norm_eval=True,\n",
      "        zero_init_residual=False,\n",
      "        bn_frozen=True,\n",
      "        in_channels=2),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        num_classes=7,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "dataset_type = 'RawframeDataset'\n",
      "data_root = 'data/childact_rawframe/train/'\n",
      "data_root_val = 'data/childact_rawframe/val/'\n",
      "ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
      "ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
      "ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
      "img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
      "train_pipeline = [\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=10,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_train_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/train/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    val=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_val_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/val/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    test=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_test_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/test/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=10,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'))\n",
      "optimizer = dict(type='SGD', lr=0.000125, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(10, 1e-05),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "total_epochs = 51\n",
      "checkpoint_config = dict(interval=12)\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "log_config = dict(\n",
      "    interval=100,\n",
      "    hooks=[dict(type='TextLoggerHook'),\n",
      "           dict(type='TensorboardLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "work_dir = './childact-checkpoints/childact-CSN'\n",
      "load_from = 'checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "find_unused_parameters = True\n",
      "omnisource = False\n",
      "momentum_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(0.8947368421052632, 1),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/childact-CSN/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_rawframe/train/'\n",
    "cfg.data_root_val = 'data/childact_rawframe/val/'\n",
    "cfg.ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "\n",
    "# cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_rawframe/test/'\n",
    "\n",
    "# cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_rawframe/train/'\n",
    "\n",
    "# cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_rawframe/val/'\n",
    "\n",
    "cfg.data.test.modality = 'Flow'\n",
    "cfg.data.val.modality = 'Flow'\n",
    "cfg.data.train.modality = 'Flow'\n",
    "\n",
    "cfg.data.train.start_index = 0\n",
    "cfg.data.test.start_index = 0\n",
    "cfg.data.val.start_index = 0\n",
    "\n",
    "cfg.data.test.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.train.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.val.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = 'checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/childact-CSN'\n",
    "\n",
    "cfg.img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
    "\n",
    "\n",
    "cfg.val_pipeline = [\n",
    "    dict(\n",
    "        type='SampleFrames',\n",
    "        clip_len=32,\n",
    "        frame_interval=2,\n",
    "        num_clips=1,\n",
    "        test_mode=True),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "#     dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "#     dict(type='Flip', flip_ratio=0.5)\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=10, test_mode=True),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='RandomCrop', size=224),\n",
    "    dict(type='RandomResizedCrop'),\n",
    "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "#     dict(type='Flip', flip_ratio=0.5),\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
    "]\n",
    "\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.val.pipeline = cfg.val_pipeline\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "# cfg.data.videos_per_gpu = 24\n",
    "# cfg.optimizer.type = 'Adam'\n",
    "# cfg.optimizer.weight_decay=0.0001\n",
    "\n",
    "# cfg.optimizer_config.grad_clip=None\n",
    "# cfg.optimizer.lr = 0.01\n",
    "\n",
    "cfg.lr_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(10, 1e-5),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "cfg.total_epochs = 51\n",
    "\n",
    "cfg.momentum_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(0.85 / 0.95, 1),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 12\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.data.videos_per_gpu=8\n",
    "\n",
    "cfg.model.backbone.in_channels = 2\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 00:19:33,457 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r152_ig65m_20200807-771c4135.pth\n",
      "2021-03-31 00:19:33,458 - mmaction - INFO - Use load_from_http loader\n",
      "2021-03-31 00:19:33,627 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for conv1.conv.weight: copying a param with shape torch.Size([64, 3, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 2, 3, 7, 7]).\n",
      "2021-03-31 00:19:36,157 - mmaction - INFO - load checkpoint from checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth\n",
      "2021-03-31 00:19:36,158 - mmaction - INFO - Use load_from_local loader\n",
      "2021-03-31 00:19:36,339 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for backbone.conv1.conv.weight: copying a param with shape torch.Size([64, 3, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 2, 3, 7, 7]).\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([7, 2048]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([7]).\n",
      "2021-03-31 00:19:36,345 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /home/actrec/.virtualenvs/mmaction/mmaction2/childact-checkpoints/childact-CSN\n",
      "2021-03-31 00:19:36,345 - mmaction - INFO - workflow: [('train', 1)], max: 51 epochs\n",
      "/home/actrec/.virtualenvs/mmaction/mmaction2/mmaction/core/evaluation/eval_hooks.py:131: UserWarning: runner.meta is None. Creating a empty one.\n",
      "  warnings.warn('runner.meta is None. Creating a empty one.')\n",
      "2021-03-31 00:22:58,472 - mmaction - INFO - Epoch [1][100/132]\tlr: 1.287e-04, eta: 3:43:21, time: 2.021, data_time: 0.031, memory: 21787, top1_acc: 0.1437, top5_acc: 0.6875, loss_cls: 1.9549, loss: 1.9549, grad_norm: 5.0368\n",
      "2021-03-31 00:27:15,621 - mmaction - INFO - Epoch [2][100/132]\tlr: 1.453e-04, eta: 3:06:02, time: 1.963, data_time: 0.029, memory: 21787, top1_acc: 0.1212, top5_acc: 0.7275, loss_cls: 1.9467, loss: 1.9467, grad_norm: 1.3383\n",
      "2021-03-31 00:31:31,788 - mmaction - INFO - Epoch [3][100/132]\tlr: 1.747e-04, eta: 2:53:08, time: 1.954, data_time: 0.031, memory: 21787, top1_acc: 0.1475, top5_acc: 0.7388, loss_cls: 1.9456, loss: 1.9456, grad_norm: 1.3923\n",
      "2021-03-31 00:35:47,940 - mmaction - INFO - Epoch [4][100/132]\tlr: 2.163e-04, eta: 2:45:22, time: 1.954, data_time: 0.030, memory: 21787, top1_acc: 0.1825, top5_acc: 0.7188, loss_cls: 1.9455, loss: 1.9455, grad_norm: 1.6199\n",
      "2021-03-31 00:40:03,748 - mmaction - INFO - Epoch [5][100/132]\tlr: 2.690e-04, eta: 2:39:27, time: 1.952, data_time: 0.030, memory: 21787, top1_acc: 0.1450, top5_acc: 0.7625, loss_cls: 1.9266, loss: 1.9266, grad_norm: 4.2586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.5 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 00:41:11,735 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 00:41:11,736 - mmaction - INFO - \n",
      "top1_acc\t0.3413\n",
      "top5_acc\t0.9762\n",
      "2021-03-31 00:41:11,737 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 00:41:11,738 - mmaction - INFO - \n",
      "mean_acc\t0.3413\n",
      "2021-03-31 00:41:12,076 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
      "2021-03-31 00:41:12,077 - mmaction - INFO - Best top1_acc is 0.3413 at 5 epoch.\n",
      "2021-03-31 00:41:12,078 - mmaction - INFO - Epoch(val) [5][132]\ttop1_acc: 0.3413, top5_acc: 0.9762, mean_class_accuracy: 0.3413\n",
      "2021-03-31 00:44:27,227 - mmaction - INFO - Epoch [6][100/132]\tlr: 3.316e-04, eta: 2:34:28, time: 1.951, data_time: 0.030, memory: 21787, top1_acc: 0.2938, top5_acc: 0.9050, loss_cls: 1.7022, loss: 1.7022, grad_norm: 19.4689\n",
      "2021-03-31 00:48:42,961 - mmaction - INFO - Epoch [7][100/132]\tlr: 4.027e-04, eta: 2:29:59, time: 1.950, data_time: 0.029, memory: 21787, top1_acc: 0.4412, top5_acc: 0.9400, loss_cls: 1.3115, loss: 1.3115, grad_norm: 29.7646\n",
      "2021-03-31 00:52:58,934 - mmaction - INFO - Epoch [8][100/132]\tlr: 4.805e-04, eta: 2:25:50, time: 1.953, data_time: 0.030, memory: 21787, top1_acc: 0.5363, top5_acc: 0.9550, loss_cls: 1.1724, loss: 1.1724, grad_norm: 23.8277\n",
      "2021-03-31 00:57:14,770 - mmaction - INFO - Epoch [9][100/132]\tlr: 5.632e-04, eta: 2:21:53, time: 1.952, data_time: 0.029, memory: 21787, top1_acc: 0.5600, top5_acc: 0.9525, loss_cls: 1.1253, loss: 1.1253, grad_norm: 25.6989\n",
      "2021-03-31 01:01:30,672 - mmaction - INFO - Epoch [10][100/132]\tlr: 6.488e-04, eta: 2:18:04, time: 1.952, data_time: 0.030, memory: 21787, top1_acc: 0.5763, top5_acc: 0.9500, loss_cls: 1.0747, loss: 1.0747, grad_norm: 23.0445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.6 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 01:02:38,583 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 01:02:38,585 - mmaction - INFO - \n",
      "top1_acc\t0.6508\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 01:02:38,586 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 01:02:38,588 - mmaction - INFO - \n",
      "mean_acc\t0.6508\n",
      "2021-03-31 01:02:38,959 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_10.pth.\n",
      "2021-03-31 01:02:38,960 - mmaction - INFO - Best top1_acc is 0.6508 at 10 epoch.\n",
      "2021-03-31 01:02:38,961 - mmaction - INFO - Epoch(val) [10][132]\ttop1_acc: 0.6508, top5_acc: 0.9921, mean_class_accuracy: 0.6508\n",
      "2021-03-31 01:05:54,031 - mmaction - INFO - Epoch [11][100/132]\tlr: 7.354e-04, eta: 2:14:22, time: 1.951, data_time: 0.029, memory: 21787, top1_acc: 0.6125, top5_acc: 0.9650, loss_cls: 0.9817, loss: 0.9817, grad_norm: 19.4048\n",
      "2021-03-31 01:10:09,967 - mmaction - INFO - Epoch [12][100/132]\tlr: 8.208e-04, eta: 2:10:44, time: 1.952, data_time: 0.031, memory: 21787, top1_acc: 0.6300, top5_acc: 0.9613, loss_cls: 0.9476, loss: 0.9476, grad_norm: 17.1123\n",
      "2021-03-31 01:11:10,622 - mmaction - INFO - Saving checkpoint at 12 epochs\n",
      "2021-03-31 01:14:25,972 - mmaction - INFO - Epoch [13][100/132]\tlr: 9.031e-04, eta: 2:07:10, time: 1.950, data_time: 0.029, memory: 21787, top1_acc: 0.5863, top5_acc: 0.9700, loss_cls: 1.0291, loss: 1.0291, grad_norm: 17.7710\n",
      "2021-03-31 01:18:41,837 - mmaction - INFO - Epoch [14][100/132]\tlr: 9.802e-04, eta: 2:03:38, time: 1.952, data_time: 0.030, memory: 21787, top1_acc: 0.6550, top5_acc: 0.9550, loss_cls: 0.9138, loss: 0.9138, grad_norm: 17.0397\n",
      "2021-03-31 01:22:57,711 - mmaction - INFO - Epoch [15][100/132]\tlr: 1.050e-03, eta: 2:00:09, time: 1.952, data_time: 0.030, memory: 21787, top1_acc: 0.6450, top5_acc: 0.9613, loss_cls: 0.9461, loss: 0.9461, grad_norm: 16.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.7 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 01:24:05,585 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 01:24:05,587 - mmaction - INFO - \n",
      "top1_acc\t0.8095\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 01:24:05,587 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 01:24:05,589 - mmaction - INFO - \n",
      "mean_acc\t0.8095\n",
      "2021-03-31 01:24:05,961 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_15.pth.\n",
      "2021-03-31 01:24:05,962 - mmaction - INFO - Best top1_acc is 0.8095 at 15 epoch.\n",
      "2021-03-31 01:24:05,962 - mmaction - INFO - Epoch(val) [15][132]\ttop1_acc: 0.8095, top5_acc: 0.9921, mean_class_accuracy: 0.8095\n",
      "2021-03-31 01:27:20,911 - mmaction - INFO - Epoch [16][100/132]\tlr: 1.112e-03, eta: 1:56:42, time: 1.949, data_time: 0.029, memory: 21787, top1_acc: 0.6663, top5_acc: 0.9563, loss_cls: 0.8675, loss: 0.8675, grad_norm: 13.1629\n",
      "2021-03-31 01:31:36,855 - mmaction - INFO - Epoch [17][100/132]\tlr: 1.164e-03, eta: 1:53:16, time: 1.953, data_time: 0.032, memory: 21787, top1_acc: 0.6687, top5_acc: 0.9575, loss_cls: 0.8587, loss: 0.8587, grad_norm: 14.4016\n",
      "2021-03-31 01:35:52,564 - mmaction - INFO - Epoch [18][100/132]\tlr: 1.204e-03, eta: 1:49:51, time: 1.950, data_time: 0.029, memory: 21787, top1_acc: 0.6637, top5_acc: 0.9587, loss_cls: 0.8492, loss: 0.8492, grad_norm: 14.4181\n",
      "2021-03-31 01:40:08,382 - mmaction - INFO - Epoch [19][100/132]\tlr: 1.232e-03, eta: 1:46:27, time: 1.952, data_time: 0.030, memory: 21787, top1_acc: 0.6613, top5_acc: 0.9712, loss_cls: 0.8785, loss: 0.8785, grad_norm: 14.2126\n",
      "2021-03-31 01:44:24,174 - mmaction - INFO - Epoch [20][100/132]\tlr: 1.247e-03, eta: 1:43:04, time: 1.952, data_time: 0.030, memory: 21787, top1_acc: 0.6725, top5_acc: 0.9500, loss_cls: 0.8768, loss: 0.8768, grad_norm: 12.6922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.9 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 01:45:31,966 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 01:45:31,968 - mmaction - INFO - \n",
      "top1_acc\t0.8254\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 01:45:31,968 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 01:45:31,969 - mmaction - INFO - \n",
      "mean_acc\t0.8254\n",
      "2021-03-31 01:45:32,325 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_20.pth.\n",
      "2021-03-31 01:45:32,326 - mmaction - INFO - Best top1_acc is 0.8254 at 20 epoch.\n",
      "2021-03-31 01:45:32,327 - mmaction - INFO - Epoch(val) [20][132]\ttop1_acc: 0.8254, top5_acc: 0.9921, mean_class_accuracy: 0.8254\n",
      "2021-03-31 01:48:47,597 - mmaction - INFO - Epoch [21][100/132]\tlr: 1.250e-03, eta: 1:39:43, time: 1.953, data_time: 0.031, memory: 21787, top1_acc: 0.6650, top5_acc: 0.9525, loss_cls: 0.8718, loss: 0.8718, grad_norm: 12.2906\n",
      "2021-03-31 01:53:03,316 - mmaction - INFO - Epoch [22][100/132]\tlr: 1.244e-03, eta: 1:36:21, time: 1.951, data_time: 0.029, memory: 21787, top1_acc: 0.6775, top5_acc: 0.9637, loss_cls: 0.8345, loss: 0.8345, grad_norm: 12.3174\n",
      "2021-03-31 01:57:19,142 - mmaction - INFO - Epoch [23][100/132]\tlr: 1.232e-03, eta: 1:33:00, time: 1.951, data_time: 0.029, memory: 21787, top1_acc: 0.6562, top5_acc: 0.9625, loss_cls: 0.8391, loss: 0.8391, grad_norm: 14.6783\n",
      "2021-03-31 02:01:34,882 - mmaction - INFO - Epoch [24][100/132]\tlr: 1.213e-03, eta: 1:29:40, time: 1.951, data_time: 0.029, memory: 21787, top1_acc: 0.6763, top5_acc: 0.9537, loss_cls: 0.8472, loss: 0.8472, grad_norm: 12.3530\n",
      "2021-03-31 02:02:35,471 - mmaction - INFO - Saving checkpoint at 24 epochs\n",
      "2021-03-31 02:05:50,894 - mmaction - INFO - Epoch [25][100/132]\tlr: 1.189e-03, eta: 1:26:20, time: 1.951, data_time: 0.029, memory: 21787, top1_acc: 0.6737, top5_acc: 0.9587, loss_cls: 0.8308, loss: 0.8308, grad_norm: 11.8398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.5 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 02:06:58,836 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 02:06:58,837 - mmaction - INFO - \n",
      "top1_acc\t0.8730\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 02:06:58,838 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 02:06:58,841 - mmaction - INFO - \n",
      "mean_acc\t0.8730\n",
      "2021-03-31 02:06:59,234 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_25.pth.\n",
      "2021-03-31 02:06:59,235 - mmaction - INFO - Best top1_acc is 0.8730 at 25 epoch.\n",
      "2021-03-31 02:06:59,236 - mmaction - INFO - Epoch(val) [25][132]\ttop1_acc: 0.8730, top5_acc: 0.9921, mean_class_accuracy: 0.8730\n",
      "2021-03-31 02:10:14,284 - mmaction - INFO - Epoch [26][100/132]\tlr: 1.158e-03, eta: 1:23:00, time: 1.950, data_time: 0.029, memory: 21787, top1_acc: 0.6863, top5_acc: 0.9675, loss_cls: 0.7419, loss: 0.7419, grad_norm: 11.4448\n",
      "2021-03-31 02:14:30,088 - mmaction - INFO - Epoch [27][100/132]\tlr: 1.122e-03, eta: 1:19:41, time: 1.951, data_time: 0.029, memory: 21787, top1_acc: 0.7163, top5_acc: 0.9688, loss_cls: 0.7329, loss: 0.7329, grad_norm: 11.0152\n",
      "2021-03-31 02:18:45,829 - mmaction - INFO - Epoch [28][100/132]\tlr: 1.080e-03, eta: 1:16:22, time: 1.951, data_time: 0.030, memory: 21787, top1_acc: 0.7125, top5_acc: 0.9663, loss_cls: 0.7120, loss: 0.7120, grad_norm: 9.0206\n",
      "2021-03-31 02:23:01,594 - mmaction - INFO - Epoch [29][100/132]\tlr: 1.034e-03, eta: 1:13:03, time: 1.951, data_time: 0.029, memory: 21787, top1_acc: 0.7150, top5_acc: 0.9625, loss_cls: 0.7790, loss: 0.7790, grad_norm: 10.8102\n",
      "2021-03-31 02:27:17,354 - mmaction - INFO - Epoch [30][100/132]\tlr: 9.833e-04, eta: 1:09:44, time: 1.951, data_time: 0.029, memory: 21787, top1_acc: 0.6937, top5_acc: 0.9525, loss_cls: 0.7706, loss: 0.7706, grad_norm: 9.8952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.4 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 02:28:25,322 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 02:28:25,323 - mmaction - INFO - \n",
      "top1_acc\t0.9048\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 02:28:25,324 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 02:28:25,325 - mmaction - INFO - \n",
      "mean_acc\t0.9048\n",
      "2021-03-31 02:28:25,706 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_30.pth.\n",
      "2021-03-31 02:28:25,707 - mmaction - INFO - Best top1_acc is 0.9048 at 30 epoch.\n",
      "2021-03-31 02:28:25,708 - mmaction - INFO - Epoch(val) [30][132]\ttop1_acc: 0.9048, top5_acc: 0.9921, mean_class_accuracy: 0.9048\n",
      "2021-03-31 02:31:40,756 - mmaction - INFO - Epoch [31][100/132]\tlr: 9.289e-04, eta: 1:06:26, time: 1.950, data_time: 0.030, memory: 21787, top1_acc: 0.7200, top5_acc: 0.9637, loss_cls: 0.7187, loss: 0.7187, grad_norm: 9.0214\n",
      "2021-03-31 02:35:56,706 - mmaction - INFO - Epoch [32][100/132]\tlr: 8.713e-04, eta: 1:03:08, time: 1.952, data_time: 0.031, memory: 21787, top1_acc: 0.7362, top5_acc: 0.9637, loss_cls: 0.6791, loss: 0.6791, grad_norm: 9.0725\n",
      "2021-03-31 02:40:12,482 - mmaction - INFO - Epoch [33][100/132]\tlr: 8.112e-04, eta: 0:59:50, time: 1.951, data_time: 0.029, memory: 21787, top1_acc: 0.7400, top5_acc: 0.9650, loss_cls: 0.7027, loss: 0.7027, grad_norm: 10.6142\n",
      "2021-03-31 02:44:28,382 - mmaction - INFO - Epoch [34][100/132]\tlr: 7.491e-04, eta: 0:56:32, time: 1.951, data_time: 0.029, memory: 21787, top1_acc: 0.7275, top5_acc: 0.9600, loss_cls: 0.7119, loss: 0.7119, grad_norm: 8.7767\n",
      "2021-03-31 02:48:44,111 - mmaction - INFO - Epoch [35][100/132]\tlr: 6.857e-04, eta: 0:53:15, time: 1.951, data_time: 0.030, memory: 21787, top1_acc: 0.7588, top5_acc: 0.9762, loss_cls: 0.6441, loss: 0.6441, grad_norm: 12.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.7 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 02:49:51,978 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 02:49:51,980 - mmaction - INFO - \n",
      "top1_acc\t0.8968\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 02:49:51,981 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 02:49:51,983 - mmaction - INFO - \n",
      "mean_acc\t0.8968\n",
      "2021-03-31 02:49:51,984 - mmaction - INFO - Epoch(val) [35][132]\ttop1_acc: 0.8968, top5_acc: 0.9921, mean_class_accuracy: 0.8968\n",
      "2021-03-31 02:53:07,100 - mmaction - INFO - Epoch [36][100/132]\tlr: 6.216e-04, eta: 0:49:57, time: 1.951, data_time: 0.029, memory: 21787, top1_acc: 0.7425, top5_acc: 0.9688, loss_cls: 0.6508, loss: 0.6508, grad_norm: 9.7295\n",
      "2021-03-31 02:54:07,730 - mmaction - INFO - Saving checkpoint at 36 epochs\n",
      "2021-03-31 02:57:23,287 - mmaction - INFO - Epoch [37][100/132]\tlr: 5.576e-04, eta: 0:46:40, time: 1.952, data_time: 0.030, memory: 21787, top1_acc: 0.7588, top5_acc: 0.9725, loss_cls: 0.6332, loss: 0.6332, grad_norm: 10.7476\n",
      "2021-03-31 03:01:39,091 - mmaction - INFO - Epoch [38][100/132]\tlr: 4.943e-04, eta: 0:43:23, time: 1.951, data_time: 0.031, memory: 21787, top1_acc: 0.7212, top5_acc: 0.9675, loss_cls: 0.6879, loss: 0.6879, grad_norm: 9.6850\n",
      "2021-03-31 03:05:54,765 - mmaction - INFO - Epoch [39][100/132]\tlr: 4.323e-04, eta: 0:40:06, time: 1.950, data_time: 0.029, memory: 21787, top1_acc: 0.7488, top5_acc: 0.9600, loss_cls: 0.6471, loss: 0.6471, grad_norm: 9.3502\n",
      "2021-03-31 03:10:10,733 - mmaction - INFO - Epoch [40][100/132]\tlr: 3.724e-04, eta: 0:36:49, time: 1.953, data_time: 0.031, memory: 21787, top1_acc: 0.7638, top5_acc: 0.9712, loss_cls: 0.6148, loss: 0.6148, grad_norm: 9.6621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.8 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 03:11:18,639 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 03:11:18,641 - mmaction - INFO - \n",
      "top1_acc\t0.8571\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 03:11:18,642 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 03:11:18,643 - mmaction - INFO - \n",
      "mean_acc\t0.8571\n",
      "2021-03-31 03:11:18,644 - mmaction - INFO - Epoch(val) [40][132]\ttop1_acc: 0.8571, top5_acc: 0.9921, mean_class_accuracy: 0.8571\n",
      "2021-03-31 03:14:33,736 - mmaction - INFO - Epoch [41][100/132]\tlr: 3.152e-04, eta: 0:33:32, time: 1.951, data_time: 0.029, memory: 21787, top1_acc: 0.7600, top5_acc: 0.9700, loss_cls: 0.6333, loss: 0.6333, grad_norm: 10.3063\n",
      "2021-03-31 03:18:49,499 - mmaction - INFO - Epoch [42][100/132]\tlr: 2.612e-04, eta: 0:30:15, time: 1.952, data_time: 0.030, memory: 21787, top1_acc: 0.7887, top5_acc: 0.9725, loss_cls: 0.6009, loss: 0.6009, grad_norm: 9.9502\n",
      "2021-03-31 03:23:05,287 - mmaction - INFO - Epoch [43][100/132]\tlr: 2.110e-04, eta: 0:26:59, time: 1.952, data_time: 0.031, memory: 21787, top1_acc: 0.7712, top5_acc: 0.9775, loss_cls: 0.5878, loss: 0.5878, grad_norm: 10.2350\n",
      "2021-03-31 03:27:21,016 - mmaction - INFO - Epoch [44][100/132]\tlr: 1.652e-04, eta: 0:23:42, time: 1.951, data_time: 0.029, memory: 21787, top1_acc: 0.7825, top5_acc: 0.9800, loss_cls: 0.5489, loss: 0.5489, grad_norm: 8.9255\n",
      "2021-03-31 03:31:37,013 - mmaction - INFO - Epoch [45][100/132]\tlr: 1.243e-04, eta: 0:20:25, time: 1.953, data_time: 0.032, memory: 21787, top1_acc: 0.7850, top5_acc: 0.9750, loss_cls: 0.5603, loss: 0.5603, grad_norm: 9.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.5 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 03:32:44,908 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 03:32:44,909 - mmaction - INFO - \n",
      "top1_acc\t0.8889\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 03:32:44,910 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 03:32:44,911 - mmaction - INFO - \n",
      "mean_acc\t0.8889\n",
      "2021-03-31 03:32:44,911 - mmaction - INFO - Epoch(val) [45][132]\ttop1_acc: 0.8889, top5_acc: 0.9921, mean_class_accuracy: 0.8889\n",
      "2021-03-31 03:36:00,053 - mmaction - INFO - Epoch [46][100/132]\tlr: 8.858e-05, eta: 0:17:09, time: 1.951, data_time: 0.030, memory: 21787, top1_acc: 0.7525, top5_acc: 0.9688, loss_cls: 0.6210, loss: 0.6210, grad_norm: 10.5199\n",
      "2021-03-31 03:40:15,735 - mmaction - INFO - Epoch [47][100/132]\tlr: 5.854e-05, eta: 0:13:52, time: 1.950, data_time: 0.029, memory: 21787, top1_acc: 0.7900, top5_acc: 0.9700, loss_cls: 0.5427, loss: 0.5427, grad_norm: 9.7076\n",
      "2021-03-31 03:44:31,750 - mmaction - INFO - Epoch [48][100/132]\tlr: 3.446e-05, eta: 0:10:36, time: 1.953, data_time: 0.031, memory: 21787, top1_acc: 0.7837, top5_acc: 0.9775, loss_cls: 0.5457, loss: 0.5457, grad_norm: 10.5360\n",
      "2021-03-31 03:45:32,630 - mmaction - INFO - Saving checkpoint at 48 epochs\n",
      "2021-03-31 03:48:48,041 - mmaction - INFO - Epoch [49][100/132]\tlr: 1.660e-05, eta: 0:07:20, time: 1.951, data_time: 0.030, memory: 21787, top1_acc: 0.7688, top5_acc: 0.9700, loss_cls: 0.5722, loss: 0.5722, grad_norm: 9.3274\n",
      "2021-03-31 03:53:03,950 - mmaction - INFO - Epoch [50][100/132]\tlr: 5.139e-06, eta: 0:04:03, time: 1.952, data_time: 0.029, memory: 21787, top1_acc: 0.7662, top5_acc: 0.9750, loss_cls: 0.5814, loss: 0.5814, grad_norm: 10.3221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.4 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 03:54:12,138 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 03:54:12,140 - mmaction - INFO - \n",
      "top1_acc\t0.8968\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 03:54:12,141 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 03:54:12,143 - mmaction - INFO - \n",
      "mean_acc\t0.8968\n",
      "2021-03-31 03:54:12,144 - mmaction - INFO - Epoch(val) [50][132]\ttop1_acc: 0.8968, top5_acc: 0.9921, mean_class_accuracy: 0.8968\n",
      "2021-03-31 03:57:27,564 - mmaction - INFO - Epoch [51][100/132]\tlr: 2.070e-07, eta: 0:00:47, time: 1.954, data_time: 0.029, memory: 21787, top1_acc: 0.7625, top5_acc: 0.9738, loss_cls: 0.5954, loss: 0.5954, grad_norm: 9.0673\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model50e\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 0.7 task/s, elapsed: 183s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.9762\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.9762\n",
      "top1_acc: 0.9762\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmaction.models import build_model\n",
    "from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=4,\n",
    "        workers_per_gpu=1,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'], yticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# TANet 96.03%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64CW6d_AaT-Q",
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-29 00:29:51--  https://download.openmmlab.com/mmaction/recognition/tanet/tanet_r50_dense_1x1x8_100e_kinetics400_rgb/tanet_r50_dense_1x1x8_100e_kinetics400_rgb_20210219-032c8e94.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.254.186.225\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.254.186.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 102681749 (98M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/tanet_r50_dense_1x1x8_100e_kinetics400_rgb_20210219-032c8e94.pth’\n",
      "\n",
      "checkpoints/tanet_r 100%[===================>]  97,92M  11,1MB/s    in 9,1s    \n",
      "\n",
      "2021-03-29 00:30:03 (10,8 MB/s) - ‘checkpoints/tanet_r50_dense_1x1x8_100e_kinetics400_rgb_20210219-032c8e94.pth’ saved [102681749/102681749]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/tanet/tanet_r50_dense_1x1x8_100e_kinetics400_rgb/tanet_r50_dense_1x1x8_100e_kinetics400_rgb_20210219-032c8e94.pth \\\n",
    "      -O checkpoints/tanet_r50_dense_1x1x8_100e_kinetics400_rgb_20210219-032c8e94.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/tanet/tanet_r50_dense_1x1x8_100e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer2D',\n",
      "    backbone=dict(\n",
      "        type='TANet',\n",
      "        pretrained='torchvision://resnet50',\n",
      "        depth=50,\n",
      "        num_segments=8,\n",
      "        tam_cfg=dict(),\n",
      "        in_channels=2),\n",
      "    cls_head=dict(\n",
      "        type='TSMHead',\n",
      "        num_classes=7,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        consensus=dict(type='AvgConsensus', dim=1),\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.001),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "checkpoint_config = dict(interval=12)\n",
      "log_config = dict(interval=25, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/tanet_r50_dense_1x1x8_100e_kinetics400_rgb_20210219-032c8e94.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'RawframeDataset'\n",
      "data_root = 'data/childact_rawframe/train/'\n",
      "data_root_val = 'data/childact_rawframe/val/'\n",
      "ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
      "ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
      "ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
      "img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
      "train_pipeline = [\n",
      "    dict(type='DenseSampleFrames', clip_len=1, frame_interval=1, num_clips=8),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCHW_Flow'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        type='DenseSampleFrames',\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=8,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCHW_Flow'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='DenseSampleFrames',\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=8,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='ThreeCrop', crop_size=256),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCHW_Flow'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    test_dataloader=dict(videos_per_gpu=2),\n",
      "    train=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_train_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/train/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='DenseSampleFrames',\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=8),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCHW_Flow'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    val=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_val_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/val/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='DenseSampleFrames',\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=8,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCHW_Flow'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    test=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_test_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/test/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='DenseSampleFrames',\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=8,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='ThreeCrop', crop_size=256),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCHW_Flow'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'))\n",
      "evaluation = dict(\n",
      "    interval=2, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "optimizer = dict(\n",
      "    type='SGD',\n",
      "    constructor='TSMOptimizerConstructor',\n",
      "    paramwise_cfg=dict(fc_lr5=True),\n",
      "    lr=0.01,\n",
      "    momentum=0.9,\n",
      "    weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=20, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(10, 1e-05),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "total_epochs = 51\n",
      "work_dir = './childact-checkpoints/childact-TANet'\n",
      "omnisource = False\n",
      "momentum_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(0.8947368421052632, 1),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/childact-TANet/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_rawframe/train/'\n",
    "cfg.data_root_val = 'data/childact_rawframe/val/'\n",
    "cfg.ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "\n",
    "# cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_rawframe/test/'\n",
    "\n",
    "# cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_rawframe/train/'\n",
    "\n",
    "# cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_rawframe/val/'\n",
    "\n",
    "cfg.data.test.modality = 'Flow'\n",
    "cfg.data.val.modality = 'Flow'\n",
    "cfg.data.train.modality = 'Flow'\n",
    "\n",
    "cfg.data.train.start_index = 0\n",
    "cfg.data.test.start_index = 0\n",
    "cfg.data.val.start_index = 0\n",
    "\n",
    "cfg.data.test.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.train.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.val.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = 'checkpoints/tanet_r50_dense_1x1x8_100e_kinetics400_rgb_20210219-032c8e94.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/childact-TANet'\n",
    "\n",
    "# cfg.train_pipeline[1] = dict(type='RawFrameDecode')\n",
    "# cfg.test_pipeline[1] = dict(type='RawFrameDecode')\n",
    "# cfg.val_pipeline[1] = dict(type='RawFrameDecode')\n",
    "\n",
    "cfg.img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
    "\n",
    "cfg.train_pipeline[7].input_format = 'NCHW_Flow'\n",
    "cfg.test_pipeline[5].input_format = 'NCHW_Flow'\n",
    "cfg.val_pipeline[5].input_format = 'NCHW_Flow'\n",
    "\n",
    "cfg.train_pipeline[6] = dict(type='Normalize', mean=[128, 128], std=[128, 128])\n",
    "cfg.test_pipeline[4] = dict(type='Normalize', mean=[128, 128], std=[128, 128])\n",
    "cfg.val_pipeline[4] = dict(type='Normalize', mean=[128, 128], std=[128, 128])\n",
    "\n",
    "# cfg.train_pipeline[0].clip_len = 1\n",
    "# cfg.test_pipeline[0].clip_len = 1\n",
    "# cfg.val_pipeline[0].clip_len = 1\n",
    "\n",
    "# cfg.train_pipeline[0] = dict(\n",
    "#         type='SampleFrames',\n",
    "#         clip_len=3,\n",
    "#         frame_interval=1,\n",
    "#         num_clips=25)\n",
    "# cfg.test_pipeline[0] = dict(\n",
    "#         type='SampleFrames',\n",
    "#         clip_len=5,\n",
    "#         frame_interval=1,\n",
    "#         num_clips=3,\n",
    "#         test_mode=True)\n",
    "# cfg.val_pipeline[0] = dict(\n",
    "#         type='SampleFrames',\n",
    "#         clip_len=5,\n",
    "#         frame_interval=1,\n",
    "#         num_clips=25,\n",
    "#         test_mode=True)\n",
    "\n",
    "cfg.train_pipeline[3] = dict(type='RandomResizedCrop')\n",
    "\n",
    "del cfg.train_pipeline[5]\n",
    "\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.val.pipeline = cfg.val_pipeline\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "# cfg.data.videos_per_gpu = 24\n",
    "# cfg.optimizer.type = 'Adam'\n",
    "# cfg.optimizer.weight_decay=0.0001\n",
    "\n",
    "# cfg.optimizer_config.grad_clip=None\n",
    "# cfg.optimizer.lr = 0.01\n",
    "\n",
    "cfg.lr_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(10, 1e-5),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "cfg.total_epochs = 51\n",
    "\n",
    "cfg.momentum_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(0.85 / 0.95, 1),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 12\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# cfg.img_norm_cfg.mean = [0.485, 0.456, 0.406]\n",
    "# cfg.img_norm_cfg.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# cfg.train_pipeline[6] = dict(type='Normalize', mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], to_bgr=False)\n",
    "# cfg.test_pipeline[4] = dict(type='Normalize', mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], to_bgr=False)\n",
    "# cfg.val_pipeline[4] = dict(type='Normalize', mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], to_bgr=False)\n",
    "\n",
    "cfg.model.backbone.in_channels = 2\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:18:39,908 - mmaction - INFO - These parameters in pretrained checkpoint are not loaded: {'fc.bias', 'fc.weight', 'conv1.weight'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_torchvision loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:18:39,999 - mmaction - INFO - load checkpoint from checkpoints/tanet_r50_dense_1x1x8_100e_kinetics400_rgb_20210219-032c8e94.pth\n",
      "2021-03-29 12:18:40,000 - mmaction - INFO - Use load_from_local loader\n",
      "2021-03-29 12:18:40,088 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for backbone.conv1.conv.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 2, 7, 7]).\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([7, 2048]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([7]).\n",
      "2021-03-29 12:18:40,090 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /home/actrec/.virtualenvs/mmaction/mmaction2/childact-checkpoints/childact-TANet\n",
      "2021-03-29 12:18:40,090 - mmaction - INFO - workflow: [('train', 1)], max: 51 epochs\n",
      "2021-03-29 12:18:49,336 - mmaction - INFO - Epoch [1][25/132]\tlr: 1.002e-02, eta: 0:41:19, time: 0.370, data_time: 0.095, memory: 7153, top1_acc: 0.1850, top5_acc: 0.7650, loss_cls: 2.0557, loss: 2.0557, grad_norm: 9.7515\n",
      "2021-03-29 12:18:56,184 - mmaction - INFO - Epoch [1][50/132]\tlr: 1.007e-02, eta: 0:35:50, time: 0.274, data_time: 0.000, memory: 7153, top1_acc: 0.2800, top5_acc: 0.8450, loss_cls: 1.8575, loss: 1.8575, grad_norm: 6.4151\n",
      "2021-03-29 12:19:02,959 - mmaction - INFO - Epoch [1][75/132]\tlr: 1.017e-02, eta: 0:33:49, time: 0.271, data_time: 0.000, memory: 7153, top1_acc: 0.3750, top5_acc: 0.9250, loss_cls: 1.6502, loss: 1.6502, grad_norm: 5.4960\n",
      "2021-03-29 12:19:09,789 - mmaction - INFO - Epoch [1][100/132]\tlr: 1.030e-02, eta: 0:32:49, time: 0.273, data_time: 0.000, memory: 7153, top1_acc: 0.3050, top5_acc: 0.8300, loss_cls: 1.8212, loss: 1.8212, grad_norm: 5.1186\n",
      "2021-03-29 12:19:16,569 - mmaction - INFO - Epoch [1][125/132]\tlr: 1.047e-02, eta: 0:32:07, time: 0.271, data_time: 0.000, memory: 7153, top1_acc: 0.3550, top5_acc: 0.9500, loss_cls: 1.4968, loss: 1.4968, grad_norm: 3.9792\n",
      "2021-03-29 12:19:27,626 - mmaction - INFO - Epoch [2][25/132]\tlr: 1.074e-02, eta: 0:31:54, time: 0.370, data_time: 0.097, memory: 7153, top1_acc: 0.3450, top5_acc: 0.9350, loss_cls: 1.5463, loss: 1.5463, grad_norm: 4.4238\n",
      "2021-03-29 12:19:34,414 - mmaction - INFO - Epoch [2][50/132]\tlr: 1.100e-02, eta: 0:31:29, time: 0.272, data_time: 0.000, memory: 7153, top1_acc: 0.4250, top5_acc: 0.9100, loss_cls: 1.4709, loss: 1.4709, grad_norm: 3.9662\n",
      "2021-03-29 12:19:41,214 - mmaction - INFO - Epoch [2][75/132]\tlr: 1.129e-02, eta: 0:31:09, time: 0.272, data_time: 0.000, memory: 7153, top1_acc: 0.4700, top5_acc: 0.9400, loss_cls: 1.3981, loss: 1.3981, grad_norm: 4.3671\n",
      "2021-03-29 12:19:48,044 - mmaction - INFO - Epoch [2][100/132]\tlr: 1.163e-02, eta: 0:30:52, time: 0.273, data_time: 0.000, memory: 7153, top1_acc: 0.4050, top5_acc: 0.9200, loss_cls: 1.4549, loss: 1.4549, grad_norm: 4.4776\n",
      "2021-03-29 12:19:54,872 - mmaction - INFO - Epoch [2][125/132]\tlr: 1.199e-02, eta: 0:30:38, time: 0.273, data_time: 0.000, memory: 7153, top1_acc: 0.4150, top5_acc: 0.9400, loss_cls: 1.5323, loss: 1.5323, grad_norm: 3.9329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 9.2 task/s, elapsed: 14s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:20:10,521 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:20:10,523 - mmaction - INFO - \n",
      "top1_acc\t0.7460\n",
      "top5_acc\t0.9921\n",
      "2021-03-29 12:20:10,524 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:20:10,526 - mmaction - INFO - \n",
      "mean_acc\t0.7460\n",
      "2021-03-29 12:20:10,814 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_2.pth.\n",
      "2021-03-29 12:20:10,816 - mmaction - INFO - Best top1_acc is 0.7460 at 2 epoch.\n",
      "2021-03-29 12:20:10,816 - mmaction - INFO - Epoch(val) [2][132]\ttop1_acc: 0.7460, top5_acc: 0.9921, mean_class_accuracy: 0.7460\n",
      "2021-03-29 12:20:20,084 - mmaction - INFO - Epoch [3][25/132]\tlr: 1.252e-02, eta: 0:30:33, time: 0.371, data_time: 0.096, memory: 7542, top1_acc: 0.4850, top5_acc: 0.9400, loss_cls: 1.3050, loss: 1.3050, grad_norm: 3.2627\n",
      "2021-03-29 12:20:26,945 - mmaction - INFO - Epoch [3][50/132]\tlr: 1.297e-02, eta: 0:30:20, time: 0.274, data_time: 0.000, memory: 7542, top1_acc: 0.5000, top5_acc: 0.9250, loss_cls: 1.1642, loss: 1.1642, grad_norm: 3.6943\n",
      "2021-03-29 12:20:33,780 - mmaction - INFO - Epoch [3][75/132]\tlr: 1.346e-02, eta: 0:30:08, time: 0.273, data_time: 0.000, memory: 7542, top1_acc: 0.4350, top5_acc: 0.9400, loss_cls: 1.2773, loss: 1.2773, grad_norm: 3.4488\n",
      "2021-03-29 12:20:40,638 - mmaction - INFO - Epoch [3][100/132]\tlr: 1.398e-02, eta: 0:29:58, time: 0.274, data_time: 0.000, memory: 7542, top1_acc: 0.4700, top5_acc: 0.9450, loss_cls: 1.2636, loss: 1.2636, grad_norm: 3.6138\n",
      "2021-03-29 12:20:47,497 - mmaction - INFO - Epoch [3][125/132]\tlr: 1.453e-02, eta: 0:29:47, time: 0.274, data_time: 0.000, memory: 7542, top1_acc: 0.5200, top5_acc: 0.9500, loss_cls: 1.2017, loss: 1.2017, grad_norm: 3.4511\n",
      "2021-03-29 12:20:58,642 - mmaction - INFO - Epoch [4][25/132]\tlr: 1.530e-02, eta: 0:29:43, time: 0.373, data_time: 0.098, memory: 7542, top1_acc: 0.5350, top5_acc: 0.9200, loss_cls: 1.1730, loss: 1.1730, grad_norm: 3.1337\n",
      "2021-03-29 12:21:05,505 - mmaction - INFO - Epoch [4][50/132]\tlr: 1.593e-02, eta: 0:29:33, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.5150, top5_acc: 0.9650, loss_cls: 1.1823, loss: 1.1823, grad_norm: 3.8380\n",
      "2021-03-29 12:21:12,369 - mmaction - INFO - Epoch [4][75/132]\tlr: 1.660e-02, eta: 0:29:23, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.5400, top5_acc: 0.9550, loss_cls: 1.1157, loss: 1.1157, grad_norm: 2.8842\n",
      "2021-03-29 12:21:19,231 - mmaction - INFO - Epoch [4][100/132]\tlr: 1.730e-02, eta: 0:29:14, time: 0.274, data_time: 0.000, memory: 7542, top1_acc: 0.5200, top5_acc: 0.9450, loss_cls: 1.1683, loss: 1.1683, grad_norm: 3.5702\n",
      "2021-03-29 12:21:26,100 - mmaction - INFO - Epoch [4][125/132]\tlr: 1.803e-02, eta: 0:29:05, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.5200, top5_acc: 0.9550, loss_cls: 1.0920, loss: 1.0920, grad_norm: 2.7112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 8.8 task/s, elapsed: 14s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:21:42,394 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:21:42,396 - mmaction - INFO - \n",
      "top1_acc\t0.7857\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:21:42,396 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:21:42,398 - mmaction - INFO - \n",
      "mean_acc\t0.7857\n",
      "2021-03-29 12:21:42,718 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_4.pth.\n",
      "2021-03-29 12:21:42,719 - mmaction - INFO - Best top1_acc is 0.7857 at 4 epoch.\n",
      "2021-03-29 12:21:42,719 - mmaction - INFO - Epoch(val) [4][132]\ttop1_acc: 0.7857, top5_acc: 1.0000, mean_class_accuracy: 0.7857\n",
      "2021-03-29 12:21:52,074 - mmaction - INFO - Epoch [5][25/132]\tlr: 1.902e-02, eta: 0:29:00, time: 0.374, data_time: 0.098, memory: 7542, top1_acc: 0.5150, top5_acc: 0.9600, loss_cls: 1.1166, loss: 1.1166, grad_norm: 2.8345\n",
      "2021-03-29 12:21:58,959 - mmaction - INFO - Epoch [5][50/132]\tlr: 1.982e-02, eta: 0:28:51, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.5700, top5_acc: 0.9500, loss_cls: 1.1296, loss: 1.1296, grad_norm: 3.4791\n",
      "2021-03-29 12:22:05,867 - mmaction - INFO - Epoch [5][75/132]\tlr: 2.066e-02, eta: 0:28:43, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5800, top5_acc: 0.9600, loss_cls: 1.0953, loss: 1.0953, grad_norm: 3.2255\n",
      "2021-03-29 12:22:12,752 - mmaction - INFO - Epoch [5][100/132]\tlr: 2.152e-02, eta: 0:28:34, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.6000, top5_acc: 0.9650, loss_cls: 1.0787, loss: 1.0787, grad_norm: 2.8780\n",
      "2021-03-29 12:22:19,650 - mmaction - INFO - Epoch [5][125/132]\tlr: 2.241e-02, eta: 0:28:26, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5600, top5_acc: 0.9700, loss_cls: 1.1336, loss: 1.1336, grad_norm: 2.9456\n",
      "2021-03-29 12:22:30,814 - mmaction - INFO - Epoch [6][25/132]\tlr: 2.359e-02, eta: 0:28:20, time: 0.374, data_time: 0.096, memory: 7542, top1_acc: 0.4850, top5_acc: 0.9250, loss_cls: 1.2668, loss: 1.2668, grad_norm: 3.2763\n",
      "2021-03-29 12:22:37,704 - mmaction - INFO - Epoch [6][50/132]\tlr: 2.454e-02, eta: 0:28:12, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5500, top5_acc: 0.9600, loss_cls: 1.1290, loss: 1.1290, grad_norm: 2.8908\n",
      "2021-03-29 12:22:44,607 - mmaction - INFO - Epoch [6][75/132]\tlr: 2.552e-02, eta: 0:28:04, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5600, top5_acc: 0.9550, loss_cls: 1.1433, loss: 1.1433, grad_norm: 3.2682\n",
      "2021-03-29 12:22:51,500 - mmaction - INFO - Epoch [6][100/132]\tlr: 2.653e-02, eta: 0:27:56, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.4800, top5_acc: 0.9650, loss_cls: 1.3198, loss: 1.3198, grad_norm: 2.9401\n",
      "2021-03-29 12:22:58,392 - mmaction - INFO - Epoch [6][125/132]\tlr: 2.756e-02, eta: 0:27:48, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6600, top5_acc: 0.9750, loss_cls: 0.9199, loss: 0.9199, grad_norm: 2.6600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 9.0 task/s, elapsed: 14s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:23:14,235 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:23:14,237 - mmaction - INFO - \n",
      "top1_acc\t0.7063\n",
      "top5_acc\t0.9921\n",
      "2021-03-29 12:23:14,238 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:23:14,240 - mmaction - INFO - \n",
      "mean_acc\t0.7063\n",
      "2021-03-29 12:23:14,241 - mmaction - INFO - Epoch(val) [6][132]\ttop1_acc: 0.7063, top5_acc: 0.9921, mean_class_accuracy: 0.7063\n",
      "2021-03-29 12:23:23,577 - mmaction - INFO - Epoch [7][25/132]\tlr: 2.891e-02, eta: 0:27:42, time: 0.373, data_time: 0.096, memory: 7542, top1_acc: 0.4950, top5_acc: 0.9550, loss_cls: 1.2765, loss: 1.2765, grad_norm: 3.5840\n",
      "2021-03-29 12:23:30,468 - mmaction - INFO - Epoch [7][50/132]\tlr: 2.999e-02, eta: 0:27:34, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5400, top5_acc: 0.9750, loss_cls: 1.1278, loss: 1.1278, grad_norm: 2.6806\n",
      "2021-03-29 12:23:37,361 - mmaction - INFO - Epoch [7][75/132]\tlr: 3.109e-02, eta: 0:27:26, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6000, top5_acc: 0.9650, loss_cls: 1.0245, loss: 1.0245, grad_norm: 2.7426\n",
      "2021-03-29 12:23:44,254 - mmaction - INFO - Epoch [7][100/132]\tlr: 3.221e-02, eta: 0:27:18, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5650, top5_acc: 0.9600, loss_cls: 1.1022, loss: 1.1022, grad_norm: 2.4739\n",
      "2021-03-29 12:23:51,155 - mmaction - INFO - Epoch [7][125/132]\tlr: 3.335e-02, eta: 0:27:10, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5350, top5_acc: 0.9650, loss_cls: 1.2158, loss: 1.2158, grad_norm: 2.4762\n",
      "2021-03-29 12:24:02,328 - mmaction - INFO - Epoch [8][25/132]\tlr: 3.484e-02, eta: 0:27:04, time: 0.374, data_time: 0.097, memory: 7542, top1_acc: 0.5400, top5_acc: 0.9550, loss_cls: 1.1798, loss: 1.1798, grad_norm: 2.6436\n",
      "2021-03-29 12:24:09,232 - mmaction - INFO - Epoch [8][50/132]\tlr: 3.602e-02, eta: 0:26:56, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5800, top5_acc: 0.9650, loss_cls: 1.1090, loss: 1.1090, grad_norm: 2.4601\n",
      "2021-03-29 12:24:16,125 - mmaction - INFO - Epoch [8][75/132]\tlr: 3.722e-02, eta: 0:26:48, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5250, top5_acc: 0.9500, loss_cls: 1.1558, loss: 1.1558, grad_norm: 2.1978\n",
      "2021-03-29 12:24:23,025 - mmaction - INFO - Epoch [8][100/132]\tlr: 3.844e-02, eta: 0:26:40, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5950, top5_acc: 0.9600, loss_cls: 1.0735, loss: 1.0735, grad_norm: 1.9991\n",
      "2021-03-29 12:24:29,932 - mmaction - INFO - Epoch [8][125/132]\tlr: 3.966e-02, eta: 0:26:33, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6050, top5_acc: 0.9700, loss_cls: 1.0376, loss: 1.0376, grad_norm: 2.1951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 8.7 task/s, elapsed: 14s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:24:46,285 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:24:46,286 - mmaction - INFO - \n",
      "top1_acc\t0.7381\n",
      "top5_acc\t0.9921\n",
      "2021-03-29 12:24:46,287 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:24:46,287 - mmaction - INFO - \n",
      "mean_acc\t0.7381\n",
      "2021-03-29 12:24:46,288 - mmaction - INFO - Epoch(val) [8][132]\ttop1_acc: 0.7381, top5_acc: 0.9921, mean_class_accuracy: 0.7381\n",
      "2021-03-29 12:24:55,618 - mmaction - INFO - Epoch [9][25/132]\tlr: 4.125e-02, eta: 0:26:26, time: 0.373, data_time: 0.096, memory: 7542, top1_acc: 0.5800, top5_acc: 0.9550, loss_cls: 1.0139, loss: 1.0139, grad_norm: 2.1394\n",
      "2021-03-29 12:25:02,513 - mmaction - INFO - Epoch [9][50/132]\tlr: 4.251e-02, eta: 0:26:18, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6100, top5_acc: 0.9350, loss_cls: 1.0128, loss: 1.0128, grad_norm: 2.0550\n",
      "2021-03-29 12:25:09,412 - mmaction - INFO - Epoch [9][75/132]\tlr: 4.378e-02, eta: 0:26:11, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5850, top5_acc: 0.9650, loss_cls: 1.0608, loss: 1.0608, grad_norm: 2.1492\n",
      "2021-03-29 12:25:16,312 - mmaction - INFO - Epoch [9][100/132]\tlr: 4.505e-02, eta: 0:26:03, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5250, top5_acc: 0.9400, loss_cls: 1.1191, loss: 1.1191, grad_norm: 2.1310\n",
      "2021-03-29 12:25:23,211 - mmaction - INFO - Epoch [9][125/132]\tlr: 4.634e-02, eta: 0:25:55, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6050, top5_acc: 0.9700, loss_cls: 0.9896, loss: 0.9896, grad_norm: 2.1163\n",
      "2021-03-29 12:25:34,324 - mmaction - INFO - Epoch [10][25/132]\tlr: 4.799e-02, eta: 0:25:48, time: 0.371, data_time: 0.094, memory: 7542, top1_acc: 0.6250, top5_acc: 0.9750, loss_cls: 1.0080, loss: 1.0080, grad_norm: 2.2876\n",
      "2021-03-29 12:25:41,231 - mmaction - INFO - Epoch [10][50/132]\tlr: 4.929e-02, eta: 0:25:40, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5750, top5_acc: 0.9600, loss_cls: 1.0283, loss: 1.0283, grad_norm: 1.8547\n",
      "2021-03-29 12:25:48,310 - mmaction - INFO - Epoch [10][75/132]\tlr: 5.060e-02, eta: 0:25:34, time: 0.283, data_time: 0.000, memory: 7542, top1_acc: 0.6100, top5_acc: 0.9700, loss_cls: 0.9591, loss: 0.9591, grad_norm: 2.0407\n",
      "2021-03-29 12:25:55,350 - mmaction - INFO - Epoch [10][100/132]\tlr: 5.190e-02, eta: 0:25:27, time: 0.282, data_time: 0.000, memory: 7542, top1_acc: 0.6300, top5_acc: 0.9650, loss_cls: 1.0168, loss: 1.0168, grad_norm: 2.1033\n",
      "2021-03-29 12:26:02,442 - mmaction - INFO - Epoch [10][125/132]\tlr: 5.321e-02, eta: 0:25:20, time: 0.284, data_time: 0.000, memory: 7542, top1_acc: 0.5600, top5_acc: 0.9450, loss_cls: 1.1795, loss: 1.1795, grad_norm: 1.9874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 8.4 task/s, elapsed: 15s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:26:19,308 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:26:19,310 - mmaction - INFO - \n",
      "top1_acc\t0.7619\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:26:19,311 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:26:19,314 - mmaction - INFO - \n",
      "mean_acc\t0.7619\n",
      "2021-03-29 12:26:19,315 - mmaction - INFO - Epoch(val) [10][132]\ttop1_acc: 0.7619, top5_acc: 1.0000, mean_class_accuracy: 0.7619\n",
      "2021-03-29 12:26:28,658 - mmaction - INFO - Epoch [11][25/132]\tlr: 5.489e-02, eta: 0:25:13, time: 0.373, data_time: 0.096, memory: 7542, top1_acc: 0.5850, top5_acc: 0.9500, loss_cls: 1.0882, loss: 1.0882, grad_norm: 1.8450\n",
      "2021-03-29 12:26:35,554 - mmaction - INFO - Epoch [11][50/132]\tlr: 5.621e-02, eta: 0:25:05, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6550, top5_acc: 0.9600, loss_cls: 0.9252, loss: 0.9252, grad_norm: 1.7665\n",
      "2021-03-29 12:26:42,452 - mmaction - INFO - Epoch [11][75/132]\tlr: 5.752e-02, eta: 0:24:58, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6100, top5_acc: 0.9300, loss_cls: 1.0417, loss: 1.0417, grad_norm: 2.4101\n",
      "2021-03-29 12:26:49,348 - mmaction - INFO - Epoch [11][100/132]\tlr: 5.883e-02, eta: 0:24:50, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6200, top5_acc: 0.9700, loss_cls: 0.9607, loss: 0.9607, grad_norm: 2.0375\n",
      "2021-03-29 12:26:56,246 - mmaction - INFO - Epoch [11][125/132]\tlr: 6.014e-02, eta: 0:24:43, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6100, top5_acc: 0.9700, loss_cls: 1.0215, loss: 1.0215, grad_norm: 2.2774\n",
      "2021-03-29 12:27:07,389 - mmaction - INFO - Epoch [12][25/132]\tlr: 6.180e-02, eta: 0:24:35, time: 0.372, data_time: 0.095, memory: 7542, top1_acc: 0.6200, top5_acc: 0.9700, loss_cls: 0.8082, loss: 0.8082, grad_norm: 1.5620\n",
      "2021-03-29 12:27:14,301 - mmaction - INFO - Epoch [12][50/132]\tlr: 6.310e-02, eta: 0:24:27, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6000, top5_acc: 0.9700, loss_cls: 1.0477, loss: 1.0477, grad_norm: 2.0795\n",
      "2021-03-29 12:27:21,203 - mmaction - INFO - Epoch [12][75/132]\tlr: 6.438e-02, eta: 0:24:20, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6500, top5_acc: 0.9700, loss_cls: 0.9541, loss: 0.9541, grad_norm: 1.6821\n",
      "2021-03-29 12:27:28,099 - mmaction - INFO - Epoch [12][100/132]\tlr: 6.566e-02, eta: 0:24:13, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6400, top5_acc: 0.9650, loss_cls: 0.9217, loss: 0.9217, grad_norm: 1.9170\n",
      "2021-03-29 12:27:35,007 - mmaction - INFO - Epoch [12][125/132]\tlr: 6.693e-02, eta: 0:24:05, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6400, top5_acc: 0.9800, loss_cls: 0.9701, loss: 0.9701, grad_norm: 2.2489\n",
      "2021-03-29 12:27:36,905 - mmaction - INFO - Saving checkpoint at 12 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 7.7 task/s, elapsed: 16s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:27:53,690 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:27:53,692 - mmaction - INFO - \n",
      "top1_acc\t0.7857\n",
      "top5_acc\t0.9921\n",
      "2021-03-29 12:27:53,692 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:27:53,694 - mmaction - INFO - \n",
      "mean_acc\t0.7857\n",
      "2021-03-29 12:27:53,694 - mmaction - INFO - Epoch(val) [12][132]\ttop1_acc: 0.7857, top5_acc: 0.9921, mean_class_accuracy: 0.7857\n",
      "2021-03-29 12:28:03,444 - mmaction - INFO - Epoch [13][25/132]\tlr: 6.855e-02, eta: 0:23:59, time: 0.390, data_time: 0.096, memory: 7542, top1_acc: 0.5400, top5_acc: 0.9350, loss_cls: 1.1494, loss: 1.1494, grad_norm: 1.7940\n",
      "2021-03-29 12:28:10,649 - mmaction - INFO - Epoch [13][50/132]\tlr: 6.979e-02, eta: 0:23:52, time: 0.288, data_time: 0.000, memory: 7542, top1_acc: 0.6300, top5_acc: 0.9650, loss_cls: 1.0300, loss: 1.0300, grad_norm: 1.6314\n",
      "2021-03-29 12:28:17,824 - mmaction - INFO - Epoch [13][75/132]\tlr: 7.103e-02, eta: 0:23:46, time: 0.287, data_time: 0.000, memory: 7542, top1_acc: 0.6400, top5_acc: 0.9500, loss_cls: 0.9833, loss: 0.9833, grad_norm: 1.6513\n",
      "2021-03-29 12:28:24,983 - mmaction - INFO - Epoch [13][100/132]\tlr: 7.225e-02, eta: 0:23:39, time: 0.286, data_time: 0.000, memory: 7542, top1_acc: 0.6650, top5_acc: 0.9650, loss_cls: 0.9118, loss: 0.9118, grad_norm: 1.6905\n",
      "2021-03-29 12:28:31,909 - mmaction - INFO - Epoch [13][125/132]\tlr: 7.345e-02, eta: 0:23:32, time: 0.277, data_time: 0.000, memory: 7542, top1_acc: 0.5700, top5_acc: 0.9400, loss_cls: 1.1806, loss: 1.1806, grad_norm: 2.0976\n",
      "2021-03-29 12:28:43,074 - mmaction - INFO - Epoch [14][25/132]\tlr: 7.497e-02, eta: 0:23:24, time: 0.374, data_time: 0.095, memory: 7542, top1_acc: 0.6000, top5_acc: 0.9700, loss_cls: 1.0810, loss: 1.0810, grad_norm: 1.7512\n",
      "2021-03-29 12:28:49,976 - mmaction - INFO - Epoch [14][50/132]\tlr: 7.614e-02, eta: 0:23:16, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5850, top5_acc: 0.9500, loss_cls: 1.0712, loss: 1.0712, grad_norm: 1.7791\n",
      "2021-03-29 12:28:56,874 - mmaction - INFO - Epoch [14][75/132]\tlr: 7.729e-02, eta: 0:23:09, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6100, top5_acc: 0.9050, loss_cls: 1.0776, loss: 1.0776, grad_norm: 1.5453\n",
      "2021-03-29 12:29:03,797 - mmaction - INFO - Epoch [14][100/132]\tlr: 7.842e-02, eta: 0:23:02, time: 0.277, data_time: 0.000, memory: 7542, top1_acc: 0.5350, top5_acc: 0.9350, loss_cls: 1.1994, loss: 1.1994, grad_norm: 1.5828\n",
      "2021-03-29 12:29:10,719 - mmaction - INFO - Epoch [14][125/132]\tlr: 7.953e-02, eta: 0:22:54, time: 0.277, data_time: 0.000, memory: 7542, top1_acc: 0.6350, top5_acc: 0.9400, loss_cls: 0.9671, loss: 0.9671, grad_norm: 1.4217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 4.9 task/s, elapsed: 26s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:29:38,320 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:29:38,322 - mmaction - INFO - \n",
      "top1_acc\t0.7540\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:29:38,323 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:29:38,324 - mmaction - INFO - \n",
      "mean_acc\t0.7540\n",
      "2021-03-29 12:29:38,325 - mmaction - INFO - Epoch(val) [14][132]\ttop1_acc: 0.7540, top5_acc: 1.0000, mean_class_accuracy: 0.7540\n",
      "2021-03-29 12:29:47,604 - mmaction - INFO - Epoch [15][25/132]\tlr: 8.092e-02, eta: 0:22:46, time: 0.371, data_time: 0.095, memory: 7542, top1_acc: 0.6250, top5_acc: 0.9800, loss_cls: 1.1604, loss: 1.1604, grad_norm: 1.8526\n",
      "2021-03-29 12:29:54,470 - mmaction - INFO - Epoch [15][50/132]\tlr: 8.198e-02, eta: 0:22:39, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.6350, top5_acc: 0.9650, loss_cls: 0.9313, loss: 0.9313, grad_norm: 1.5301\n",
      "2021-03-29 12:30:01,372 - mmaction - INFO - Epoch [15][75/132]\tlr: 8.302e-02, eta: 0:22:31, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6200, top5_acc: 0.9500, loss_cls: 1.0239, loss: 1.0239, grad_norm: 1.7137\n",
      "2021-03-29 12:30:08,332 - mmaction - INFO - Epoch [15][100/132]\tlr: 8.404e-02, eta: 0:22:24, time: 0.278, data_time: 0.000, memory: 7542, top1_acc: 0.6150, top5_acc: 0.9550, loss_cls: 0.9471, loss: 0.9471, grad_norm: 1.7452\n",
      "2021-03-29 12:30:15,291 - mmaction - INFO - Epoch [15][125/132]\tlr: 8.503e-02, eta: 0:22:17, time: 0.278, data_time: 0.000, memory: 7542, top1_acc: 0.5900, top5_acc: 0.9550, loss_cls: 1.0767, loss: 1.0767, grad_norm: 1.8169\n",
      "2021-03-29 12:30:26,590 - mmaction - INFO - Epoch [16][25/132]\tlr: 8.626e-02, eta: 0:22:09, time: 0.376, data_time: 0.095, memory: 7542, top1_acc: 0.6400, top5_acc: 0.9550, loss_cls: 0.9385, loss: 0.9385, grad_norm: 1.6119\n",
      "2021-03-29 12:30:33,560 - mmaction - INFO - Epoch [16][50/132]\tlr: 8.719e-02, eta: 0:22:02, time: 0.279, data_time: 0.000, memory: 7542, top1_acc: 0.6000, top5_acc: 0.9500, loss_cls: 1.0229, loss: 1.0229, grad_norm: 1.5852\n",
      "2021-03-29 12:30:40,458 - mmaction - INFO - Epoch [16][75/132]\tlr: 8.809e-02, eta: 0:21:54, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6700, top5_acc: 0.9550, loss_cls: 0.8608, loss: 0.8608, grad_norm: 1.2665\n",
      "2021-03-29 12:30:47,356 - mmaction - INFO - Epoch [16][100/132]\tlr: 8.897e-02, eta: 0:21:47, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6650, top5_acc: 0.9600, loss_cls: 0.8769, loss: 0.8769, grad_norm: 1.6505\n",
      "2021-03-29 12:30:54,260 - mmaction - INFO - Epoch [16][125/132]\tlr: 8.981e-02, eta: 0:21:40, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5900, top5_acc: 0.9750, loss_cls: 1.0290, loss: 1.0290, grad_norm: 2.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 6.6 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:31:15,268 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:31:15,270 - mmaction - INFO - \n",
      "top1_acc\t0.7063\n",
      "top5_acc\t0.9762\n",
      "2021-03-29 12:31:15,270 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:31:15,271 - mmaction - INFO - \n",
      "mean_acc\t0.7063\n",
      "2021-03-29 12:31:15,271 - mmaction - INFO - Epoch(val) [16][132]\ttop1_acc: 0.7063, top5_acc: 0.9762, mean_class_accuracy: 0.7063\n",
      "2021-03-29 12:31:24,767 - mmaction - INFO - Epoch [17][25/132]\tlr: 9.085e-02, eta: 0:21:32, time: 0.380, data_time: 0.096, memory: 7542, top1_acc: 0.6550, top5_acc: 0.9700, loss_cls: 0.8708, loss: 0.8708, grad_norm: 1.3874\n",
      "2021-03-29 12:31:31,719 - mmaction - INFO - Epoch [17][50/132]\tlr: 9.163e-02, eta: 0:21:25, time: 0.278, data_time: 0.000, memory: 7542, top1_acc: 0.6100, top5_acc: 0.9750, loss_cls: 1.0270, loss: 1.0270, grad_norm: 1.7035\n",
      "2021-03-29 12:31:38,611 - mmaction - INFO - Epoch [17][75/132]\tlr: 9.238e-02, eta: 0:21:17, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5750, top5_acc: 0.9250, loss_cls: 1.0626, loss: 1.0626, grad_norm: 1.7838\n",
      "2021-03-29 12:31:45,502 - mmaction - INFO - Epoch [17][100/132]\tlr: 9.309e-02, eta: 0:21:10, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6450, top5_acc: 0.9550, loss_cls: 1.0444, loss: 1.0444, grad_norm: 1.7346\n",
      "2021-03-29 12:31:52,395 - mmaction - INFO - Epoch [17][125/132]\tlr: 9.378e-02, eta: 0:21:03, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6450, top5_acc: 0.9500, loss_cls: 0.9241, loss: 0.9241, grad_norm: 1.3245\n",
      "2021-03-29 12:32:03,549 - mmaction - INFO - Epoch [18][25/132]\tlr: 9.460e-02, eta: 0:20:54, time: 0.373, data_time: 0.095, memory: 7542, top1_acc: 0.6000, top5_acc: 0.9400, loss_cls: 1.0611, loss: 1.0611, grad_norm: 1.3958\n",
      "2021-03-29 12:32:10,438 - mmaction - INFO - Epoch [18][50/132]\tlr: 9.521e-02, eta: 0:20:47, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6700, top5_acc: 0.9850, loss_cls: 0.8888, loss: 0.8888, grad_norm: 1.2460\n",
      "2021-03-29 12:32:17,334 - mmaction - INFO - Epoch [18][75/132]\tlr: 9.578e-02, eta: 0:20:40, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6300, top5_acc: 0.9650, loss_cls: 1.0358, loss: 1.0358, grad_norm: 1.5387\n",
      "2021-03-29 12:32:24,231 - mmaction - INFO - Epoch [18][100/132]\tlr: 9.632e-02, eta: 0:20:32, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5850, top5_acc: 0.9600, loss_cls: 1.0634, loss: 1.0634, grad_norm: 1.4811\n",
      "2021-03-29 12:32:31,136 - mmaction - INFO - Epoch [18][125/132]\tlr: 9.682e-02, eta: 0:20:25, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6350, top5_acc: 0.9500, loss_cls: 1.0007, loss: 1.0007, grad_norm: 1.5335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 7.2 task/s, elapsed: 18s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:32:50,652 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:32:50,655 - mmaction - INFO - \n",
      "top1_acc\t0.8016\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:32:50,655 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:32:50,656 - mmaction - INFO - \n",
      "mean_acc\t0.8016\n",
      "2021-03-29 12:32:50,980 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_18.pth.\n",
      "2021-03-29 12:32:50,981 - mmaction - INFO - Best top1_acc is 0.8016 at 18 epoch.\n",
      "2021-03-29 12:32:50,982 - mmaction - INFO - Epoch(val) [18][132]\ttop1_acc: 0.8016, top5_acc: 1.0000, mean_class_accuracy: 0.8016\n",
      "2021-03-29 12:33:00,329 - mmaction - INFO - Epoch [19][25/132]\tlr: 9.741e-02, eta: 0:20:17, time: 0.374, data_time: 0.097, memory: 7542, top1_acc: 0.6100, top5_acc: 0.9600, loss_cls: 1.0305, loss: 1.0305, grad_norm: 1.4992\n",
      "2021-03-29 12:33:07,215 - mmaction - INFO - Epoch [19][50/132]\tlr: 9.783e-02, eta: 0:20:10, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.5650, top5_acc: 0.9700, loss_cls: 0.9985, loss: 0.9985, grad_norm: 1.6139\n",
      "2021-03-29 12:33:14,101 - mmaction - INFO - Epoch [19][75/132]\tlr: 9.822e-02, eta: 0:20:02, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.5700, top5_acc: 0.9550, loss_cls: 1.0418, loss: 1.0418, grad_norm: 1.5290\n",
      "2021-03-29 12:33:20,992 - mmaction - INFO - Epoch [19][100/132]\tlr: 9.856e-02, eta: 0:19:55, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6450, top5_acc: 0.9550, loss_cls: 0.9028, loss: 0.9028, grad_norm: 1.7869\n",
      "2021-03-29 12:33:27,897 - mmaction - INFO - Epoch [19][125/132]\tlr: 9.888e-02, eta: 0:19:48, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6150, top5_acc: 0.9450, loss_cls: 0.9456, loss: 0.9456, grad_norm: 1.4814\n",
      "2021-03-29 12:33:39,065 - mmaction - INFO - Epoch [20][25/132]\tlr: 9.922e-02, eta: 0:19:39, time: 0.373, data_time: 0.097, memory: 7542, top1_acc: 0.6050, top5_acc: 0.9800, loss_cls: 0.9866, loss: 0.9866, grad_norm: 1.7350\n",
      "2021-03-29 12:33:45,968 - mmaction - INFO - Epoch [20][50/132]\tlr: 9.944e-02, eta: 0:19:32, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6200, top5_acc: 0.9550, loss_cls: 0.9605, loss: 0.9605, grad_norm: 1.2943\n",
      "2021-03-29 12:33:52,862 - mmaction - INFO - Epoch [20][75/132]\tlr: 9.963e-02, eta: 0:19:25, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6300, top5_acc: 0.9550, loss_cls: 0.9161, loss: 0.9161, grad_norm: 1.5399\n",
      "2021-03-29 12:33:59,751 - mmaction - INFO - Epoch [20][100/132]\tlr: 9.978e-02, eta: 0:19:18, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6500, top5_acc: 0.9650, loss_cls: 0.9982, loss: 0.9982, grad_norm: 1.4038\n",
      "2021-03-29 12:34:06,645 - mmaction - INFO - Epoch [20][125/132]\tlr: 9.989e-02, eta: 0:19:10, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6950, top5_acc: 0.9750, loss_cls: 0.8380, loss: 0.8380, grad_norm: 1.5877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 8.3 task/s, elapsed: 15s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:34:23,751 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:34:23,754 - mmaction - INFO - \n",
      "top1_acc\t0.8571\n",
      "top5_acc\t0.9921\n",
      "2021-03-29 12:34:23,755 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:34:23,757 - mmaction - INFO - \n",
      "mean_acc\t0.8571\n",
      "2021-03-29 12:34:24,084 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_20.pth.\n",
      "2021-03-29 12:34:24,085 - mmaction - INFO - Best top1_acc is 0.8571 at 20 epoch.\n",
      "2021-03-29 12:34:24,086 - mmaction - INFO - Epoch(val) [20][132]\ttop1_acc: 0.8571, top5_acc: 0.9921, mean_class_accuracy: 0.8571\n",
      "2021-03-29 12:34:33,385 - mmaction - INFO - Epoch [21][25/132]\tlr: 9.998e-02, eta: 0:19:02, time: 0.372, data_time: 0.095, memory: 7542, top1_acc: 0.6450, top5_acc: 0.9550, loss_cls: 0.9383, loss: 0.9383, grad_norm: 1.4433\n",
      "2021-03-29 12:34:40,270 - mmaction - INFO - Epoch [21][50/132]\tlr: 1.000e-01, eta: 0:18:55, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.5950, top5_acc: 0.9650, loss_cls: 0.9552, loss: 0.9552, grad_norm: 1.6056\n",
      "2021-03-29 12:34:47,155 - mmaction - INFO - Epoch [21][75/132]\tlr: 9.999e-02, eta: 0:18:48, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.5950, top5_acc: 0.9500, loss_cls: 1.0423, loss: 1.0423, grad_norm: 1.8799\n",
      "2021-03-29 12:34:54,042 - mmaction - INFO - Epoch [21][100/132]\tlr: 9.997e-02, eta: 0:18:40, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.6450, top5_acc: 0.9450, loss_cls: 0.9352, loss: 0.9352, grad_norm: 1.2142\n",
      "2021-03-29 12:35:00,936 - mmaction - INFO - Epoch [21][125/132]\tlr: 9.992e-02, eta: 0:18:33, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6750, top5_acc: 0.9500, loss_cls: 0.8304, loss: 0.8304, grad_norm: 1.3545\n",
      "2021-03-29 12:35:12,126 - mmaction - INFO - Epoch [22][25/132]\tlr: 9.984e-02, eta: 0:18:25, time: 0.374, data_time: 0.097, memory: 7542, top1_acc: 0.5950, top5_acc: 0.9450, loss_cls: 1.1139, loss: 1.1139, grad_norm: 1.6421\n",
      "2021-03-29 12:35:19,020 - mmaction - INFO - Epoch [22][50/132]\tlr: 9.975e-02, eta: 0:18:17, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6500, top5_acc: 0.9450, loss_cls: 0.8306, loss: 0.8306, grad_norm: 1.2618\n",
      "2021-03-29 12:35:25,927 - mmaction - INFO - Epoch [22][75/132]\tlr: 9.964e-02, eta: 0:18:10, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6500, top5_acc: 0.9500, loss_cls: 0.8849, loss: 0.8849, grad_norm: 1.5864\n",
      "2021-03-29 12:35:32,817 - mmaction - INFO - Epoch [22][100/132]\tlr: 9.952e-02, eta: 0:18:03, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6250, top5_acc: 0.9550, loss_cls: 1.0240, loss: 1.0240, grad_norm: 1.5229\n",
      "2021-03-29 12:35:39,727 - mmaction - INFO - Epoch [22][125/132]\tlr: 9.937e-02, eta: 0:17:56, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6950, top5_acc: 0.9600, loss_cls: 0.8359, loss: 0.8359, grad_norm: 1.3272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 7.3 task/s, elapsed: 17s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:35:58,993 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:35:58,995 - mmaction - INFO - \n",
      "top1_acc\t0.8571\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:35:58,995 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:35:58,997 - mmaction - INFO - \n",
      "mean_acc\t0.8571\n",
      "2021-03-29 12:35:58,998 - mmaction - INFO - Epoch(val) [22][132]\ttop1_acc: 0.8571, top5_acc: 1.0000, mean_class_accuracy: 0.8571\n",
      "2021-03-29 12:36:08,389 - mmaction - INFO - Epoch [23][25/132]\tlr: 9.916e-02, eta: 0:17:47, time: 0.375, data_time: 0.097, memory: 7542, top1_acc: 0.6350, top5_acc: 0.9450, loss_cls: 1.0547, loss: 1.0547, grad_norm: 1.5259\n",
      "2021-03-29 12:36:15,277 - mmaction - INFO - Epoch [23][50/132]\tlr: 9.897e-02, eta: 0:17:40, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6650, top5_acc: 0.9750, loss_cls: 0.8709, loss: 0.8709, grad_norm: 1.4287\n",
      "2021-03-29 12:36:22,169 - mmaction - INFO - Epoch [23][75/132]\tlr: 9.877e-02, eta: 0:17:33, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5950, top5_acc: 0.9700, loss_cls: 1.0287, loss: 1.0287, grad_norm: 1.3994\n",
      "2021-03-29 12:36:29,068 - mmaction - INFO - Epoch [23][100/132]\tlr: 9.854e-02, eta: 0:17:26, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5950, top5_acc: 0.9750, loss_cls: 0.9330, loss: 0.9330, grad_norm: 1.4386\n",
      "2021-03-29 12:36:35,969 - mmaction - INFO - Epoch [23][125/132]\tlr: 9.830e-02, eta: 0:17:19, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5850, top5_acc: 0.9550, loss_cls: 1.0291, loss: 1.0291, grad_norm: 1.5332\n",
      "2021-03-29 12:36:47,154 - mmaction - INFO - Epoch [24][25/132]\tlr: 9.797e-02, eta: 0:17:10, time: 0.374, data_time: 0.097, memory: 7542, top1_acc: 0.6250, top5_acc: 0.9750, loss_cls: 0.9930, loss: 0.9930, grad_norm: 1.5583\n",
      "2021-03-29 12:36:54,047 - mmaction - INFO - Epoch [24][50/132]\tlr: 9.768e-02, eta: 0:17:03, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6050, top5_acc: 0.9700, loss_cls: 0.9497, loss: 0.9497, grad_norm: 1.6586\n",
      "2021-03-29 12:37:00,951 - mmaction - INFO - Epoch [24][75/132]\tlr: 9.738e-02, eta: 0:16:56, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5650, top5_acc: 0.9450, loss_cls: 1.0695, loss: 1.0695, grad_norm: 1.7685\n",
      "2021-03-29 12:37:07,861 - mmaction - INFO - Epoch [24][100/132]\tlr: 9.706e-02, eta: 0:16:49, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5950, top5_acc: 0.9900, loss_cls: 0.8967, loss: 0.8967, grad_norm: 1.2119\n",
      "2021-03-29 12:37:14,775 - mmaction - INFO - Epoch [24][125/132]\tlr: 9.673e-02, eta: 0:16:42, time: 0.277, data_time: 0.000, memory: 7542, top1_acc: 0.6950, top5_acc: 0.9550, loss_cls: 0.8005, loss: 0.8005, grad_norm: 1.2580\n",
      "2021-03-29 12:37:16,611 - mmaction - INFO - Saving checkpoint at 24 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 7.9 task/s, elapsed: 16s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:37:33,029 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:37:33,032 - mmaction - INFO - \n",
      "top1_acc\t0.8413\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:37:33,033 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:37:33,035 - mmaction - INFO - \n",
      "mean_acc\t0.8413\n",
      "2021-03-29 12:37:33,036 - mmaction - INFO - Epoch(val) [24][132]\ttop1_acc: 0.8413, top5_acc: 1.0000, mean_class_accuracy: 0.8413\n",
      "2021-03-29 12:37:42,529 - mmaction - INFO - Epoch [25][25/132]\tlr: 9.627e-02, eta: 0:16:33, time: 0.379, data_time: 0.100, memory: 7542, top1_acc: 0.6400, top5_acc: 0.9750, loss_cls: 0.9685, loss: 0.9685, grad_norm: 1.3406\n",
      "2021-03-29 12:37:49,424 - mmaction - INFO - Epoch [25][50/132]\tlr: 9.589e-02, eta: 0:16:26, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.5750, top5_acc: 0.9700, loss_cls: 0.9444, loss: 0.9444, grad_norm: 1.2980\n",
      "2021-03-29 12:37:56,313 - mmaction - INFO - Epoch [25][75/132]\tlr: 9.550e-02, eta: 0:16:19, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6850, top5_acc: 0.9700, loss_cls: 0.8436, loss: 0.8436, grad_norm: 1.2538\n",
      "2021-03-29 12:38:03,206 - mmaction - INFO - Epoch [25][100/132]\tlr: 9.508e-02, eta: 0:16:12, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6550, top5_acc: 0.9750, loss_cls: 0.8445, loss: 0.8445, grad_norm: 1.1864\n",
      "2021-03-29 12:38:10,097 - mmaction - INFO - Epoch [25][125/132]\tlr: 9.466e-02, eta: 0:16:05, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6300, top5_acc: 0.9600, loss_cls: 0.9665, loss: 0.9665, grad_norm: 1.2870\n",
      "2021-03-29 12:38:21,259 - mmaction - INFO - Epoch [26][25/132]\tlr: 9.408e-02, eta: 0:15:56, time: 0.373, data_time: 0.096, memory: 7542, top1_acc: 0.6200, top5_acc: 0.9600, loss_cls: 0.9710, loss: 0.9710, grad_norm: 1.4416\n",
      "2021-03-29 12:38:28,157 - mmaction - INFO - Epoch [26][50/132]\tlr: 9.362e-02, eta: 0:15:49, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6950, top5_acc: 0.9600, loss_cls: 0.7432, loss: 0.7432, grad_norm: 1.2814\n",
      "2021-03-29 12:38:35,048 - mmaction - INFO - Epoch [26][75/132]\tlr: 9.313e-02, eta: 0:15:42, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6050, top5_acc: 0.9700, loss_cls: 0.9073, loss: 0.9073, grad_norm: 1.6359\n",
      "2021-03-29 12:38:41,945 - mmaction - INFO - Epoch [26][100/132]\tlr: 9.263e-02, eta: 0:15:35, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6900, top5_acc: 0.9700, loss_cls: 0.7661, loss: 0.7661, grad_norm: 1.3443\n",
      "2021-03-29 12:38:48,849 - mmaction - INFO - Epoch [26][125/132]\tlr: 9.212e-02, eta: 0:15:27, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6150, top5_acc: 0.9650, loss_cls: 0.9283, loss: 0.9283, grad_norm: 1.4233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 5.5 task/s, elapsed: 23s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:39:13,616 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:39:13,618 - mmaction - INFO - \n",
      "top1_acc\t0.8016\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:39:13,619 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:39:13,621 - mmaction - INFO - \n",
      "mean_acc\t0.8016\n",
      "2021-03-29 12:39:13,622 - mmaction - INFO - Epoch(val) [26][132]\ttop1_acc: 0.8016, top5_acc: 1.0000, mean_class_accuracy: 0.8016\n",
      "2021-03-29 12:39:23,141 - mmaction - INFO - Epoch [27][25/132]\tlr: 9.143e-02, eta: 0:15:19, time: 0.381, data_time: 0.096, memory: 7542, top1_acc: 0.5750, top5_acc: 0.9600, loss_cls: 1.0374, loss: 1.0374, grad_norm: 1.5633\n",
      "2021-03-29 12:39:30,041 - mmaction - INFO - Epoch [27][50/132]\tlr: 9.088e-02, eta: 0:15:12, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7050, top5_acc: 0.9650, loss_cls: 0.8179, loss: 0.8179, grad_norm: 1.2858\n",
      "2021-03-29 12:39:36,928 - mmaction - INFO - Epoch [27][75/132]\tlr: 9.031e-02, eta: 0:15:05, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.6600, top5_acc: 0.9700, loss_cls: 0.8947, loss: 0.8947, grad_norm: 1.2944\n",
      "2021-03-29 12:39:43,815 - mmaction - INFO - Epoch [27][100/132]\tlr: 8.973e-02, eta: 0:14:58, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.6750, top5_acc: 0.9700, loss_cls: 0.8555, loss: 0.8555, grad_norm: 1.2609\n",
      "2021-03-29 12:39:50,703 - mmaction - INFO - Epoch [27][125/132]\tlr: 8.913e-02, eta: 0:14:50, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6850, top5_acc: 0.9650, loss_cls: 0.8777, loss: 0.8777, grad_norm: 1.2621\n",
      "2021-03-29 12:40:01,825 - mmaction - INFO - Epoch [28][25/132]\tlr: 8.835e-02, eta: 0:14:42, time: 0.372, data_time: 0.095, memory: 7542, top1_acc: 0.6800, top5_acc: 0.9650, loss_cls: 0.8196, loss: 0.8196, grad_norm: 1.1795\n",
      "2021-03-29 12:40:08,717 - mmaction - INFO - Epoch [28][50/132]\tlr: 8.772e-02, eta: 0:14:35, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6950, top5_acc: 0.9800, loss_cls: 0.8157, loss: 0.8157, grad_norm: 1.3065\n",
      "2021-03-29 12:40:15,629 - mmaction - INFO - Epoch [28][75/132]\tlr: 8.707e-02, eta: 0:14:28, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7000, top5_acc: 0.9850, loss_cls: 0.7189, loss: 0.7189, grad_norm: 1.1782\n",
      "2021-03-29 12:40:22,532 - mmaction - INFO - Epoch [28][100/132]\tlr: 8.641e-02, eta: 0:14:20, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7150, top5_acc: 0.9650, loss_cls: 0.7517, loss: 0.7517, grad_norm: 1.3273\n",
      "2021-03-29 12:40:29,437 - mmaction - INFO - Epoch [28][125/132]\tlr: 8.574e-02, eta: 0:14:13, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6300, top5_acc: 0.9800, loss_cls: 0.8734, loss: 0.8734, grad_norm: 1.4158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 6.2 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:40:51,587 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:40:51,589 - mmaction - INFO - \n",
      "top1_acc\t0.8016\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:40:51,590 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:40:51,592 - mmaction - INFO - \n",
      "mean_acc\t0.8016\n",
      "2021-03-29 12:40:51,593 - mmaction - INFO - Epoch(val) [28][132]\ttop1_acc: 0.8016, top5_acc: 1.0000, mean_class_accuracy: 0.8016\n",
      "2021-03-29 12:41:00,931 - mmaction - INFO - Epoch [29][25/132]\tlr: 8.486e-02, eta: 0:14:05, time: 0.373, data_time: 0.096, memory: 7542, top1_acc: 0.6900, top5_acc: 0.9850, loss_cls: 0.8418, loss: 0.8418, grad_norm: 1.3215\n",
      "2021-03-29 12:41:07,813 - mmaction - INFO - Epoch [29][50/132]\tlr: 8.415e-02, eta: 0:13:57, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.6900, top5_acc: 0.9750, loss_cls: 0.8487, loss: 0.8487, grad_norm: 1.4120\n",
      "2021-03-29 12:41:14,700 - mmaction - INFO - Epoch [29][75/132]\tlr: 8.344e-02, eta: 0:13:50, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.6250, top5_acc: 0.9700, loss_cls: 0.8689, loss: 0.8689, grad_norm: 1.2653\n",
      "2021-03-29 12:41:21,585 - mmaction - INFO - Epoch [29][100/132]\tlr: 8.271e-02, eta: 0:13:43, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.6650, top5_acc: 0.9800, loss_cls: 0.8060, loss: 0.8060, grad_norm: 1.3942\n",
      "2021-03-29 12:41:28,474 - mmaction - INFO - Epoch [29][125/132]\tlr: 8.197e-02, eta: 0:13:36, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6750, top5_acc: 0.9600, loss_cls: 0.8251, loss: 0.8251, grad_norm: 1.4200\n",
      "2021-03-29 12:41:39,619 - mmaction - INFO - Epoch [30][25/132]\tlr: 8.100e-02, eta: 0:13:27, time: 0.373, data_time: 0.096, memory: 7542, top1_acc: 0.6800, top5_acc: 0.9750, loss_cls: 0.7662, loss: 0.7662, grad_norm: 1.2603\n",
      "2021-03-29 12:41:46,507 - mmaction - INFO - Epoch [30][50/132]\tlr: 8.023e-02, eta: 0:13:20, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6600, top5_acc: 0.9600, loss_cls: 0.8187, loss: 0.8187, grad_norm: 1.3063\n",
      "2021-03-29 12:41:53,399 - mmaction - INFO - Epoch [30][75/132]\tlr: 7.945e-02, eta: 0:13:13, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6950, top5_acc: 0.9750, loss_cls: 0.8337, loss: 0.8337, grad_norm: 1.2363\n",
      "2021-03-29 12:42:00,285 - mmaction - INFO - Epoch [30][100/132]\tlr: 7.866e-02, eta: 0:13:06, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.6550, top5_acc: 0.9500, loss_cls: 0.8373, loss: 0.8373, grad_norm: 1.2329\n",
      "2021-03-29 12:42:07,386 - mmaction - INFO - Epoch [30][125/132]\tlr: 7.786e-02, eta: 0:12:59, time: 0.284, data_time: 0.000, memory: 7542, top1_acc: 0.6750, top5_acc: 0.9450, loss_cls: 0.8893, loss: 0.8893, grad_norm: 1.0879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 7.9 task/s, elapsed: 16s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:42:25,226 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:42:25,228 - mmaction - INFO - \n",
      "top1_acc\t0.6984\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:42:25,229 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:42:25,230 - mmaction - INFO - \n",
      "mean_acc\t0.6984\n",
      "2021-03-29 12:42:25,231 - mmaction - INFO - Epoch(val) [30][132]\ttop1_acc: 0.6984, top5_acc: 1.0000, mean_class_accuracy: 0.6984\n",
      "2021-03-29 12:42:34,678 - mmaction - INFO - Epoch [31][25/132]\tlr: 7.682e-02, eta: 0:12:50, time: 0.378, data_time: 0.097, memory: 7542, top1_acc: 0.6250, top5_acc: 0.9650, loss_cls: 0.9535, loss: 0.9535, grad_norm: 1.2246\n",
      "2021-03-29 12:42:41,679 - mmaction - INFO - Epoch [31][50/132]\tlr: 7.599e-02, eta: 0:12:43, time: 0.280, data_time: 0.000, memory: 7542, top1_acc: 0.5900, top5_acc: 0.9750, loss_cls: 0.8822, loss: 0.8822, grad_norm: 1.2808\n",
      "2021-03-29 12:42:49,007 - mmaction - INFO - Epoch [31][75/132]\tlr: 7.516e-02, eta: 0:12:37, time: 0.293, data_time: 0.000, memory: 7542, top1_acc: 0.6950, top5_acc: 0.9850, loss_cls: 0.8233, loss: 0.8233, grad_norm: 1.3663\n",
      "2021-03-29 12:42:56,003 - mmaction - INFO - Epoch [31][100/132]\tlr: 7.431e-02, eta: 0:12:30, time: 0.280, data_time: 0.000, memory: 7542, top1_acc: 0.6800, top5_acc: 0.9750, loss_cls: 0.7669, loss: 0.7669, grad_norm: 1.2152\n",
      "2021-03-29 12:43:02,948 - mmaction - INFO - Epoch [31][125/132]\tlr: 7.346e-02, eta: 0:12:23, time: 0.278, data_time: 0.000, memory: 7542, top1_acc: 0.6200, top5_acc: 0.9550, loss_cls: 0.9894, loss: 0.9894, grad_norm: 1.6482\n",
      "2021-03-29 12:43:14,239 - mmaction - INFO - Epoch [32][25/132]\tlr: 7.235e-02, eta: 0:12:14, time: 0.378, data_time: 0.097, memory: 7542, top1_acc: 0.6500, top5_acc: 0.9650, loss_cls: 0.8109, loss: 0.8109, grad_norm: 1.2737\n",
      "2021-03-29 12:43:21,210 - mmaction - INFO - Epoch [32][50/132]\tlr: 7.148e-02, eta: 0:12:07, time: 0.279, data_time: 0.000, memory: 7542, top1_acc: 0.5650, top5_acc: 0.9550, loss_cls: 1.1339, loss: 1.1339, grad_norm: 1.4347\n",
      "2021-03-29 12:43:28,178 - mmaction - INFO - Epoch [32][75/132]\tlr: 7.060e-02, eta: 0:12:00, time: 0.279, data_time: 0.000, memory: 7542, top1_acc: 0.6800, top5_acc: 0.9600, loss_cls: 0.7839, loss: 0.7839, grad_norm: 1.0229\n",
      "2021-03-29 12:43:35,138 - mmaction - INFO - Epoch [32][100/132]\tlr: 6.971e-02, eta: 0:11:53, time: 0.278, data_time: 0.000, memory: 7542, top1_acc: 0.7250, top5_acc: 0.9550, loss_cls: 0.7428, loss: 0.7428, grad_norm: 1.2816\n",
      "2021-03-29 12:43:42,090 - mmaction - INFO - Epoch [32][125/132]\tlr: 6.881e-02, eta: 0:11:46, time: 0.278, data_time: 0.000, memory: 7542, top1_acc: 0.6750, top5_acc: 0.9650, loss_cls: 0.8026, loss: 0.8026, grad_norm: 1.3114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 7.4 task/s, elapsed: 17s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:44:01,109 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:44:01,111 - mmaction - INFO - \n",
      "top1_acc\t0.8730\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:44:01,112 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:44:01,113 - mmaction - INFO - \n",
      "mean_acc\t0.8730\n",
      "2021-03-29 12:44:01,430 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_32.pth.\n",
      "2021-03-29 12:44:01,431 - mmaction - INFO - Best top1_acc is 0.8730 at 32 epoch.\n",
      "2021-03-29 12:44:01,432 - mmaction - INFO - Epoch(val) [32][132]\ttop1_acc: 0.8730, top5_acc: 1.0000, mean_class_accuracy: 0.8730\n",
      "2021-03-29 12:44:10,830 - mmaction - INFO - Epoch [33][25/132]\tlr: 6.765e-02, eta: 0:11:37, time: 0.376, data_time: 0.096, memory: 7542, top1_acc: 0.6750, top5_acc: 0.9800, loss_cls: 0.7608, loss: 0.7608, grad_norm: 1.3078\n",
      "2021-03-29 12:44:17,767 - mmaction - INFO - Epoch [33][50/132]\tlr: 6.674e-02, eta: 0:11:30, time: 0.277, data_time: 0.000, memory: 7542, top1_acc: 0.6350, top5_acc: 0.9700, loss_cls: 0.9161, loss: 0.9161, grad_norm: 1.4679\n",
      "2021-03-29 12:44:24,679 - mmaction - INFO - Epoch [33][75/132]\tlr: 6.582e-02, eta: 0:11:23, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6850, top5_acc: 0.9650, loss_cls: 0.7637, loss: 0.7637, grad_norm: 1.4960\n",
      "2021-03-29 12:44:31,603 - mmaction - INFO - Epoch [33][100/132]\tlr: 6.490e-02, eta: 0:11:16, time: 0.277, data_time: 0.000, memory: 7542, top1_acc: 0.7250, top5_acc: 0.9850, loss_cls: 0.7296, loss: 0.7296, grad_norm: 1.4642\n",
      "2021-03-29 12:44:38,527 - mmaction - INFO - Epoch [33][125/132]\tlr: 6.396e-02, eta: 0:11:09, time: 0.277, data_time: 0.000, memory: 7542, top1_acc: 0.6950, top5_acc: 0.9850, loss_cls: 0.7350, loss: 0.7350, grad_norm: 1.1867\n",
      "2021-03-29 12:44:49,739 - mmaction - INFO - Epoch [34][25/132]\tlr: 6.277e-02, eta: 0:11:00, time: 0.375, data_time: 0.097, memory: 7542, top1_acc: 0.7100, top5_acc: 0.9650, loss_cls: 0.7642, loss: 0.7642, grad_norm: 1.3346\n",
      "2021-03-29 12:44:56,667 - mmaction - INFO - Epoch [34][50/132]\tlr: 6.182e-02, eta: 0:10:53, time: 0.277, data_time: 0.000, memory: 7542, top1_acc: 0.7050, top5_acc: 0.9850, loss_cls: 0.7672, loss: 0.7672, grad_norm: 1.2373\n",
      "2021-03-29 12:45:03,594 - mmaction - INFO - Epoch [34][75/132]\tlr: 6.088e-02, eta: 0:10:46, time: 0.277, data_time: 0.000, memory: 7542, top1_acc: 0.6550, top5_acc: 0.9800, loss_cls: 0.8917, loss: 0.8917, grad_norm: 1.5933\n",
      "2021-03-29 12:45:10,515 - mmaction - INFO - Epoch [34][100/132]\tlr: 5.993e-02, eta: 0:10:39, time: 0.277, data_time: 0.000, memory: 7542, top1_acc: 0.6800, top5_acc: 0.9750, loss_cls: 0.7715, loss: 0.7715, grad_norm: 1.2121\n",
      "2021-03-29 12:45:17,440 - mmaction - INFO - Epoch [34][125/132]\tlr: 5.897e-02, eta: 0:10:32, time: 0.277, data_time: 0.000, memory: 7542, top1_acc: 0.6950, top5_acc: 0.9900, loss_cls: 0.7502, loss: 0.7502, grad_norm: 1.2166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 6.2 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:45:39,709 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:45:39,711 - mmaction - INFO - \n",
      "top1_acc\t0.8016\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:45:39,712 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:45:39,713 - mmaction - INFO - \n",
      "mean_acc\t0.8016\n",
      "2021-03-29 12:45:39,714 - mmaction - INFO - Epoch(val) [34][132]\ttop1_acc: 0.8016, top5_acc: 1.0000, mean_class_accuracy: 0.8016\n",
      "2021-03-29 12:45:49,041 - mmaction - INFO - Epoch [35][25/132]\tlr: 5.774e-02, eta: 0:10:23, time: 0.373, data_time: 0.095, memory: 7542, top1_acc: 0.7150, top5_acc: 0.9750, loss_cls: 0.7551, loss: 0.7551, grad_norm: 1.3288\n",
      "2021-03-29 12:45:55,947 - mmaction - INFO - Epoch [35][50/132]\tlr: 5.678e-02, eta: 0:10:16, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6100, top5_acc: 0.9800, loss_cls: 0.9415, loss: 0.9415, grad_norm: 1.4335\n",
      "2021-03-29 12:46:02,847 - mmaction - INFO - Epoch [35][75/132]\tlr: 5.582e-02, eta: 0:10:09, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6900, top5_acc: 0.9800, loss_cls: 0.7707, loss: 0.7707, grad_norm: 1.2507\n",
      "2021-03-29 12:46:09,746 - mmaction - INFO - Epoch [35][100/132]\tlr: 5.485e-02, eta: 0:10:01, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6750, top5_acc: 0.9500, loss_cls: 0.8309, loss: 0.8309, grad_norm: 1.2666\n",
      "2021-03-29 12:46:16,657 - mmaction - INFO - Epoch [35][125/132]\tlr: 5.388e-02, eta: 0:09:54, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6600, top5_acc: 0.9700, loss_cls: 0.8491, loss: 0.8491, grad_norm: 1.1505\n",
      "2021-03-29 12:46:27,788 - mmaction - INFO - Epoch [36][25/132]\tlr: 5.264e-02, eta: 0:09:46, time: 0.372, data_time: 0.095, memory: 7542, top1_acc: 0.7100, top5_acc: 0.9700, loss_cls: 0.7949, loss: 0.7949, grad_norm: 1.0499\n",
      "2021-03-29 12:46:34,686 - mmaction - INFO - Epoch [36][50/132]\tlr: 5.167e-02, eta: 0:09:39, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6350, top5_acc: 0.9750, loss_cls: 0.8894, loss: 0.8894, grad_norm: 1.3446\n",
      "2021-03-29 12:46:41,585 - mmaction - INFO - Epoch [36][75/132]\tlr: 5.070e-02, eta: 0:09:31, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7050, top5_acc: 0.9650, loss_cls: 0.7577, loss: 0.7577, grad_norm: 1.0177\n",
      "2021-03-29 12:46:48,493 - mmaction - INFO - Epoch [36][100/132]\tlr: 4.973e-02, eta: 0:09:24, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7500, top5_acc: 0.9900, loss_cls: 0.7122, loss: 0.7122, grad_norm: 1.2191\n",
      "2021-03-29 12:46:55,394 - mmaction - INFO - Epoch [36][125/132]\tlr: 4.876e-02, eta: 0:09:17, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6850, top5_acc: 0.9800, loss_cls: 0.7861, loss: 0.7861, grad_norm: 1.2918\n",
      "2021-03-29 12:46:57,227 - mmaction - INFO - Saving checkpoint at 36 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 7.8 task/s, elapsed: 16s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:47:13,822 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:47:13,824 - mmaction - INFO - \n",
      "top1_acc\t0.7778\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:47:13,824 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:47:13,826 - mmaction - INFO - \n",
      "mean_acc\t0.7778\n",
      "2021-03-29 12:47:13,827 - mmaction - INFO - Epoch(val) [36][132]\ttop1_acc: 0.7778, top5_acc: 1.0000, mean_class_accuracy: 0.7778\n",
      "2021-03-29 12:47:23,158 - mmaction - INFO - Epoch [37][25/132]\tlr: 4.751e-02, eta: 0:09:08, time: 0.373, data_time: 0.096, memory: 7542, top1_acc: 0.7100, top5_acc: 0.9750, loss_cls: 0.7372, loss: 0.7372, grad_norm: 1.1137\n",
      "2021-03-29 12:47:30,048 - mmaction - INFO - Epoch [37][50/132]\tlr: 4.654e-02, eta: 0:09:01, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7350, top5_acc: 0.9700, loss_cls: 0.6571, loss: 0.6571, grad_norm: 1.0894\n",
      "2021-03-29 12:47:36,945 - mmaction - INFO - Epoch [37][75/132]\tlr: 4.557e-02, eta: 0:08:54, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7400, top5_acc: 0.9800, loss_cls: 0.6838, loss: 0.6838, grad_norm: 1.1417\n",
      "2021-03-29 12:47:43,844 - mmaction - INFO - Epoch [37][100/132]\tlr: 4.461e-02, eta: 0:08:47, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6750, top5_acc: 0.9650, loss_cls: 0.8338, loss: 0.8338, grad_norm: 1.3346\n",
      "2021-03-29 12:47:50,751 - mmaction - INFO - Epoch [37][125/132]\tlr: 4.364e-02, eta: 0:08:40, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7300, top5_acc: 0.9850, loss_cls: 0.6805, loss: 0.6805, grad_norm: 1.1223\n",
      "2021-03-29 12:48:01,900 - mmaction - INFO - Epoch [38][25/132]\tlr: 4.241e-02, eta: 0:08:31, time: 0.373, data_time: 0.096, memory: 7542, top1_acc: 0.6600, top5_acc: 0.9800, loss_cls: 0.8494, loss: 0.8494, grad_norm: 1.2582\n",
      "2021-03-29 12:48:08,793 - mmaction - INFO - Epoch [38][50/132]\tlr: 4.145e-02, eta: 0:08:24, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7600, top5_acc: 0.9700, loss_cls: 0.6564, loss: 0.6564, grad_norm: 1.0647\n",
      "2021-03-29 12:48:15,681 - mmaction - INFO - Epoch [38][75/132]\tlr: 4.049e-02, eta: 0:08:17, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6850, top5_acc: 0.9800, loss_cls: 0.7269, loss: 0.7269, grad_norm: 1.2545\n",
      "2021-03-29 12:48:22,577 - mmaction - INFO - Epoch [38][100/132]\tlr: 3.954e-02, eta: 0:08:10, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6750, top5_acc: 0.9750, loss_cls: 0.8544, loss: 0.8544, grad_norm: 1.4065\n",
      "2021-03-29 12:48:29,478 - mmaction - INFO - Epoch [38][125/132]\tlr: 3.859e-02, eta: 0:08:03, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7350, top5_acc: 0.9650, loss_cls: 0.7304, loss: 0.7304, grad_norm: 1.1216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 8.2 task/s, elapsed: 15s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:48:46,678 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:48:46,679 - mmaction - INFO - \n",
      "top1_acc\t0.8889\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:48:46,680 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:48:46,681 - mmaction - INFO - \n",
      "mean_acc\t0.8889\n",
      "2021-03-29 12:48:46,987 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_38.pth.\n",
      "2021-03-29 12:48:46,988 - mmaction - INFO - Best top1_acc is 0.8889 at 38 epoch.\n",
      "2021-03-29 12:48:46,988 - mmaction - INFO - Epoch(val) [38][132]\ttop1_acc: 0.8889, top5_acc: 1.0000, mean_class_accuracy: 0.8889\n",
      "2021-03-29 12:48:56,353 - mmaction - INFO - Epoch [39][25/132]\tlr: 3.738e-02, eta: 0:07:54, time: 0.374, data_time: 0.098, memory: 7542, top1_acc: 0.7200, top5_acc: 0.9800, loss_cls: 0.7111, loss: 0.7111, grad_norm: 1.0545\n",
      "2021-03-29 12:49:03,252 - mmaction - INFO - Epoch [39][50/132]\tlr: 3.645e-02, eta: 0:07:47, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7000, top5_acc: 0.9800, loss_cls: 0.6746, loss: 0.6746, grad_norm: 1.3612\n",
      "2021-03-29 12:49:10,143 - mmaction - INFO - Epoch [39][75/132]\tlr: 3.551e-02, eta: 0:07:40, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7150, top5_acc: 0.9800, loss_cls: 0.7297, loss: 0.7297, grad_norm: 1.4894\n",
      "2021-03-29 12:49:17,040 - mmaction - INFO - Epoch [39][100/132]\tlr: 3.459e-02, eta: 0:07:33, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7000, top5_acc: 0.9800, loss_cls: 0.7431, loss: 0.7431, grad_norm: 1.4003\n",
      "2021-03-29 12:49:23,952 - mmaction - INFO - Epoch [39][125/132]\tlr: 3.366e-02, eta: 0:07:26, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7050, top5_acc: 0.9800, loss_cls: 0.7211, loss: 0.7211, grad_norm: 1.2026\n",
      "2021-03-29 12:49:35,093 - mmaction - INFO - Epoch [40][25/132]\tlr: 3.249e-02, eta: 0:07:17, time: 0.373, data_time: 0.096, memory: 7542, top1_acc: 0.7200, top5_acc: 0.9700, loss_cls: 0.7021, loss: 0.7021, grad_norm: 1.2591\n",
      "2021-03-29 12:49:41,988 - mmaction - INFO - Epoch [40][50/132]\tlr: 3.159e-02, eta: 0:07:10, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7000, top5_acc: 0.9650, loss_cls: 0.6954, loss: 0.6954, grad_norm: 1.1760\n",
      "2021-03-29 12:49:48,883 - mmaction - INFO - Epoch [40][75/132]\tlr: 3.069e-02, eta: 0:07:03, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7100, top5_acc: 0.9700, loss_cls: 0.7019, loss: 0.7019, grad_norm: 1.3349\n",
      "2021-03-29 12:49:55,777 - mmaction - INFO - Epoch [40][100/132]\tlr: 2.979e-02, eta: 0:06:56, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6600, top5_acc: 0.9750, loss_cls: 0.7911, loss: 0.7911, grad_norm: 1.3430\n",
      "2021-03-29 12:50:02,678 - mmaction - INFO - Epoch [40][125/132]\tlr: 2.891e-02, eta: 0:06:49, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7150, top5_acc: 0.9650, loss_cls: 0.7520, loss: 0.7520, grad_norm: 1.1901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 5.9 task/s, elapsed: 21s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:50:25,956 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:50:25,958 - mmaction - INFO - \n",
      "top1_acc\t0.8968\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:50:25,959 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:50:25,960 - mmaction - INFO - \n",
      "mean_acc\t0.8968\n",
      "2021-03-29 12:50:26,280 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_40.pth.\n",
      "2021-03-29 12:50:26,281 - mmaction - INFO - Best top1_acc is 0.8968 at 40 epoch.\n",
      "2021-03-29 12:50:26,282 - mmaction - INFO - Epoch(val) [40][132]\ttop1_acc: 0.8968, top5_acc: 1.0000, mean_class_accuracy: 0.8968\n",
      "2021-03-29 12:50:35,651 - mmaction - INFO - Epoch [41][25/132]\tlr: 2.779e-02, eta: 0:06:40, time: 0.375, data_time: 0.098, memory: 7542, top1_acc: 0.7900, top5_acc: 0.9800, loss_cls: 0.6404, loss: 0.6404, grad_norm: 1.0543\n",
      "2021-03-29 12:50:42,536 - mmaction - INFO - Epoch [41][50/132]\tlr: 2.692e-02, eta: 0:06:33, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.7050, top5_acc: 0.9600, loss_cls: 0.7288, loss: 0.7288, grad_norm: 1.1548\n",
      "2021-03-29 12:50:49,437 - mmaction - INFO - Epoch [41][75/132]\tlr: 2.606e-02, eta: 0:06:26, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7050, top5_acc: 0.9550, loss_cls: 0.8225, loss: 0.8225, grad_norm: 1.1756\n",
      "2021-03-29 12:50:56,323 - mmaction - INFO - Epoch [41][100/132]\tlr: 2.521e-02, eta: 0:06:19, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.7350, top5_acc: 0.9850, loss_cls: 0.6713, loss: 0.6713, grad_norm: 1.0980\n",
      "2021-03-29 12:51:03,213 - mmaction - INFO - Epoch [41][125/132]\tlr: 2.437e-02, eta: 0:06:12, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7800, top5_acc: 0.9900, loss_cls: 0.5738, loss: 0.5738, grad_norm: 0.9121\n",
      "2021-03-29 12:51:14,360 - mmaction - INFO - Epoch [42][25/132]\tlr: 2.331e-02, eta: 0:06:03, time: 0.373, data_time: 0.095, memory: 7542, top1_acc: 0.6850, top5_acc: 0.9700, loss_cls: 0.7901, loss: 0.7901, grad_norm: 1.2706\n",
      "2021-03-29 12:51:21,257 - mmaction - INFO - Epoch [42][50/132]\tlr: 2.250e-02, eta: 0:05:56, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7100, top5_acc: 0.9750, loss_cls: 0.6980, loss: 0.6980, grad_norm: 1.1228\n",
      "2021-03-29 12:51:28,159 - mmaction - INFO - Epoch [42][75/132]\tlr: 2.169e-02, eta: 0:05:49, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7600, top5_acc: 0.9650, loss_cls: 0.5942, loss: 0.5942, grad_norm: 1.0570\n",
      "2021-03-29 12:51:35,050 - mmaction - INFO - Epoch [42][100/132]\tlr: 2.089e-02, eta: 0:05:42, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7400, top5_acc: 0.9850, loss_cls: 0.6808, loss: 0.6808, grad_norm: 1.1553\n",
      "2021-03-29 12:51:41,945 - mmaction - INFO - Epoch [42][125/132]\tlr: 2.011e-02, eta: 0:05:35, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.8150, top5_acc: 0.9950, loss_cls: 0.5567, loss: 0.5567, grad_norm: 1.0294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 7.3 task/s, elapsed: 17s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:52:01,100 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:52:01,101 - mmaction - INFO - \n",
      "top1_acc\t0.9206\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:52:01,102 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:52:01,103 - mmaction - INFO - \n",
      "mean_acc\t0.9206\n",
      "2021-03-29 12:52:01,409 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_42.pth.\n",
      "2021-03-29 12:52:01,410 - mmaction - INFO - Best top1_acc is 0.9206 at 42 epoch.\n",
      "2021-03-29 12:52:01,411 - mmaction - INFO - Epoch(val) [42][132]\ttop1_acc: 0.9206, top5_acc: 1.0000, mean_class_accuracy: 0.9206\n",
      "2021-03-29 12:52:10,768 - mmaction - INFO - Epoch [43][25/132]\tlr: 1.912e-02, eta: 0:05:26, time: 0.374, data_time: 0.098, memory: 7542, top1_acc: 0.7450, top5_acc: 0.9950, loss_cls: 0.5536, loss: 0.5536, grad_norm: 1.0520\n",
      "2021-03-29 12:52:17,707 - mmaction - INFO - Epoch [43][50/132]\tlr: 1.836e-02, eta: 0:05:19, time: 0.278, data_time: 0.000, memory: 7542, top1_acc: 0.7400, top5_acc: 0.9800, loss_cls: 0.7048, loss: 0.7048, grad_norm: 1.0717\n",
      "2021-03-29 12:52:24,609 - mmaction - INFO - Epoch [43][75/132]\tlr: 1.762e-02, eta: 0:05:12, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7600, top5_acc: 0.9950, loss_cls: 0.6585, loss: 0.6585, grad_norm: 1.3757\n",
      "2021-03-29 12:52:31,501 - mmaction - INFO - Epoch [43][100/132]\tlr: 1.688e-02, eta: 0:05:05, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7100, top5_acc: 0.9750, loss_cls: 0.8013, loss: 0.8013, grad_norm: 1.3324\n",
      "2021-03-29 12:52:38,401 - mmaction - INFO - Epoch [43][125/132]\tlr: 1.616e-02, eta: 0:04:58, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6850, top5_acc: 0.9650, loss_cls: 0.7740, loss: 0.7740, grad_norm: 1.2242\n",
      "2021-03-29 12:52:49,565 - mmaction - INFO - Epoch [44][25/132]\tlr: 1.525e-02, eta: 0:04:49, time: 0.373, data_time: 0.096, memory: 7542, top1_acc: 0.7300, top5_acc: 0.9950, loss_cls: 0.6254, loss: 0.6254, grad_norm: 1.1622\n",
      "2021-03-29 12:52:56,472 - mmaction - INFO - Epoch [44][50/132]\tlr: 1.456e-02, eta: 0:04:42, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7400, top5_acc: 0.9950, loss_cls: 0.6008, loss: 0.6008, grad_norm: 1.0857\n",
      "2021-03-29 12:53:03,367 - mmaction - INFO - Epoch [44][75/132]\tlr: 1.388e-02, eta: 0:04:35, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7750, top5_acc: 0.9750, loss_cls: 0.6031, loss: 0.6031, grad_norm: 1.2765\n",
      "2021-03-29 12:53:10,261 - mmaction - INFO - Epoch [44][100/132]\tlr: 1.322e-02, eta: 0:04:28, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6950, top5_acc: 0.9500, loss_cls: 0.7259, loss: 0.7259, grad_norm: 1.3194\n",
      "2021-03-29 12:53:17,167 - mmaction - INFO - Epoch [44][125/132]\tlr: 1.257e-02, eta: 0:04:21, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7300, top5_acc: 0.9950, loss_cls: 0.7302, loss: 0.7302, grad_norm: 1.4291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 8.3 task/s, elapsed: 15s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:53:34,189 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:53:34,191 - mmaction - INFO - \n",
      "top1_acc\t0.9365\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:53:34,192 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:53:34,194 - mmaction - INFO - \n",
      "mean_acc\t0.9365\n",
      "2021-03-29 12:53:34,515 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_44.pth.\n",
      "2021-03-29 12:53:34,516 - mmaction - INFO - Best top1_acc is 0.9365 at 44 epoch.\n",
      "2021-03-29 12:53:34,516 - mmaction - INFO - Epoch(val) [44][132]\ttop1_acc: 0.9365, top5_acc: 1.0000, mean_class_accuracy: 0.9365\n",
      "2021-03-29 12:53:43,861 - mmaction - INFO - Epoch [45][25/132]\tlr: 1.175e-02, eta: 0:04:12, time: 0.374, data_time: 0.097, memory: 7542, top1_acc: 0.7250, top5_acc: 0.9750, loss_cls: 0.7311, loss: 0.7311, grad_norm: 1.2606\n",
      "2021-03-29 12:53:50,752 - mmaction - INFO - Epoch [45][50/132]\tlr: 1.113e-02, eta: 0:04:05, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6950, top5_acc: 0.9900, loss_cls: 0.7231, loss: 0.7231, grad_norm: 1.0746\n",
      "2021-03-29 12:53:57,649 - mmaction - INFO - Epoch [45][75/132]\tlr: 1.053e-02, eta: 0:03:58, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7300, top5_acc: 0.9900, loss_cls: 0.6016, loss: 0.6016, grad_norm: 1.0683\n",
      "2021-03-29 12:54:04,543 - mmaction - INFO - Epoch [45][100/132]\tlr: 9.941e-03, eta: 0:03:51, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7150, top5_acc: 0.9800, loss_cls: 0.7133, loss: 0.7133, grad_norm: 1.3340\n",
      "2021-03-29 12:54:11,452 - mmaction - INFO - Epoch [45][125/132]\tlr: 9.367e-03, eta: 0:03:44, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7050, top5_acc: 0.9800, loss_cls: 0.7365, loss: 0.7365, grad_norm: 1.2877\n",
      "2021-03-29 12:54:22,619 - mmaction - INFO - Epoch [46][25/132]\tlr: 8.655e-03, eta: 0:03:35, time: 0.373, data_time: 0.096, memory: 7542, top1_acc: 0.7700, top5_acc: 0.9850, loss_cls: 0.5569, loss: 0.5569, grad_norm: 1.0856\n",
      "2021-03-29 12:54:29,525 - mmaction - INFO - Epoch [46][50/132]\tlr: 8.116e-03, eta: 0:03:28, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7050, top5_acc: 0.9800, loss_cls: 0.6689, loss: 0.6689, grad_norm: 1.2185\n",
      "2021-03-29 12:54:36,416 - mmaction - INFO - Epoch [46][75/132]\tlr: 7.593e-03, eta: 0:03:21, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.6950, top5_acc: 0.9650, loss_cls: 0.7452, loss: 0.7452, grad_norm: 1.3518\n",
      "2021-03-29 12:54:43,310 - mmaction - INFO - Epoch [46][100/132]\tlr: 7.086e-03, eta: 0:03:14, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7650, top5_acc: 0.9700, loss_cls: 0.5646, loss: 0.5646, grad_norm: 1.0445\n",
      "2021-03-29 12:54:50,205 - mmaction - INFO - Epoch [46][125/132]\tlr: 6.596e-03, eta: 0:03:07, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7650, top5_acc: 0.9700, loss_cls: 0.6401, loss: 0.6401, grad_norm: 1.1602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 4.5 task/s, elapsed: 28s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:55:20,084 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:55:20,086 - mmaction - INFO - \n",
      "top1_acc\t0.9048\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:55:20,086 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:55:20,088 - mmaction - INFO - \n",
      "mean_acc\t0.9048\n",
      "2021-03-29 12:55:20,089 - mmaction - INFO - Epoch(val) [46][132]\ttop1_acc: 0.9048, top5_acc: 1.0000, mean_class_accuracy: 0.9048\n",
      "2021-03-29 12:55:29,408 - mmaction - INFO - Epoch [47][25/132]\tlr: 5.991e-03, eta: 0:02:58, time: 0.373, data_time: 0.096, memory: 7542, top1_acc: 0.7600, top5_acc: 0.9700, loss_cls: 0.6438, loss: 0.6438, grad_norm: 1.1836\n",
      "2021-03-29 12:55:36,285 - mmaction - INFO - Epoch [47][50/132]\tlr: 5.538e-03, eta: 0:02:51, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.6950, top5_acc: 0.9750, loss_cls: 0.6791, loss: 0.6791, grad_norm: 1.2062\n",
      "2021-03-29 12:55:43,171 - mmaction - INFO - Epoch [47][75/132]\tlr: 5.102e-03, eta: 0:02:44, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.7750, top5_acc: 0.9850, loss_cls: 0.5889, loss: 0.5889, grad_norm: 1.2161\n",
      "2021-03-29 12:55:50,055 - mmaction - INFO - Epoch [47][100/132]\tlr: 4.683e-03, eta: 0:02:37, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.8050, top5_acc: 0.9850, loss_cls: 0.6002, loss: 0.6002, grad_norm: 1.1757\n",
      "2021-03-29 12:55:56,941 - mmaction - INFO - Epoch [47][125/132]\tlr: 4.281e-03, eta: 0:02:30, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.7650, top5_acc: 0.9750, loss_cls: 0.5336, loss: 0.5336, grad_norm: 1.1228\n",
      "2021-03-29 12:56:08,100 - mmaction - INFO - Epoch [48][25/132]\tlr: 3.791e-03, eta: 0:02:21, time: 0.373, data_time: 0.097, memory: 7542, top1_acc: 0.7800, top5_acc: 0.9750, loss_cls: 0.5768, loss: 0.5768, grad_norm: 1.0639\n",
      "2021-03-29 12:56:14,982 - mmaction - INFO - Epoch [48][50/132]\tlr: 3.429e-03, eta: 0:02:14, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.7450, top5_acc: 0.9850, loss_cls: 0.6117, loss: 0.6117, grad_norm: 1.3891\n",
      "2021-03-29 12:56:21,869 - mmaction - INFO - Epoch [48][75/132]\tlr: 3.084e-03, eta: 0:02:07, time: 0.275, data_time: 0.000, memory: 7542, top1_acc: 0.7650, top5_acc: 0.9750, loss_cls: 0.5846, loss: 0.5846, grad_norm: 1.2654\n",
      "2021-03-29 12:56:28,768 - mmaction - INFO - Epoch [48][100/132]\tlr: 2.757e-03, eta: 0:02:00, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7500, top5_acc: 0.9650, loss_cls: 0.6421, loss: 0.6421, grad_norm: 1.1038\n",
      "2021-03-29 12:56:35,659 - mmaction - INFO - Epoch [48][125/132]\tlr: 2.447e-03, eta: 0:01:53, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7950, top5_acc: 0.9900, loss_cls: 0.5121, loss: 0.5121, grad_norm: 1.2533\n",
      "2021-03-29 12:56:37,478 - mmaction - INFO - Saving checkpoint at 48 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 8.3 task/s, elapsed: 15s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:56:53,000 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:56:53,002 - mmaction - INFO - \n",
      "top1_acc\t0.9444\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:56:53,002 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:56:53,003 - mmaction - INFO - \n",
      "mean_acc\t0.9444\n",
      "2021-03-29 12:56:53,309 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_48.pth.\n",
      "2021-03-29 12:56:53,310 - mmaction - INFO - Best top1_acc is 0.9444 at 48 epoch.\n",
      "2021-03-29 12:56:53,311 - mmaction - INFO - Epoch(val) [48][132]\ttop1_acc: 0.9444, top5_acc: 1.0000, mean_class_accuracy: 0.9444\n",
      "2021-03-29 12:57:02,606 - mmaction - INFO - Epoch [49][25/132]\tlr: 2.078e-03, eta: 0:01:44, time: 0.372, data_time: 0.095, memory: 7542, top1_acc: 0.6650, top5_acc: 0.9600, loss_cls: 0.6950, loss: 0.6950, grad_norm: 1.2440\n",
      "2021-03-29 12:57:09,496 - mmaction - INFO - Epoch [49][50/132]\tlr: 1.809e-03, eta: 0:01:37, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7600, top5_acc: 0.9950, loss_cls: 0.6444, loss: 0.6444, grad_norm: 1.1846\n",
      "2021-03-29 12:57:16,385 - mmaction - INFO - Epoch [49][75/132]\tlr: 1.559e-03, eta: 0:01:30, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7350, top5_acc: 0.9850, loss_cls: 0.6016, loss: 0.6016, grad_norm: 1.2235\n",
      "2021-03-29 12:57:23,275 - mmaction - INFO - Epoch [49][100/132]\tlr: 1.328e-03, eta: 0:01:23, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7300, top5_acc: 0.9850, loss_cls: 0.6470, loss: 0.6470, grad_norm: 1.3103\n",
      "2021-03-29 12:57:30,169 - mmaction - INFO - Epoch [49][125/132]\tlr: 1.114e-03, eta: 0:01:15, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7300, top5_acc: 0.9650, loss_cls: 0.6841, loss: 0.6841, grad_norm: 1.3238\n",
      "2021-03-29 12:57:41,325 - mmaction - INFO - Epoch [50][25/132]\tlr: 8.683e-04, eta: 0:01:07, time: 0.372, data_time: 0.095, memory: 7542, top1_acc: 0.7500, top5_acc: 0.9950, loss_cls: 0.5485, loss: 0.5485, grad_norm: 1.0365\n",
      "2021-03-29 12:57:48,227 - mmaction - INFO - Epoch [50][50/132]\tlr: 6.973e-04, eta: 0:01:00, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7500, top5_acc: 0.9850, loss_cls: 0.5969, loss: 0.5969, grad_norm: 1.2212\n",
      "2021-03-29 12:57:55,122 - mmaction - INFO - Epoch [50][75/132]\tlr: 5.448e-04, eta: 0:00:53, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7850, top5_acc: 0.9900, loss_cls: 0.5532, loss: 0.5532, grad_norm: 1.1956\n",
      "2021-03-29 12:58:02,023 - mmaction - INFO - Epoch [50][100/132]\tlr: 4.111e-04, eta: 0:00:45, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7850, top5_acc: 0.9900, loss_cls: 0.5519, loss: 0.5519, grad_norm: 1.0584\n",
      "2021-03-29 12:58:08,914 - mmaction - INFO - Epoch [50][125/132]\tlr: 2.961e-04, eta: 0:00:38, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7550, top5_acc: 0.9800, loss_cls: 0.6028, loss: 0.6028, grad_norm: 1.1568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 8.2 task/s, elapsed: 15s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 12:58:26,284 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 12:58:26,286 - mmaction - INFO - \n",
      "top1_acc\t0.9365\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 12:58:26,286 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 12:58:26,287 - mmaction - INFO - \n",
      "mean_acc\t0.9365\n",
      "2021-03-29 12:58:26,287 - mmaction - INFO - Epoch(val) [50][132]\ttop1_acc: 0.9365, top5_acc: 1.0000, mean_class_accuracy: 0.9365\n",
      "2021-03-29 12:58:35,659 - mmaction - INFO - Epoch [51][25/132]\tlr: 1.763e-04, eta: 0:00:30, time: 0.375, data_time: 0.098, memory: 7542, top1_acc: 0.7600, top5_acc: 0.9750, loss_cls: 0.6415, loss: 0.6415, grad_norm: 1.1715\n",
      "2021-03-29 12:58:42,555 - mmaction - INFO - Epoch [51][50/132]\tlr: 1.042e-04, eta: 0:00:22, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7450, top5_acc: 0.9800, loss_cls: 0.6178, loss: 0.6178, grad_norm: 1.2646\n",
      "2021-03-29 12:58:49,449 - mmaction - INFO - Epoch [51][75/132]\tlr: 5.095e-05, eta: 0:00:15, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7400, top5_acc: 0.9900, loss_cls: 0.6026, loss: 0.6026, grad_norm: 1.0846\n",
      "2021-03-29 12:58:56,342 - mmaction - INFO - Epoch [51][100/132]\tlr: 1.656e-05, eta: 0:00:08, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7700, top5_acc: 0.9900, loss_cls: 0.6322, loss: 0.6322, grad_norm: 1.2376\n",
      "2021-03-29 12:59:03,240 - mmaction - INFO - Epoch [51][125/132]\tlr: 1.068e-06, eta: 0:00:01, time: 0.276, data_time: 0.000, memory: 7542, top1_acc: 0.7600, top5_acc: 0.9850, loss_cls: 0.5627, loss: 0.5627, grad_norm: 1.0976\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model50e\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 2.5 task/s, elapsed: 50s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.9603\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.9603\n",
      "top1_acc: 0.9603\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.9603\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmaction.models import build_model\n",
    "from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=4,\n",
    "        workers_per_gpu=1,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'], yticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# TPN 96.83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64CW6d_AaT-Q",
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-29 21:56:37--  https://download.openmmlab.com/mmaction/recognition/tpn/tpn_imagenet_pretrained_slowonly_r50_8x8x1_150e_kinetics_rgb/tpn_imagenet_pretrained_slowonly_r50_8x8x1_150e_kinetics_rgb_20200923-52629684.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.75.20.25\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.75.20.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 366390252 (349M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/tpn_imagenet_pretrained_slowonly_r50_8x8x1_150e_kinetics_rgb_20200923-52629684.pth’\n",
      "\n",
      "checkpoints/tpn_ima 100%[===================>] 349,42M  1021KB/s    in 4m 12s  \n",
      "\n",
      "2021-03-29 22:00:52 (1,39 MB/s) - ‘checkpoints/tpn_imagenet_pretrained_slowonly_r50_8x8x1_150e_kinetics_rgb_20200923-52629684.pth’ saved [366390252/366390252]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/tpn/tpn_imagenet_pretrained_slowonly_r50_8x8x1_150e_kinetics_rgb/tpn_imagenet_pretrained_slowonly_r50_8x8x1_150e_kinetics_rgb_20200923-52629684.pth \\\n",
    "      -O checkpoints/tpn_imagenet_pretrained_slowonly_r50_8x8x1_150e_kinetics_rgb_20200923-52629684.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/tpn/tpn_imagenet_pretrained_slowonly_r50_8x8x1_150e_kinetics_rgb.py')\n",
    "# print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='ResNet3dSlowOnly',\n",
      "        depth=50,\n",
      "        pretrained='torchvision://resnet50',\n",
      "        lateral=False,\n",
      "        out_indices=(2, 3),\n",
      "        conv1_kernel=(1, 7, 7),\n",
      "        conv1_stride_t=1,\n",
      "        pool1_stride_t=1,\n",
      "        inflate=(0, 0, 1, 1),\n",
      "        norm_eval=False),\n",
      "    neck=dict(\n",
      "        type='TPN',\n",
      "        in_channels=(1024, 2048),\n",
      "        out_channels=1024,\n",
      "        spatial_modulation_cfg=dict(\n",
      "            in_channels=(1024, 2048), out_channels=2048),\n",
      "        temporal_modulation_cfg=dict(downsample_scales=(8, 8)),\n",
      "        upsample_cfg=dict(scale_factor=(1, 1, 1)),\n",
      "        downsample_cfg=dict(downsample_scale=(1, 1, 1)),\n",
      "        level_fusion_cfg=dict(\n",
      "            in_channels=(1024, 1024),\n",
      "            mid_channels=(1024, 1024),\n",
      "            out_channels=2048,\n",
      "            downsample_scales=((1, 1, 1), (1, 1, 1))),\n",
      "        aux_head_cfg=dict(out_channels=400, loss_weight=0.5)),\n",
      "    cls_head=dict(\n",
      "        type='TPNHead',\n",
      "        num_classes=7,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        consensus=dict(type='AvgConsensus', dim=1),\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "checkpoint_config = dict(interval=12)\n",
      "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/tpn_imagenet_pretrained_slowonly_r50_8x8x1_150e_kinetics_rgb_20200923-52629684.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'RawframeDataset'\n",
      "data_root = 'data/childact_rgb_rawframe/train/'\n",
      "data_root_val = 'data/childact_rgb_rawframe/val/'\n",
      "ann_file_train = 'data/childact_rgb_rawframe/childact_train_rgb_rawframe.txt'\n",
      "ann_file_val = 'data/childact_rgb_rawframe/childact_val_rgb_rawframe.txt'\n",
      "ann_file_test = 'data/childact_rgb_rawframe/childact_test_rgb_rawframe.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='SampleFrames', clip_len=8, frame_interval=8, num_clips=1),\n",
      "    dict(type='FrameSelector'),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(type='ColorJitter', color_space_aug=True),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=8,\n",
      "        frame_interval=8,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='FrameSelector'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='ColorJitter', color_space_aug=True),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=8,\n",
      "        frame_interval=8,\n",
      "        num_clips=10,\n",
      "        test_mode=True),\n",
      "    dict(type='FrameSelector'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='ThreeCrop', crop_size=256),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=8,\n",
      "    train=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rgb_rawframe/childact_train_rgb_rawframe.txt',\n",
      "        data_prefix='data/childact_rgb_rawframe/train/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames', clip_len=8, frame_interval=8,\n",
      "                num_clips=1),\n",
      "            dict(type='FrameSelector'),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(type='ColorJitter', color_space_aug=True),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ],\n",
      "        start_index=0),\n",
      "    val=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rgb_rawframe/childact_val_rgb_rawframe.txt',\n",
      "        data_prefix='data/childact_rgb_rawframe/val/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=8,\n",
      "                frame_interval=8,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='FrameSelector'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='ColorJitter', color_space_aug=True),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        start_index=0),\n",
      "    test=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rgb_rawframe/childact_test_rgb_rawframe.txt',\n",
      "        data_prefix='data/childact_rgb_rawframe/test/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=8,\n",
      "                frame_interval=8,\n",
      "                num_clips=10,\n",
      "                test_mode=True),\n",
      "            dict(type='FrameSelector'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='ThreeCrop', crop_size=256),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        start_index=0))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "optimizer = dict(\n",
      "    type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(10, 1e-05),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "total_epochs = 51\n",
      "work_dir = './childact-checkpoints/childact-TPN'\n",
      "omnisource = False\n",
      "momentum_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(0.8947368421052632, 1),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/childact-TPN/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_rgb_rawframe/train/'\n",
    "cfg.data_root_val = 'data/childact_rgb_rawframe/val/'\n",
    "cfg.ann_file_train = 'data/childact_rgb_rawframe/childact_train_rgb_rawframe.txt'\n",
    "cfg.ann_file_val = 'data/childact_rgb_rawframe/childact_val_rgb_rawframe.txt'\n",
    "cfg.ann_file_test = 'data/childact_rgb_rawframe/childact_test_rgb_rawframe.txt'\n",
    "\n",
    "# cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_rgb_rawframe/childact_test_rgb_rawframe.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_rgb_rawframe/test/'\n",
    "\n",
    "# cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_rgb_rawframe/childact_train_rgb_rawframe.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_rgb_rawframe/train/'\n",
    "\n",
    "# cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_rgb_rawframe/childact_val_rgb_rawframe.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_rgb_rawframe/val/'\n",
    "\n",
    "cfg.data.train.start_index = 0\n",
    "cfg.data.test.start_index = 0\n",
    "cfg.data.val.start_index = 0\n",
    "\n",
    "# cfg.data.test.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# cfg.data.train.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# cfg.data.val.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = 'checkpoints/tpn_imagenet_pretrained_slowonly_r50_8x8x1_150e_kinetics_rgb_20200923-52629684.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/childact-TPN'\n",
    "\n",
    "# cfg.train_pipeline[1] = dict(type='RawFrameDecode')\n",
    "# cfg.test_pipeline[1] = dict(type='RawFrameDecode')\n",
    "# cfg.val_pipeline[1] = dict(type='RawFrameDecode')\n",
    "\n",
    "# cfg.img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
    "\n",
    "# cfg.train_pipeline = [\n",
    "#     dict(type='SampleFrames', clip_len=8, frame_interval=8, num_clips=1),\n",
    "#     dict(type='RawFrameDecode'),\n",
    "# #     dict(type='Resize', scale=(-1, 256)),\n",
    "# #     dict(type='RandomCrop', size=224),\n",
    "#     dict(type='RandomResizedCrop'),\n",
    "#     dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "# #     dict(type='Flip', flip_ratio=0.5),\n",
    "#     dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "#     dict(type='FormatShape', input_format='NCTHW'),\n",
    "#     dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "#     dict(type='ToTensor', keys=['imgs', 'label'])\n",
    "# ]\n",
    "\n",
    "# cfg.val_pipeline = [\n",
    "#     dict(\n",
    "#         type='SampleFrames',\n",
    "#         clip_len=8,\n",
    "#         frame_interval=8,\n",
    "#         num_clips=1,\n",
    "#         test_mode=True),\n",
    "#     dict(type='RawFrameDecode'),\n",
    "#     dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='CenterCrop', crop_size=224),\n",
    "# #     dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "# #     dict(type='Flip', flip_ratio=0.5)\n",
    "#     dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "#     dict(type='FormatShape', input_format='NCTHW'),\n",
    "#     dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "#     dict(type='ToTensor', keys=['imgs'])\n",
    "# ]\n",
    "# cfg.test_pipeline = [\n",
    "#     dict(type='SampleFrames', clip_len=8, frame_interval=8, num_clips=10, test_mode=True),\n",
    "#     dict(type='RawFrameDecode'),\n",
    "#     dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='ThreeCrop', crop_size=256),\n",
    "#     dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "#     dict(type='FormatShape', input_format='NCTHW'),\n",
    "#     dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "#     dict(type='ToTensor', keys=['imgs'])\n",
    "# ]\n",
    "\n",
    "\n",
    "# cfg.data.train.pipeline = cfg.train_pipeline\n",
    "# cfg.data.val.pipeline = cfg.val_pipeline\n",
    "# cfg.data.test.pipeline = cfg.test_pipeline\n",
    "\n",
    "cfg.lr_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(10, 1e-5),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "cfg.total_epochs = 51\n",
    "\n",
    "cfg.momentum_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(0.85 / 0.95, 1),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 12\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# cfg.img_norm_cfg.mean = [0.485, 0.456, 0.406]\n",
    "# cfg.img_norm_cfg.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# cfg.train_pipeline[6] = dict(type='Normalize', mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], to_bgr=False)\n",
    "# cfg.test_pipeline[4] = dict(type='Normalize', mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], to_bgr=False)\n",
    "# cfg.val_pipeline[4] = dict(type='Normalize', mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], to_bgr=False)\n",
    "\n",
    "# cfg.model.backbone.in_channels = 2\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 13:10:24,061 - mmaction - INFO - load model from: torchvision://resnet50\n",
      "2021-04-01 13:10:24,254 - mmaction - INFO - These parameters in the 2d checkpoint are not loaded: {'fc.weight', 'fc.bias'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_torchvision loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 13:10:24,697 - mmaction - INFO - load checkpoint from checkpoints/tpn_imagenet_pretrained_slowonly_r50_8x8x1_150e_kinetics_rgb_20200923-52629684.pth\n",
      "2021-04-01 13:10:24,698 - mmaction - INFO - Use load_from_local loader\n",
      "2021-04-01 13:10:24,935 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([7, 2048]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([7]).\n",
      "2021-04-01 13:10:24,944 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /home/actrec/.virtualenvs/mmaction/mmaction2/childact-checkpoints/childact-TPN\n",
      "2021-04-01 13:10:24,945 - mmaction - INFO - workflow: [('train', 1)], max: 51 epochs\n",
      "2021-04-01 13:11:15,496 - mmaction - INFO - Epoch [1][100/132]\tlr: 1.030e-02, eta: 0:55:52, time: 0.505, data_time: 0.036, memory: 6932, loss_aux: 0.9700, top1_acc: 0.3900, top5_acc: 0.9263, loss_cls: 1.4808, loss: 2.4508, grad_norm: 11.2977\n",
      "2021-04-01 13:12:20,503 - mmaction - INFO - Epoch [2][100/132]\tlr: 1.163e-02, eta: 0:47:05, time: 0.503, data_time: 0.033, memory: 6932, loss_aux: 0.5689, top1_acc: 0.5600, top5_acc: 0.9700, loss_cls: 1.1336, loss: 1.7025, grad_norm: 7.9854\n",
      "2021-04-01 13:13:26,356 - mmaction - INFO - Epoch [3][100/132]\tlr: 1.398e-02, eta: 0:44:15, time: 0.510, data_time: 0.035, memory: 6932, loss_aux: 0.5700, top1_acc: 0.5675, top5_acc: 0.9738, loss_cls: 1.0740, loss: 1.6439, grad_norm: 6.0977\n",
      "2021-04-01 13:14:32,293 - mmaction - INFO - Epoch [4][100/132]\tlr: 1.730e-02, eta: 0:42:29, time: 0.510, data_time: 0.034, memory: 6932, loss_aux: 0.5400, top1_acc: 0.6300, top5_acc: 0.9800, loss_cls: 0.9901, loss: 1.5301, grad_norm: 5.4699\n",
      "2021-04-01 13:15:38,470 - mmaction - INFO - Epoch [5][100/132]\tlr: 2.152e-02, eta: 0:41:08, time: 0.512, data_time: 0.035, memory: 6932, loss_aux: 0.5026, top1_acc: 0.6400, top5_acc: 0.9838, loss_cls: 0.9246, loss: 1.4271, grad_norm: 5.4807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 34.1 task/s, elapsed: 4s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 13:15:57,546 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 13:15:57,548 - mmaction - INFO - \n",
      "top1_acc\t0.4921\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 13:15:57,548 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 13:15:57,551 - mmaction - INFO - \n",
      "mean_acc\t0.4921\n",
      "2021-04-01 13:15:58,907 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
      "2021-04-01 13:15:58,908 - mmaction - INFO - Best top1_acc is 0.4921 at 5 epoch.\n",
      "2021-04-01 13:15:58,909 - mmaction - INFO - Epoch(val) [5][132]\ttop1_acc: 0.4921, top5_acc: 1.0000, mean_class_accuracy: 0.4921\n",
      "2021-04-01 13:16:50,187 - mmaction - INFO - Epoch [6][100/132]\tlr: 2.653e-02, eta: 0:39:58, time: 0.513, data_time: 0.036, memory: 6932, loss_aux: 0.5872, top1_acc: 0.5363, top5_acc: 0.9688, loss_cls: 1.0932, loss: 1.6804, grad_norm: 5.0571\n",
      "2021-04-01 13:17:56,423 - mmaction - INFO - Epoch [7][100/132]\tlr: 3.221e-02, eta: 0:38:53, time: 0.512, data_time: 0.036, memory: 6932, loss_aux: 0.5759, top1_acc: 0.5913, top5_acc: 0.9712, loss_cls: 1.0677, loss: 1.6436, grad_norm: 5.1867\n",
      "2021-04-01 13:19:02,672 - mmaction - INFO - Epoch [8][100/132]\tlr: 3.844e-02, eta: 0:37:52, time: 0.512, data_time: 0.035, memory: 6932, loss_aux: 0.5901, top1_acc: 0.5763, top5_acc: 0.9750, loss_cls: 1.0847, loss: 1.6748, grad_norm: 4.8539\n",
      "2021-04-01 13:20:08,911 - mmaction - INFO - Epoch [9][100/132]\tlr: 4.505e-02, eta: 0:36:53, time: 0.512, data_time: 0.035, memory: 6932, loss_aux: 0.6032, top1_acc: 0.5550, top5_acc: 0.9738, loss_cls: 1.0906, loss: 1.6938, grad_norm: 4.4930\n",
      "2021-04-01 13:21:15,569 - mmaction - INFO - Epoch [10][100/132]\tlr: 5.190e-02, eta: 0:35:58, time: 0.517, data_time: 0.035, memory: 6932, loss_aux: 0.5807, top1_acc: 0.5737, top5_acc: 0.9762, loss_cls: 1.1612, loss: 1.7419, grad_norm: 4.3403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 34.1 task/s, elapsed: 4s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 13:21:34,364 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 13:21:34,366 - mmaction - INFO - \n",
      "top1_acc\t0.7143\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 13:21:34,367 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 13:21:34,368 - mmaction - INFO - \n",
      "mean_acc\t0.7143\n",
      "2021-04-01 13:21:35,791 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_10.pth.\n",
      "2021-04-01 13:21:35,792 - mmaction - INFO - Best top1_acc is 0.7143 at 10 epoch.\n",
      "2021-04-01 13:21:35,793 - mmaction - INFO - Epoch(val) [10][132]\ttop1_acc: 0.7143, top5_acc: 1.0000, mean_class_accuracy: 0.7143\n",
      "2021-04-01 13:22:26,947 - mmaction - INFO - Epoch [11][100/132]\tlr: 5.883e-02, eta: 0:35:01, time: 0.511, data_time: 0.035, memory: 6932, loss_aux: 0.5808, top1_acc: 0.5837, top5_acc: 0.9788, loss_cls: 1.0677, loss: 1.6485, grad_norm: 3.8896\n",
      "2021-04-01 13:23:33,066 - mmaction - INFO - Epoch [12][100/132]\tlr: 6.566e-02, eta: 0:34:05, time: 0.511, data_time: 0.034, memory: 6932, loss_aux: 0.6040, top1_acc: 0.5837, top5_acc: 0.9788, loss_cls: 1.0405, loss: 1.6445, grad_norm: 3.3994\n",
      "2021-04-01 13:23:48,083 - mmaction - INFO - Saving checkpoint at 12 epochs\n",
      "2021-04-01 13:24:40,712 - mmaction - INFO - Epoch [13][100/132]\tlr: 7.225e-02, eta: 0:33:10, time: 0.513, data_time: 0.036, memory: 6932, loss_aux: 0.7060, top1_acc: 0.5100, top5_acc: 0.9625, loss_cls: 1.2814, loss: 1.9874, grad_norm: 4.3004\n",
      "2021-04-01 13:25:46,635 - mmaction - INFO - Epoch [14][100/132]\tlr: 7.842e-02, eta: 0:32:15, time: 0.509, data_time: 0.033, memory: 6932, loss_aux: 0.5679, top1_acc: 0.5775, top5_acc: 0.9663, loss_cls: 1.0510, loss: 1.6189, grad_norm: 3.6083\n",
      "2021-04-01 13:26:52,844 - mmaction - INFO - Epoch [15][100/132]\tlr: 8.404e-02, eta: 0:31:21, time: 0.512, data_time: 0.036, memory: 6932, loss_aux: 0.6093, top1_acc: 0.5288, top5_acc: 0.9700, loss_cls: 1.1690, loss: 1.7783, grad_norm: 3.2915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 34.8 task/s, elapsed: 4s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 13:27:11,602 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 13:27:11,604 - mmaction - INFO - \n",
      "top1_acc\t0.6746\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 13:27:11,604 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 13:27:11,605 - mmaction - INFO - \n",
      "mean_acc\t0.6746\n",
      "2021-04-01 13:27:11,606 - mmaction - INFO - Epoch(val) [15][132]\ttop1_acc: 0.6746, top5_acc: 1.0000, mean_class_accuracy: 0.6746\n",
      "2021-04-01 13:28:02,760 - mmaction - INFO - Epoch [16][100/132]\tlr: 8.897e-02, eta: 0:30:28, time: 0.511, data_time: 0.035, memory: 6932, loss_aux: 0.4836, top1_acc: 0.6362, top5_acc: 0.9838, loss_cls: 0.9407, loss: 1.4243, grad_norm: 2.5749\n",
      "2021-04-01 13:29:09,623 - mmaction - INFO - Epoch [17][100/132]\tlr: 9.309e-02, eta: 0:29:36, time: 0.519, data_time: 0.036, memory: 6932, loss_aux: 0.5092, top1_acc: 0.6125, top5_acc: 0.9775, loss_cls: 0.9582, loss: 1.4674, grad_norm: 2.7311\n",
      "2021-04-01 13:30:15,746 - mmaction - INFO - Epoch [18][100/132]\tlr: 9.632e-02, eta: 0:28:42, time: 0.511, data_time: 0.034, memory: 6932, loss_aux: 0.5334, top1_acc: 0.6075, top5_acc: 0.9775, loss_cls: 1.0181, loss: 1.5516, grad_norm: 2.7827\n",
      "2021-04-01 13:31:22,034 - mmaction - INFO - Epoch [19][100/132]\tlr: 9.856e-02, eta: 0:27:50, time: 0.513, data_time: 0.035, memory: 6932, loss_aux: 0.4972, top1_acc: 0.6212, top5_acc: 0.9775, loss_cls: 0.9045, loss: 1.4017, grad_norm: 2.4616\n",
      "2021-04-01 13:32:28,267 - mmaction - INFO - Epoch [20][100/132]\tlr: 9.978e-02, eta: 0:26:57, time: 0.512, data_time: 0.035, memory: 6932, loss_aux: 0.5129, top1_acc: 0.6112, top5_acc: 0.9788, loss_cls: 0.9851, loss: 1.4981, grad_norm: 2.3371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 34.8 task/s, elapsed: 4s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 13:32:46,992 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 13:32:46,994 - mmaction - INFO - \n",
      "top1_acc\t0.6984\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 13:32:46,995 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 13:32:46,997 - mmaction - INFO - \n",
      "mean_acc\t0.6984\n",
      "2021-04-01 13:32:46,998 - mmaction - INFO - Epoch(val) [20][132]\ttop1_acc: 0.6984, top5_acc: 1.0000, mean_class_accuracy: 0.6984\n",
      "2021-04-01 13:33:38,013 - mmaction - INFO - Epoch [21][100/132]\tlr: 9.997e-02, eta: 0:26:04, time: 0.510, data_time: 0.035, memory: 6932, loss_aux: 0.4842, top1_acc: 0.6188, top5_acc: 0.9738, loss_cls: 0.9054, loss: 1.3895, grad_norm: 2.4147\n",
      "2021-04-01 13:34:44,022 - mmaction - INFO - Epoch [22][100/132]\tlr: 9.952e-02, eta: 0:25:11, time: 0.510, data_time: 0.033, memory: 6932, loss_aux: 0.4940, top1_acc: 0.6388, top5_acc: 0.9888, loss_cls: 0.9286, loss: 1.4226, grad_norm: 2.2113\n",
      "2021-04-01 13:35:50,216 - mmaction - INFO - Epoch [23][100/132]\tlr: 9.854e-02, eta: 0:24:19, time: 0.512, data_time: 0.035, memory: 6932, loss_aux: 0.4500, top1_acc: 0.6600, top5_acc: 0.9850, loss_cls: 0.8690, loss: 1.3191, grad_norm: 2.3312\n",
      "2021-04-01 13:36:56,298 - mmaction - INFO - Epoch [24][100/132]\tlr: 9.706e-02, eta: 0:23:27, time: 0.510, data_time: 0.034, memory: 6932, loss_aux: 0.4454, top1_acc: 0.6538, top5_acc: 0.9862, loss_cls: 0.9037, loss: 1.3491, grad_norm: 2.2047\n",
      "2021-04-01 13:37:11,262 - mmaction - INFO - Saving checkpoint at 24 epochs\n",
      "2021-04-01 13:38:03,835 - mmaction - INFO - Epoch [25][100/132]\tlr: 9.508e-02, eta: 0:22:34, time: 0.512, data_time: 0.036, memory: 6932, loss_aux: 0.4372, top1_acc: 0.6425, top5_acc: 0.9850, loss_cls: 0.8457, loss: 1.2829, grad_norm: 1.9658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 34.5 task/s, elapsed: 4s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 13:38:22,577 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 13:38:22,579 - mmaction - INFO - \n",
      "top1_acc\t0.7143\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 13:38:22,580 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 13:38:22,581 - mmaction - INFO - \n",
      "mean_acc\t0.7143\n",
      "2021-04-01 13:38:22,582 - mmaction - INFO - Epoch(val) [25][132]\ttop1_acc: 0.7143, top5_acc: 1.0000, mean_class_accuracy: 0.7143\n",
      "2021-04-01 13:39:13,816 - mmaction - INFO - Epoch [26][100/132]\tlr: 9.263e-02, eta: 0:21:42, time: 0.512, data_time: 0.035, memory: 6932, loss_aux: 0.4313, top1_acc: 0.6500, top5_acc: 0.9825, loss_cls: 0.8448, loss: 1.2761, grad_norm: 1.9801\n",
      "2021-04-01 13:40:19,864 - mmaction - INFO - Epoch [27][100/132]\tlr: 8.973e-02, eta: 0:20:50, time: 0.511, data_time: 0.035, memory: 6932, loss_aux: 0.4542, top1_acc: 0.6625, top5_acc: 0.9825, loss_cls: 0.8325, loss: 1.2867, grad_norm: 2.1505\n",
      "2021-04-01 13:41:25,985 - mmaction - INFO - Epoch [28][100/132]\tlr: 8.641e-02, eta: 0:19:58, time: 0.511, data_time: 0.036, memory: 6932, loss_aux: 0.4279, top1_acc: 0.6837, top5_acc: 0.9825, loss_cls: 0.8281, loss: 1.2560, grad_norm: 1.9832\n",
      "2021-04-01 13:42:31,928 - mmaction - INFO - Epoch [29][100/132]\tlr: 8.271e-02, eta: 0:19:06, time: 0.509, data_time: 0.033, memory: 6932, loss_aux: 0.4029, top1_acc: 0.6700, top5_acc: 0.9812, loss_cls: 0.8430, loss: 1.2459, grad_norm: 1.8762\n",
      "2021-04-01 13:43:38,244 - mmaction - INFO - Epoch [30][100/132]\tlr: 7.866e-02, eta: 0:18:14, time: 0.513, data_time: 0.037, memory: 6932, loss_aux: 0.3953, top1_acc: 0.6963, top5_acc: 0.9862, loss_cls: 0.7560, loss: 1.1513, grad_norm: 1.9064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 35.6 task/s, elapsed: 4s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 13:43:56,849 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 13:43:56,850 - mmaction - INFO - \n",
      "top1_acc\t0.8016\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 13:43:56,850 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 13:43:56,851 - mmaction - INFO - \n",
      "mean_acc\t0.8016\n",
      "2021-04-01 13:43:58,254 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_30.pth.\n",
      "2021-04-01 13:43:58,256 - mmaction - INFO - Best top1_acc is 0.8016 at 30 epoch.\n",
      "2021-04-01 13:43:58,256 - mmaction - INFO - Epoch(val) [30][132]\ttop1_acc: 0.8016, top5_acc: 1.0000, mean_class_accuracy: 0.8016\n",
      "2021-04-01 13:44:49,239 - mmaction - INFO - Epoch [31][100/132]\tlr: 7.431e-02, eta: 0:17:23, time: 0.510, data_time: 0.034, memory: 6932, loss_aux: 0.3823, top1_acc: 0.6913, top5_acc: 0.9838, loss_cls: 0.7632, loss: 1.1454, grad_norm: 1.7994\n",
      "2021-04-01 13:45:55,334 - mmaction - INFO - Epoch [32][100/132]\tlr: 6.971e-02, eta: 0:16:31, time: 0.511, data_time: 0.035, memory: 6932, loss_aux: 0.4089, top1_acc: 0.6763, top5_acc: 0.9862, loss_cls: 0.7888, loss: 1.1977, grad_norm: 1.9210\n",
      "2021-04-01 13:47:01,417 - mmaction - INFO - Epoch [33][100/132]\tlr: 6.490e-02, eta: 0:15:39, time: 0.511, data_time: 0.034, memory: 6932, loss_aux: 0.3762, top1_acc: 0.6863, top5_acc: 0.9850, loss_cls: 0.7451, loss: 1.1213, grad_norm: 1.8215\n",
      "2021-04-01 13:48:07,316 - mmaction - INFO - Epoch [34][100/132]\tlr: 5.993e-02, eta: 0:14:47, time: 0.509, data_time: 0.033, memory: 6932, loss_aux: 0.4059, top1_acc: 0.6687, top5_acc: 0.9888, loss_cls: 0.7540, loss: 1.1598, grad_norm: 1.7491\n",
      "2021-04-01 13:49:13,307 - mmaction - INFO - Epoch [35][100/132]\tlr: 5.485e-02, eta: 0:13:56, time: 0.510, data_time: 0.034, memory: 6932, loss_aux: 0.3899, top1_acc: 0.6987, top5_acc: 0.9925, loss_cls: 0.7383, loss: 1.1282, grad_norm: 1.6303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 35.4 task/s, elapsed: 4s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 13:49:31,954 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 13:49:31,955 - mmaction - INFO - \n",
      "top1_acc\t0.8095\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 13:49:31,955 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 13:49:31,956 - mmaction - INFO - \n",
      "mean_acc\t0.8095\n",
      "2021-04-01 13:49:33,348 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_35.pth.\n",
      "2021-04-01 13:49:33,349 - mmaction - INFO - Best top1_acc is 0.8095 at 35 epoch.\n",
      "2021-04-01 13:49:33,350 - mmaction - INFO - Epoch(val) [35][132]\ttop1_acc: 0.8095, top5_acc: 1.0000, mean_class_accuracy: 0.8095\n",
      "2021-04-01 13:50:24,248 - mmaction - INFO - Epoch [36][100/132]\tlr: 4.973e-02, eta: 0:13:04, time: 0.509, data_time: 0.033, memory: 6932, loss_aux: 0.3701, top1_acc: 0.7025, top5_acc: 0.9912, loss_cls: 0.7086, loss: 1.0787, grad_norm: 1.6993\n",
      "2021-04-01 13:50:39,217 - mmaction - INFO - Saving checkpoint at 36 epochs\n",
      "2021-04-01 13:51:31,783 - mmaction - INFO - Epoch [37][100/132]\tlr: 4.461e-02, eta: 0:12:12, time: 0.512, data_time: 0.036, memory: 6932, loss_aux: 0.3535, top1_acc: 0.7137, top5_acc: 0.9825, loss_cls: 0.6824, loss: 1.0358, grad_norm: 1.6134\n",
      "2021-04-01 13:52:37,654 - mmaction - INFO - Epoch [38][100/132]\tlr: 3.954e-02, eta: 0:11:21, time: 0.509, data_time: 0.033, memory: 6932, loss_aux: 0.3610, top1_acc: 0.7100, top5_acc: 0.9838, loss_cls: 0.6895, loss: 1.0505, grad_norm: 1.8162\n",
      "2021-04-01 13:53:43,530 - mmaction - INFO - Epoch [39][100/132]\tlr: 3.459e-02, eta: 0:10:29, time: 0.509, data_time: 0.033, memory: 6932, loss_aux: 0.3697, top1_acc: 0.7100, top5_acc: 0.9850, loss_cls: 0.7223, loss: 1.0920, grad_norm: 1.9473\n",
      "2021-04-01 13:54:49,725 - mmaction - INFO - Epoch [40][100/132]\tlr: 2.979e-02, eta: 0:09:38, time: 0.512, data_time: 0.036, memory: 6932, loss_aux: 0.3541, top1_acc: 0.7338, top5_acc: 0.9862, loss_cls: 0.7172, loss: 1.0713, grad_norm: 1.6992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 35.6 task/s, elapsed: 4s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 13:55:08,304 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 13:55:08,306 - mmaction - INFO - \n",
      "top1_acc\t0.9286\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 13:55:08,306 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 13:55:08,307 - mmaction - INFO - \n",
      "mean_acc\t0.9286\n",
      "2021-04-01 13:55:09,719 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_40.pth.\n",
      "2021-04-01 13:55:09,721 - mmaction - INFO - Best top1_acc is 0.9286 at 40 epoch.\n",
      "2021-04-01 13:55:09,721 - mmaction - INFO - Epoch(val) [40][132]\ttop1_acc: 0.9286, top5_acc: 1.0000, mean_class_accuracy: 0.9286\n",
      "2021-04-01 13:56:00,844 - mmaction - INFO - Epoch [41][100/132]\tlr: 2.521e-02, eta: 0:08:46, time: 0.511, data_time: 0.036, memory: 6932, loss_aux: 0.3629, top1_acc: 0.7125, top5_acc: 0.9862, loss_cls: 0.6888, loss: 1.0517, grad_norm: 1.6462\n",
      "2021-04-01 13:57:07,024 - mmaction - INFO - Epoch [42][100/132]\tlr: 2.089e-02, eta: 0:07:55, time: 0.512, data_time: 0.035, memory: 6932, loss_aux: 0.3482, top1_acc: 0.7087, top5_acc: 0.9900, loss_cls: 0.6757, loss: 1.0239, grad_norm: 1.7498\n",
      "2021-04-01 13:58:13,124 - mmaction - INFO - Epoch [43][100/132]\tlr: 1.688e-02, eta: 0:07:03, time: 0.511, data_time: 0.034, memory: 6932, loss_aux: 0.3004, top1_acc: 0.7725, top5_acc: 0.9900, loss_cls: 0.5871, loss: 0.8875, grad_norm: 1.5795\n",
      "2021-04-01 13:59:19,236 - mmaction - INFO - Epoch [44][100/132]\tlr: 1.322e-02, eta: 0:06:12, time: 0.511, data_time: 0.035, memory: 6932, loss_aux: 0.3147, top1_acc: 0.7600, top5_acc: 0.9912, loss_cls: 0.6192, loss: 0.9338, grad_norm: 1.6970\n",
      "2021-04-01 14:00:25,282 - mmaction - INFO - Epoch [45][100/132]\tlr: 9.941e-03, eta: 0:05:20, time: 0.511, data_time: 0.034, memory: 6932, loss_aux: 0.3164, top1_acc: 0.7550, top5_acc: 0.9900, loss_cls: 0.6041, loss: 0.9205, grad_norm: 1.7158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 35.2 task/s, elapsed: 4s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 14:00:43,993 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 14:00:43,994 - mmaction - INFO - \n",
      "top1_acc\t0.9286\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 14:00:43,995 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 14:00:43,995 - mmaction - INFO - \n",
      "mean_acc\t0.9286\n",
      "2021-04-01 14:00:43,996 - mmaction - INFO - Epoch(val) [45][132]\ttop1_acc: 0.9286, top5_acc: 1.0000, mean_class_accuracy: 0.9286\n",
      "2021-04-01 14:01:36,395 - mmaction - INFO - Epoch [46][100/132]\tlr: 7.086e-03, eta: 0:04:29, time: 0.524, data_time: 0.035, memory: 6932, loss_aux: 0.3309, top1_acc: 0.7375, top5_acc: 0.9912, loss_cls: 0.6328, loss: 0.9637, grad_norm: 1.6805\n",
      "2021-04-01 14:02:42,786 - mmaction - INFO - Epoch [47][100/132]\tlr: 4.683e-03, eta: 0:03:38, time: 0.513, data_time: 0.036, memory: 6932, loss_aux: 0.3222, top1_acc: 0.7388, top5_acc: 0.9888, loss_cls: 0.6298, loss: 0.9521, grad_norm: 1.7570\n",
      "2021-04-01 14:03:49,159 - mmaction - INFO - Epoch [48][100/132]\tlr: 2.757e-03, eta: 0:02:46, time: 0.513, data_time: 0.036, memory: 6932, loss_aux: 0.3098, top1_acc: 0.7550, top5_acc: 0.9912, loss_cls: 0.6117, loss: 0.9215, grad_norm: 1.7238\n",
      "2021-04-01 14:04:04,180 - mmaction - INFO - Saving checkpoint at 48 epochs\n",
      "2021-04-01 14:04:56,693 - mmaction - INFO - Epoch [49][100/132]\tlr: 1.328e-03, eta: 0:01:55, time: 0.512, data_time: 0.036, memory: 6932, loss_aux: 0.2934, top1_acc: 0.7650, top5_acc: 0.9912, loss_cls: 0.5640, loss: 0.8574, grad_norm: 1.6518\n",
      "2021-04-01 14:06:02,731 - mmaction - INFO - Epoch [50][100/132]\tlr: 4.111e-04, eta: 0:01:03, time: 0.510, data_time: 0.034, memory: 6932, loss_aux: 0.2846, top1_acc: 0.7863, top5_acc: 0.9938, loss_cls: 0.5379, loss: 0.8224, grad_norm: 1.6162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 34.8 task/s, elapsed: 4s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 14:06:21,442 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 14:06:21,443 - mmaction - INFO - \n",
      "top1_acc\t0.9206\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 14:06:21,443 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 14:06:21,444 - mmaction - INFO - \n",
      "mean_acc\t0.9206\n",
      "2021-04-01 14:06:21,444 - mmaction - INFO - Epoch(val) [50][132]\ttop1_acc: 0.9206, top5_acc: 1.0000, mean_class_accuracy: 0.9206\n",
      "2021-04-01 14:07:12,779 - mmaction - INFO - Epoch [51][100/132]\tlr: 1.656e-05, eta: 0:00:12, time: 0.513, data_time: 0.036, memory: 6932, loss_aux: 0.2967, top1_acc: 0.7625, top5_acc: 0.9938, loss_cls: 0.5881, loss: 0.8847, grad_norm: 1.7090\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model50e\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 0.2 task/s, elapsed: 667s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.9683\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.9683\n",
      "top1_acc: 0.9683\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.9683\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmaction.models import build_model\n",
    "from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=4,\n",
    "        workers_per_gpu=1,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'], yticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# R(2+1)D Flow 92.86%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64CW6d_AaT-Q",
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-29 22:00:52--  https://download.openmmlab.com/mmaction/recognition/r2plus1d/r2plus1d_r34_32x2x1_180e_kinetics400_rgb/r2plus1d_r34_32x2x1_180e_kinetics400_rgb_20200618-63462eb3.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.254.186.225\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.254.186.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 255319372 (243M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/r2plus1d_r34_32x2x1_180e_kinetics400_rgb_20200618-63462eb3.pth’\n",
      "\n",
      "checkpoints/r2plus1 100%[===================>] 243,49M  5,15MB/s    in 44s     \n",
      "\n",
      "2021-03-29 22:01:39 (5,58 MB/s) - ‘checkpoints/r2plus1d_r34_32x2x1_180e_kinetics400_rgb_20200618-63462eb3.pth’ saved [255319372/255319372]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/r2plus1d/r2plus1d_r34_32x2x1_180e_kinetics400_rgb/r2plus1d_r34_32x2x1_180e_kinetics400_rgb_20200618-63462eb3.pth \\\n",
    "      -O checkpoints/r2plus1d_r34_32x2x1_180e_kinetics400_rgb_20200618-63462eb3.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/r2plus1d/r2plus1d_r34_32x2x1_180e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='ResNet2Plus1d',\n",
      "        depth=34,\n",
      "        pretrained=None,\n",
      "        pretrained2d=False,\n",
      "        norm_eval=False,\n",
      "        conv_cfg=dict(type='Conv2plus1d'),\n",
      "        conv1_kernel=(3, 7, 7),\n",
      "        conv1_stride_t=1,\n",
      "        pool1_stride_t=1,\n",
      "        inflate=(1, 1, 1, 1),\n",
      "        spatial_strides=(1, 2, 2, 2),\n",
      "        temporal_strides=(1, 2, 2, 2),\n",
      "        zero_init_residual=False,\n",
      "        in_channels=2),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        num_classes=7,\n",
      "        in_channels=512,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "checkpoint_config = dict(interval=12)\n",
      "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/r2plus1d_r34_32x2x1_180e_kinetics400_rgb_20200618-63462eb3.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'RawframeDataset'\n",
      "data_root = 'data/childact_rawframe/train/'\n",
      "data_root_val = 'data/childact_rawframe/val/'\n",
      "ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
      "ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
      "ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
      "img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
      "train_pipeline = [\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=10,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='ThreeCrop', crop_size=256),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_train_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/train/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    val=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_val_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/val/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    test=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_test_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/test/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=10,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='ThreeCrop', crop_size=256),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "optimizer = dict(type='SGD', lr=0.075, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(10, 1e-05),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "total_epochs = 51\n",
      "work_dir = './childact-checkpoints/childact-R2+1D-flow'\n",
      "find_unused_parameters = False\n",
      "omnisource = False\n",
      "momentum_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(0.8947368421052632, 1),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(\n",
      "    out='./childact-checkpoints/childact-R2+1D-flow/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_rawframe/train/'\n",
    "cfg.data_root_val = 'data/childact_rawframe/val/'\n",
    "cfg.ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "\n",
    "# cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_rawframe/test/'\n",
    "\n",
    "# cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_rawframe/train/'\n",
    "\n",
    "# cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_rawframe/val/'\n",
    "\n",
    "cfg.data.test.modality = 'Flow'\n",
    "cfg.data.val.modality = 'Flow'\n",
    "cfg.data.train.modality = 'Flow'\n",
    "\n",
    "cfg.data.train.start_index = 0\n",
    "cfg.data.test.start_index = 0\n",
    "cfg.data.val.start_index = 0\n",
    "\n",
    "cfg.data.test.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.train.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.val.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = 'checkpoints/r2plus1d_r34_32x2x1_180e_kinetics400_rgb_20200618-63462eb3.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/childact-R2+1D-flow'\n",
    "\n",
    "cfg.img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
    "\n",
    "\n",
    "cfg.val_pipeline = [\n",
    "    dict(type='SampleFrames',clip_len=32, frame_interval=2, num_clips=1, test_mode=True),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "#     dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "#     dict(type='Flip', flip_ratio=0.5)\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=10, test_mode=True),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "    dict(type='ThreeCrop', crop_size=256),\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='RandomCrop', size=224),\n",
    "    dict(type='RandomResizedCrop'),\n",
    "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "#     dict(type='Flip', flip_ratio=0.5),\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
    "]\n",
    "\n",
    "test_pipeline = [\n",
    "    dict(\n",
    "        type='SampleFrames',\n",
    "        clip_len=32,\n",
    "        frame_interval=2,\n",
    "        num_clips=10,\n",
    "        test_mode=True),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "    dict(type='ThreeCrop', crop_size=256),\n",
    "    dict(type='Flip', flip_ratio=0),\n",
    "    dict(\n",
    "        type='Normalize',\n",
    "        mean=[123.675, 116.28, 103.53],\n",
    "        std=[58.395, 57.12, 57.375],\n",
    "        to_bgr=False),\n",
    "    dict(type='FormatShape', input_format='NCTHW'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.val.pipeline = cfg.val_pipeline\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "\n",
    "\n",
    "cfg.lr_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(10, 1e-5),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "cfg.total_epochs = 51\n",
    "\n",
    "cfg.momentum_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(0.85 / 0.95, 1),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 12\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.data.videos_per_gpu=8\n",
    "\n",
    "cfg.model.backbone.in_channels = 2\n",
    "\n",
    "del cfg.model.backbone['norm_cfg']\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 09:23:45,313 - mmaction - INFO - load checkpoint from checkpoints/r2plus1d_r34_32x2x1_180e_kinetics400_rgb_20200618-63462eb3.pth\n",
      "2021-03-31 09:23:45,314 - mmaction - INFO - Use load_from_local loader\n",
      "2021-03-31 09:23:45,882 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for backbone.conv1.conv.conv_s.weight: copying a param with shape torch.Size([83, 3, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 2, 1, 7, 7]).\n",
      "size mismatch for backbone.conv1.conv.bn_s.weight: copying a param with shape torch.Size([83]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.conv1.conv.bn_s.bias: copying a param with shape torch.Size([83]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.conv1.conv.bn_s.running_mean: copying a param with shape torch.Size([83]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.conv1.conv.bn_s.running_var: copying a param with shape torch.Size([83]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "size mismatch for backbone.conv1.conv.conv_t.weight: copying a param with shape torch.Size([64, 83, 3, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 1, 1]).\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 512]) from checkpoint, the shape in current model is torch.Size([7, 512]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([7]).\n",
      "2021-03-31 09:23:45,887 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /home/actrec/.virtualenvs/mmaction/mmaction2/childact-checkpoints/childact-R2+1D-flow\n",
      "2021-03-31 09:23:45,888 - mmaction - INFO - workflow: [('train', 1)], max: 51 epochs\n",
      "2021-03-31 09:25:55,825 - mmaction - INFO - Epoch [1][100/132]\tlr: 7.725e-02, eta: 2:23:37, time: 1.299, data_time: 0.032, memory: 21787, top1_acc: 0.1812, top5_acc: 0.7762, loss_cls: 2.0917, loss: 2.0917, grad_norm: 3.3519\n",
      "2021-03-31 09:28:48,344 - mmaction - INFO - Epoch [2][100/132]\tlr: 8.719e-02, eta: 2:02:22, time: 1.321, data_time: 0.031, memory: 21787, top1_acc: 0.2963, top5_acc: 0.8662, loss_cls: 1.7636, loss: 1.7636, grad_norm: 1.2050\n",
      "2021-03-31 09:31:41,319 - mmaction - INFO - Epoch [3][100/132]\tlr: 1.048e-01, eta: 1:55:00, time: 1.324, data_time: 0.029, memory: 21787, top1_acc: 0.3438, top5_acc: 0.9163, loss_cls: 1.6365, loss: 1.6365, grad_norm: 1.4674\n",
      "2021-03-31 09:34:34,538 - mmaction - INFO - Epoch [4][100/132]\tlr: 1.298e-01, eta: 1:50:24, time: 1.325, data_time: 0.029, memory: 21787, top1_acc: 0.4188, top5_acc: 0.9387, loss_cls: 1.4425, loss: 1.4425, grad_norm: 1.3342\n",
      "2021-03-31 09:37:28,101 - mmaction - INFO - Epoch [5][100/132]\tlr: 1.614e-01, eta: 1:46:52, time: 1.328, data_time: 0.032, memory: 21787, top1_acc: 0.3412, top5_acc: 0.9175, loss_cls: 1.6149, loss: 1.6149, grad_norm: 1.4457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 19.5 task/s, elapsed: 6s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 09:38:15,316 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 09:38:15,318 - mmaction - INFO - \n",
      "top1_acc\t0.5714\n",
      "top5_acc\t0.9762\n",
      "2021-03-31 09:38:15,319 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 09:38:15,321 - mmaction - INFO - \n",
      "mean_acc\t0.5714\n",
      "2021-03-31 09:38:16,193 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
      "2021-03-31 09:38:16,194 - mmaction - INFO - Best top1_acc is 0.5714 at 5 epoch.\n",
      "2021-03-31 09:38:16,195 - mmaction - INFO - Epoch(val) [5][132]\ttop1_acc: 0.5714, top5_acc: 0.9762, mean_class_accuracy: 0.5714\n",
      "2021-03-31 09:40:28,170 - mmaction - INFO - Epoch [6][100/132]\tlr: 1.990e-01, eta: 1:43:40, time: 1.320, data_time: 0.029, memory: 21787, top1_acc: 0.3650, top5_acc: 0.9375, loss_cls: 1.5938, loss: 1.5938, grad_norm: 1.1622\n",
      "2021-03-31 09:43:21,009 - mmaction - INFO - Epoch [7][100/132]\tlr: 2.416e-01, eta: 1:40:49, time: 1.323, data_time: 0.030, memory: 21787, top1_acc: 0.4462, top5_acc: 0.9563, loss_cls: 1.3807, loss: 1.3807, grad_norm: 1.0861\n",
      "2021-03-31 09:46:14,319 - mmaction - INFO - Epoch [8][100/132]\tlr: 2.883e-01, eta: 1:38:09, time: 1.327, data_time: 0.029, memory: 21787, top1_acc: 0.4175, top5_acc: 0.9475, loss_cls: 1.4766, loss: 1.4766, grad_norm: 1.2079\n",
      "2021-03-31 09:49:07,438 - mmaction - INFO - Epoch [9][100/132]\tlr: 3.379e-01, eta: 1:35:35, time: 1.325, data_time: 0.031, memory: 21787, top1_acc: 0.4188, top5_acc: 0.9363, loss_cls: 1.4436, loss: 1.4436, grad_norm: 1.0484\n",
      "2021-03-31 09:52:00,502 - mmaction - INFO - Epoch [10][100/132]\tlr: 3.893e-01, eta: 1:33:05, time: 1.324, data_time: 0.032, memory: 21787, top1_acc: 0.4412, top5_acc: 0.9325, loss_cls: 1.4712, loss: 1.4712, grad_norm: 1.0398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 19.1 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 09:52:47,838 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 09:52:47,839 - mmaction - INFO - \n",
      "top1_acc\t0.3889\n",
      "top5_acc\t0.9762\n",
      "2021-03-31 09:52:47,839 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 09:52:47,840 - mmaction - INFO - \n",
      "mean_acc\t0.3889\n",
      "2021-03-31 09:52:47,841 - mmaction - INFO - Epoch(val) [10][132]\ttop1_acc: 0.3889, top5_acc: 0.9762, mean_class_accuracy: 0.3889\n",
      "2021-03-31 09:55:00,419 - mmaction - INFO - Epoch [11][100/132]\tlr: 4.412e-01, eta: 1:30:39, time: 1.326, data_time: 0.032, memory: 21787, top1_acc: 0.4100, top5_acc: 0.9300, loss_cls: 1.5292, loss: 1.5292, grad_norm: 1.0860\n",
      "2021-03-31 09:57:53,570 - mmaction - INFO - Epoch [12][100/132]\tlr: 4.925e-01, eta: 1:28:15, time: 1.325, data_time: 0.030, memory: 21787, top1_acc: 0.3912, top5_acc: 0.9125, loss_cls: 1.6177, loss: 1.6177, grad_norm: 1.0584\n",
      "2021-03-31 09:58:34,518 - mmaction - INFO - Saving checkpoint at 12 epochs\n",
      "2021-03-31 10:00:49,321 - mmaction - INFO - Epoch [13][100/132]\tlr: 5.418e-01, eta: 1:25:57, time: 1.339, data_time: 0.031, memory: 21787, top1_acc: 0.3950, top5_acc: 0.9250, loss_cls: 1.6127, loss: 1.6127, grad_norm: 1.0346\n",
      "2021-03-31 10:03:41,869 - mmaction - INFO - Epoch [14][100/132]\tlr: 5.881e-01, eta: 1:23:34, time: 1.318, data_time: 0.029, memory: 21787, top1_acc: 0.3650, top5_acc: 0.9125, loss_cls: 1.6354, loss: 1.6354, grad_norm: 0.9911\n",
      "2021-03-31 10:06:35,151 - mmaction - INFO - Epoch [15][100/132]\tlr: 6.303e-01, eta: 1:21:14, time: 1.326, data_time: 0.032, memory: 21787, top1_acc: 0.3962, top5_acc: 0.9237, loss_cls: 1.5532, loss: 1.5532, grad_norm: 0.8606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 18.7 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 10:07:22,687 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 10:07:22,690 - mmaction - INFO - \n",
      "top1_acc\t0.3810\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 10:07:22,690 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 10:07:22,692 - mmaction - INFO - \n",
      "mean_acc\t0.3810\n",
      "2021-03-31 10:07:22,692 - mmaction - INFO - Epoch(val) [15][132]\ttop1_acc: 0.3810, top5_acc: 0.9921, mean_class_accuracy: 0.3810\n",
      "2021-03-31 10:09:35,099 - mmaction - INFO - Epoch [16][100/132]\tlr: 6.673e-01, eta: 1:18:55, time: 1.324, data_time: 0.031, memory: 21787, top1_acc: 0.4200, top5_acc: 0.9200, loss_cls: 1.4761, loss: 1.4761, grad_norm: 0.7987\n",
      "2021-03-31 10:12:28,037 - mmaction - INFO - Epoch [17][100/132]\tlr: 6.982e-01, eta: 1:16:36, time: 1.323, data_time: 0.030, memory: 21787, top1_acc: 0.3962, top5_acc: 0.9275, loss_cls: 1.5405, loss: 1.5405, grad_norm: 0.8146\n",
      "2021-03-31 10:15:20,955 - mmaction - INFO - Epoch [18][100/132]\tlr: 7.224e-01, eta: 1:14:18, time: 1.323, data_time: 0.030, memory: 21787, top1_acc: 0.4338, top5_acc: 0.9300, loss_cls: 1.5227, loss: 1.5227, grad_norm: 0.8175\n",
      "2021-03-31 10:18:13,741 - mmaction - INFO - Epoch [19][100/132]\tlr: 7.392e-01, eta: 1:12:01, time: 1.322, data_time: 0.029, memory: 21787, top1_acc: 0.4200, top5_acc: 0.9300, loss_cls: 1.5359, loss: 1.5359, grad_norm: 0.8446\n",
      "2021-03-31 10:21:06,525 - mmaction - INFO - Epoch [20][100/132]\tlr: 7.483e-01, eta: 1:09:44, time: 1.322, data_time: 0.030, memory: 21787, top1_acc: 0.3713, top5_acc: 0.9225, loss_cls: 1.5914, loss: 1.5914, grad_norm: 0.8252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 19.0 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 10:21:53,861 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 10:21:53,863 - mmaction - INFO - \n",
      "top1_acc\t0.5397\n",
      "top5_acc\t0.9603\n",
      "2021-03-31 10:21:53,864 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 10:21:53,866 - mmaction - INFO - \n",
      "mean_acc\t0.5397\n",
      "2021-03-31 10:21:53,867 - mmaction - INFO - Epoch(val) [20][132]\ttop1_acc: 0.5397, top5_acc: 0.9603, mean_class_accuracy: 0.5397\n",
      "2021-03-31 10:24:06,925 - mmaction - INFO - Epoch [21][100/132]\tlr: 7.497e-01, eta: 1:07:29, time: 1.331, data_time: 0.030, memory: 21787, top1_acc: 0.4113, top5_acc: 0.9325, loss_cls: 1.5000, loss: 1.5000, grad_norm: 0.7922\n",
      "2021-03-31 10:27:00,101 - mmaction - INFO - Epoch [22][100/132]\tlr: 7.464e-01, eta: 1:05:13, time: 1.324, data_time: 0.029, memory: 21787, top1_acc: 0.3438, top5_acc: 0.8950, loss_cls: 1.6101, loss: 1.6101, grad_norm: 0.7219\n",
      "2021-03-31 10:29:53,382 - mmaction - INFO - Epoch [23][100/132]\tlr: 7.391e-01, eta: 1:02:58, time: 1.326, data_time: 0.030, memory: 21787, top1_acc: 0.3613, top5_acc: 0.9263, loss_cls: 1.5638, loss: 1.5638, grad_norm: 0.7427\n",
      "2021-03-31 10:32:46,308 - mmaction - INFO - Epoch [24][100/132]\tlr: 7.280e-01, eta: 1:00:42, time: 1.323, data_time: 0.029, memory: 21787, top1_acc: 0.4025, top5_acc: 0.9213, loss_cls: 1.5435, loss: 1.5435, grad_norm: 0.7993\n",
      "2021-03-31 10:33:26,996 - mmaction - INFO - Saving checkpoint at 24 epochs\n",
      "2021-03-31 10:35:40,808 - mmaction - INFO - Epoch [25][100/132]\tlr: 7.131e-01, eta: 0:58:28, time: 1.329, data_time: 0.030, memory: 21787, top1_acc: 0.3450, top5_acc: 0.9150, loss_cls: 1.6990, loss: 1.6990, grad_norm: 0.8714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 18.9 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 10:36:28,322 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 10:36:28,324 - mmaction - INFO - \n",
      "top1_acc\t0.2778\n",
      "top5_acc\t0.9841\n",
      "2021-03-31 10:36:28,324 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 10:36:28,326 - mmaction - INFO - \n",
      "mean_acc\t0.2778\n",
      "2021-03-31 10:36:28,326 - mmaction - INFO - Epoch(val) [25][132]\ttop1_acc: 0.2778, top5_acc: 0.9841, mean_class_accuracy: 0.2778\n",
      "2021-03-31 10:38:40,852 - mmaction - INFO - Epoch [26][100/132]\tlr: 6.947e-01, eta: 0:56:13, time: 1.325, data_time: 0.029, memory: 21787, top1_acc: 0.4338, top5_acc: 0.9250, loss_cls: 1.5131, loss: 1.5131, grad_norm: 0.7067\n",
      "2021-03-31 10:41:34,185 - mmaction - INFO - Epoch [27][100/132]\tlr: 6.730e-01, eta: 0:53:58, time: 1.326, data_time: 0.031, memory: 21787, top1_acc: 0.3688, top5_acc: 0.9137, loss_cls: 1.5175, loss: 1.5175, grad_norm: 0.7141\n",
      "2021-03-31 10:44:27,300 - mmaction - INFO - Epoch [28][100/132]\tlr: 6.481e-01, eta: 0:51:44, time: 1.323, data_time: 0.029, memory: 21787, top1_acc: 0.4363, top5_acc: 0.9300, loss_cls: 1.4977, loss: 1.4977, grad_norm: 0.7367\n",
      "2021-03-31 10:47:20,470 - mmaction - INFO - Epoch [29][100/132]\tlr: 6.203e-01, eta: 0:49:29, time: 1.325, data_time: 0.032, memory: 21787, top1_acc: 0.4250, top5_acc: 0.9400, loss_cls: 1.4125, loss: 1.4125, grad_norm: 0.6804\n",
      "2021-03-31 10:50:13,639 - mmaction - INFO - Epoch [30][100/132]\tlr: 5.900e-01, eta: 0:47:15, time: 1.326, data_time: 0.030, memory: 21787, top1_acc: 0.4763, top5_acc: 0.9200, loss_cls: 1.3615, loss: 1.3615, grad_norm: 0.6618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 18.9 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 10:51:00,968 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 10:51:00,970 - mmaction - INFO - \n",
      "top1_acc\t0.5159\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 10:51:00,971 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 10:51:00,973 - mmaction - INFO - \n",
      "mean_acc\t0.5159\n",
      "2021-03-31 10:51:00,973 - mmaction - INFO - Epoch(val) [30][132]\ttop1_acc: 0.5159, top5_acc: 0.9921, mean_class_accuracy: 0.5159\n",
      "2021-03-31 10:53:13,569 - mmaction - INFO - Epoch [31][100/132]\tlr: 5.573e-01, eta: 0:45:01, time: 1.326, data_time: 0.032, memory: 21787, top1_acc: 0.4288, top5_acc: 0.9287, loss_cls: 1.4670, loss: 1.4670, grad_norm: 0.7006\n",
      "2021-03-31 10:56:06,702 - mmaction - INFO - Epoch [32][100/132]\tlr: 5.228e-01, eta: 0:42:47, time: 1.325, data_time: 0.029, memory: 21787, top1_acc: 0.4750, top5_acc: 0.9387, loss_cls: 1.2957, loss: 1.2957, grad_norm: 0.7049\n",
      "2021-03-31 10:59:01,048 - mmaction - INFO - Epoch [33][100/132]\tlr: 4.867e-01, eta: 0:40:34, time: 1.337, data_time: 0.029, memory: 21787, top1_acc: 0.4700, top5_acc: 0.9437, loss_cls: 1.3124, loss: 1.3124, grad_norm: 0.6862\n",
      "2021-03-31 11:01:53,843 - mmaction - INFO - Epoch [34][100/132]\tlr: 4.494e-01, eta: 0:38:20, time: 1.321, data_time: 0.030, memory: 21787, top1_acc: 0.4675, top5_acc: 0.9463, loss_cls: 1.3420, loss: 1.3420, grad_norm: 0.7411\n",
      "2021-03-31 11:04:46,504 - mmaction - INFO - Epoch [35][100/132]\tlr: 4.114e-01, eta: 0:36:06, time: 1.320, data_time: 0.029, memory: 21787, top1_acc: 0.4637, top5_acc: 0.9313, loss_cls: 1.2972, loss: 1.2972, grad_norm: 0.6711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 18.8 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 11:05:33,816 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 11:05:33,818 - mmaction - INFO - \n",
      "top1_acc\t0.4841\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 11:05:33,819 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 11:05:33,822 - mmaction - INFO - \n",
      "mean_acc\t0.4841\n",
      "2021-03-31 11:05:33,823 - mmaction - INFO - Epoch(val) [35][132]\ttop1_acc: 0.4841, top5_acc: 0.9921, mean_class_accuracy: 0.4841\n",
      "2021-03-31 11:07:45,972 - mmaction - INFO - Epoch [36][100/132]\tlr: 3.730e-01, eta: 0:33:52, time: 1.321, data_time: 0.029, memory: 21787, top1_acc: 0.4612, top5_acc: 0.9437, loss_cls: 1.3194, loss: 1.3194, grad_norm: 0.6193\n",
      "2021-03-31 11:08:26,439 - mmaction - INFO - Saving checkpoint at 36 epochs\n",
      "2021-03-31 11:10:39,603 - mmaction - INFO - Epoch [37][100/132]\tlr: 3.345e-01, eta: 0:31:38, time: 1.323, data_time: 0.030, memory: 21787, top1_acc: 0.5262, top5_acc: 0.9300, loss_cls: 1.1870, loss: 1.1870, grad_norm: 0.6579\n",
      "2021-03-31 11:13:32,371 - mmaction - INFO - Epoch [38][100/132]\tlr: 2.966e-01, eta: 0:29:24, time: 1.322, data_time: 0.029, memory: 21787, top1_acc: 0.4925, top5_acc: 0.9425, loss_cls: 1.2298, loss: 1.2298, grad_norm: 0.6724\n",
      "2021-03-31 11:16:25,139 - mmaction - INFO - Epoch [39][100/132]\tlr: 2.594e-01, eta: 0:27:11, time: 1.323, data_time: 0.031, memory: 21787, top1_acc: 0.5500, top5_acc: 0.9475, loss_cls: 1.1322, loss: 1.1322, grad_norm: 0.6506\n",
      "2021-03-31 11:19:17,854 - mmaction - INFO - Epoch [40][100/132]\tlr: 2.235e-01, eta: 0:24:57, time: 1.321, data_time: 0.029, memory: 21787, top1_acc: 0.5288, top5_acc: 0.9400, loss_cls: 1.1419, loss: 1.1419, grad_norm: 0.5795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 19.0 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 11:20:05,134 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 11:20:05,136 - mmaction - INFO - \n",
      "top1_acc\t0.7540\n",
      "top5_acc\t1.0000\n",
      "2021-03-31 11:20:05,136 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 11:20:05,138 - mmaction - INFO - \n",
      "mean_acc\t0.7540\n",
      "2021-03-31 11:20:06,021 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_40.pth.\n",
      "2021-03-31 11:20:06,022 - mmaction - INFO - Best top1_acc is 0.7540 at 40 epoch.\n",
      "2021-03-31 11:20:06,023 - mmaction - INFO - Epoch(val) [40][132]\ttop1_acc: 0.7540, top5_acc: 1.0000, mean_class_accuracy: 0.7540\n",
      "2021-03-31 11:22:18,278 - mmaction - INFO - Epoch [41][100/132]\tlr: 1.891e-01, eta: 0:22:44, time: 1.323, data_time: 0.031, memory: 21787, top1_acc: 0.5750, top5_acc: 0.9575, loss_cls: 1.0494, loss: 1.0494, grad_norm: 0.6308\n",
      "2021-03-31 11:25:10,980 - mmaction - INFO - Epoch [42][100/132]\tlr: 1.567e-01, eta: 0:20:30, time: 1.321, data_time: 0.031, memory: 21787, top1_acc: 0.5575, top5_acc: 0.9450, loss_cls: 1.1075, loss: 1.1075, grad_norm: 0.6302\n",
      "2021-03-31 11:28:04,924 - mmaction - INFO - Epoch [43][100/132]\tlr: 1.266e-01, eta: 0:18:17, time: 1.335, data_time: 0.030, memory: 21787, top1_acc: 0.5525, top5_acc: 0.9525, loss_cls: 1.0490, loss: 1.0490, grad_norm: 0.6283\n",
      "2021-03-31 11:30:59,318 - mmaction - INFO - Epoch [44][100/132]\tlr: 9.914e-02, eta: 0:16:04, time: 1.337, data_time: 0.029, memory: 21787, top1_acc: 0.5675, top5_acc: 0.9475, loss_cls: 1.1013, loss: 1.1013, grad_norm: 0.6120\n",
      "2021-03-31 11:33:52,035 - mmaction - INFO - Epoch [45][100/132]\tlr: 7.456e-02, eta: 0:13:51, time: 1.321, data_time: 0.029, memory: 21787, top1_acc: 0.5775, top5_acc: 0.9463, loss_cls: 1.0215, loss: 1.0215, grad_norm: 0.6075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 19.1 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 11:34:39,377 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 11:34:39,378 - mmaction - INFO - \n",
      "top1_acc\t0.7381\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 11:34:39,379 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 11:34:39,379 - mmaction - INFO - \n",
      "mean_acc\t0.7381\n",
      "2021-03-31 11:34:39,380 - mmaction - INFO - Epoch(val) [45][132]\ttop1_acc: 0.7381, top5_acc: 0.9921, mean_class_accuracy: 0.7381\n",
      "2021-03-31 11:36:51,694 - mmaction - INFO - Epoch [46][100/132]\tlr: 5.315e-02, eta: 0:11:37, time: 1.323, data_time: 0.032, memory: 21787, top1_acc: 0.5800, top5_acc: 0.9725, loss_cls: 1.0079, loss: 1.0079, grad_norm: 0.6084\n",
      "2021-03-31 11:39:44,512 - mmaction - INFO - Epoch [47][100/132]\tlr: 3.512e-02, eta: 0:09:24, time: 1.322, data_time: 0.031, memory: 21787, top1_acc: 0.6138, top5_acc: 0.9537, loss_cls: 0.9614, loss: 0.9614, grad_norm: 0.5681\n",
      "2021-03-31 11:42:37,390 - mmaction - INFO - Epoch [48][100/132]\tlr: 2.067e-02, eta: 0:07:11, time: 1.323, data_time: 0.032, memory: 21787, top1_acc: 0.6288, top5_acc: 0.9637, loss_cls: 0.9107, loss: 0.9107, grad_norm: 0.5420\n",
      "2021-03-31 11:43:18,059 - mmaction - INFO - Saving checkpoint at 48 epochs\n",
      "2021-03-31 11:45:31,542 - mmaction - INFO - Epoch [49][100/132]\tlr: 9.958e-03, eta: 0:04:58, time: 1.326, data_time: 0.032, memory: 21787, top1_acc: 0.6100, top5_acc: 0.9675, loss_cls: 0.9684, loss: 0.9684, grad_norm: 0.6005\n",
      "2021-03-31 11:48:24,364 - mmaction - INFO - Epoch [50][100/132]\tlr: 3.083e-03, eta: 0:02:45, time: 1.322, data_time: 0.030, memory: 21787, top1_acc: 0.6200, top5_acc: 0.9625, loss_cls: 0.9503, loss: 0.9503, grad_norm: 0.6035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 19.5 task/s, elapsed: 6s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-31 11:49:11,545 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-31 11:49:11,547 - mmaction - INFO - \n",
      "top1_acc\t0.8016\n",
      "top5_acc\t0.9921\n",
      "2021-03-31 11:49:11,548 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-31 11:49:11,550 - mmaction - INFO - \n",
      "mean_acc\t0.8016\n",
      "2021-03-31 11:49:12,507 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_50.pth.\n",
      "2021-03-31 11:49:12,508 - mmaction - INFO - Best top1_acc is 0.8016 at 50 epoch.\n",
      "2021-03-31 11:49:12,508 - mmaction - INFO - Epoch(val) [50][132]\ttop1_acc: 0.8016, top5_acc: 0.9921, mean_class_accuracy: 0.8016\n",
      "2021-03-31 11:51:24,614 - mmaction - INFO - Epoch [51][100/132]\tlr: 1.242e-04, eta: 0:00:32, time: 1.321, data_time: 0.030, memory: 21787, top1_acc: 0.5988, top5_acc: 0.9537, loss_cls: 0.9938, loss: 0.9938, grad_norm: 0.6841\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model50e\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "model = pickle.load(open(f\"{cfg.work_dir}/model50e\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 0.6 task/s, elapsed: 210s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.9286\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.9286\n",
      "top1_acc: 0.9286\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.9286\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmaction.models import build_model\n",
    "from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=1,\n",
    "        workers_per_gpu=1,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'], yticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# TIN 87.30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64CW6d_AaT-Q",
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-29 22:59:27--  https://download.openmmlab.com/mmaction/recognition/tin/tin_tsm_finetune_r50_1x1x8_50e_kinetics400_rgb/tin_tsm_finetune_r50_1x1x8_50e_kinetics400_rgb_20200810-4a146a70.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.75.20.25\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.75.20.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 97729017 (93M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/tin_tsm_finetune_r50_1x1x8_50e_kinetics400_rgb_20200810-4a146a70.pth’\n",
      "\n",
      "checkpoints/tin_tsm 100%[===================>]  93,20M  8,39MB/s    in 13s     \n",
      "\n",
      "2021-03-29 22:59:44 (7,23 MB/s) - ‘checkpoints/tin_tsm_finetune_r50_1x1x8_50e_kinetics400_rgb_20200810-4a146a70.pth’ saved [97729017/97729017]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/tin/tin_tsm_finetune_r50_1x1x8_50e_kinetics400_rgb/tin_tsm_finetune_r50_1x1x8_50e_kinetics400_rgb_20200810-4a146a70.pth \\\n",
    "      -O checkpoints/tin_tsm_finetune_r50_1x1x8_50e_kinetics400_rgb_20200810-4a146a70.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/tin/tin_tsm_finetune_r50_1x1x8_50e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer2D',\n",
      "    backbone=dict(\n",
      "        type='ResNetTIN',\n",
      "        pretrained='torchvision://resnet50',\n",
      "        depth=50,\n",
      "        norm_eval=False,\n",
      "        shift_div=4,\n",
      "        in_channels=2),\n",
      "    cls_head=dict(\n",
      "        type='TSMHead',\n",
      "        num_classes=7,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        consensus=dict(type='AvgConsensus', dim=1),\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.001,\n",
      "        is_shift=True),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips=None))\n",
      "optimizer = dict(\n",
      "    type='SGD',\n",
      "    lr=0.01,\n",
      "    momentum=0.9,\n",
      "    weight_decay=0.0001,\n",
      "    constructor='TSMOptimizerConstructor',\n",
      "    paramwise_cfg=dict(fc_lr5=True))\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=20, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(10, 1e-05),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "total_epochs = 51\n",
      "checkpoint_config = dict(interval=12)\n",
      "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/tin_tsm_finetune_r50_1x1x8_50e_kinetics400_rgb_20200810-4a146a70.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'RawframeDataset'\n",
      "data_root = 'data/childact_rawframe/train/'\n",
      "data_root_val = 'data/childact_rawframe/val/'\n",
      "ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
      "ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
      "ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
      "img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
      "train_pipeline = [\n",
      "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=8),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(\n",
      "        type='MultiScaleCrop',\n",
      "        input_size=224,\n",
      "        scales=(1, 0.875, 0.75, 0.66),\n",
      "        random_crop=False,\n",
      "        max_wh_scale_gap=1),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCHW_Flow'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=8,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCHW_Flow'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=8,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "    dict(type='FormatShape', input_format='NCHW_Flow'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=6,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_train_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/train/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames', clip_len=1, frame_interval=1,\n",
      "                num_clips=8),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(\n",
      "                type='MultiScaleCrop',\n",
      "                input_size=224,\n",
      "                scales=(1, 0.875, 0.75, 0.66),\n",
      "                random_crop=False,\n",
      "                max_wh_scale_gap=1),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCHW_Flow'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    val=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_val_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/val/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=8,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCHW_Flow'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'),\n",
      "    test=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rawframe/childact_test_rawframe.txt',\n",
      "        data_prefix='data/childact_rawframe/test/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=8,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
      "            dict(type='FormatShape', input_format='NCHW_Flow'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        modality='Flow',\n",
      "        start_index=0,\n",
      "        filename_tmpl='flow_{}_{:05d}.jpg'))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "work_dir = './childact-checkpoints/childact-TIN'\n",
      "omnisource = False\n",
      "momentum_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(0.8947368421052632, 1),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/childact-TIN/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_rawframe/train/'\n",
    "cfg.data_root_val = 'data/childact_rawframe/val/'\n",
    "cfg.ann_file_train = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.ann_file_val = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.ann_file_test = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "\n",
    "# cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_rawframe/childact_test_rawframe.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_rawframe/test/'\n",
    "\n",
    "# cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_rawframe/childact_train_rawframe.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_rawframe/train/'\n",
    "\n",
    "# cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_rawframe/childact_val_rawframe.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_rawframe/val/'\n",
    "\n",
    "cfg.data.test.modality = 'Flow'\n",
    "cfg.data.val.modality = 'Flow'\n",
    "cfg.data.train.modality = 'Flow'\n",
    "\n",
    "cfg.data.train.start_index = 0\n",
    "cfg.data.test.start_index = 0\n",
    "cfg.data.val.start_index = 0\n",
    "\n",
    "cfg.data.test.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.train.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "cfg.data.val.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = 'checkpoints/tin_tsm_finetune_r50_1x1x8_50e_kinetics400_rgb_20200810-4a146a70.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/childact-TIN'\n",
    "\n",
    "cfg.img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
    "\n",
    "\n",
    "cfg.val_pipeline = [\n",
    "    dict(\n",
    "        type='SampleFrames',\n",
    "        clip_len=1,\n",
    "        frame_interval=1,\n",
    "        num_clips=8,\n",
    "        test_mode=True),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCHW_Flow'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "cfg.test_pipeline = [\n",
    "    dict(\n",
    "        type='SampleFrames',\n",
    "        clip_len=1,\n",
    "        frame_interval=1,\n",
    "        num_clips=8,\n",
    "        test_mode=True),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "     dict(type='CenterCrop', crop_size=224),\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCHW_Flow'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs'])\n",
    "]\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=8),\n",
    "    dict(type='RawFrameDecode'),\n",
    "    dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='RandomCrop', size=224),\n",
    "    dict(\n",
    "        type='MultiScaleCrop',\n",
    "        input_size=224,\n",
    "        scales=(1, 0.875, 0.75, 0.66),\n",
    "        random_crop=False,\n",
    "        max_wh_scale_gap=1),\n",
    "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "    dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "    dict(type='FormatShape', input_format='NCHW_Flow'),\n",
    "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
    "]\n",
    "\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.val.pipeline = cfg.val_pipeline\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "\n",
    "cfg.lr_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(10, 1e-5),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "cfg.total_epochs = 51\n",
    "\n",
    "cfg.momentum_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(0.85 / 0.95, 1),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 12\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.model.backbone.in_channels = 2\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 23:41:40,330 - mmaction - INFO - These parameters in pretrained checkpoint are not loaded: {'fc.weight', 'fc.bias', 'conv1.weight'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_torchvision loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 23:41:40,412 - mmaction - INFO - load checkpoint from checkpoints/tin_tsm_finetune_r50_1x1x8_50e_kinetics400_rgb_20200810-4a146a70.pth\n",
      "2021-03-29 23:41:40,414 - mmaction - INFO - Use load_from_local loader\n",
      "2021-03-29 23:41:40,506 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for backbone.conv1.conv.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 2, 7, 7]).\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([7, 2048]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([7]).\n",
      "2021-03-29 23:41:40,508 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /home/actrec/.virtualenvs/mmaction/mmaction2/childact-checkpoints/childact-TIN\n",
      "2021-03-29 23:41:40,508 - mmaction - INFO - workflow: [('train', 1)], max: 51 epochs\n",
      "2021-03-29 23:42:10,740 - mmaction - INFO - Epoch [1][100/175]\tlr: 1.017e-02, eta: 0:44:27, time: 0.302, data_time: 0.024, memory: 6231, top1_acc: 0.2850, top5_acc: 0.8383, loss_cls: 1.9803, loss: 1.9803, grad_norm: 9.7177\n",
      "2021-03-29 23:43:02,041 - mmaction - INFO - Epoch [2][100/175]\tlr: 1.130e-02, eta: 0:31:40, time: 0.302, data_time: 0.024, memory: 6231, top1_acc: 0.4033, top5_acc: 0.9633, loss_cls: 1.4432, loss: 1.4432, grad_norm: 4.2550\n",
      "2021-03-29 23:43:53,604 - mmaction - INFO - Epoch [3][100/175]\tlr: 1.347e-02, eta: 0:28:32, time: 0.305, data_time: 0.024, memory: 6231, top1_acc: 0.5883, top5_acc: 0.9867, loss_cls: 1.0339, loss: 1.0339, grad_norm: 4.0383\n",
      "2021-03-29 23:44:45,105 - mmaction - INFO - Epoch [4][100/175]\tlr: 1.662e-02, eta: 0:26:51, time: 0.304, data_time: 0.024, memory: 6231, top1_acc: 0.6117, top5_acc: 0.9867, loss_cls: 0.9789, loss: 0.9789, grad_norm: 4.1729\n",
      "2021-03-29 23:45:36,793 - mmaction - INFO - Epoch [5][100/175]\tlr: 2.067e-02, eta: 0:25:42, time: 0.305, data_time: 0.024, memory: 6231, top1_acc: 0.6050, top5_acc: 0.9767, loss_cls: 0.9966, loss: 0.9966, grad_norm: 3.0995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 60.5 task/s, elapsed: 2s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 23:46:00,366 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 23:46:00,368 - mmaction - INFO - \n",
      "top1_acc\t0.6984\n",
      "top5_acc\t0.9921\n",
      "2021-03-29 23:46:00,369 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 23:46:00,370 - mmaction - INFO - \n",
      "mean_acc\t0.6984\n",
      "2021-03-29 23:46:00,647 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
      "2021-03-29 23:46:00,648 - mmaction - INFO - Best top1_acc is 0.6984 at 5 epoch.\n",
      "2021-03-29 23:46:00,649 - mmaction - INFO - Epoch(val) [5][175]\ttop1_acc: 0.6984, top5_acc: 0.9921, mean_class_accuracy: 0.6984\n",
      "2021-03-29 23:46:31,401 - mmaction - INFO - Epoch [6][100/175]\tlr: 2.554e-02, eta: 0:24:49, time: 0.307, data_time: 0.024, memory: 6231, top1_acc: 0.6183, top5_acc: 0.9883, loss_cls: 1.0457, loss: 1.0457, grad_norm: 3.3395\n",
      "2021-03-29 23:47:23,205 - mmaction - INFO - Epoch [7][100/175]\tlr: 3.111e-02, eta: 0:24:01, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.5883, top5_acc: 0.9767, loss_cls: 1.1039, loss: 1.1039, grad_norm: 3.3533\n",
      "2021-03-29 23:48:15,068 - mmaction - INFO - Epoch [8][100/175]\tlr: 3.724e-02, eta: 0:23:18, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.6400, top5_acc: 0.9867, loss_cls: 0.9483, loss: 0.9483, grad_norm: 2.3404\n",
      "2021-03-29 23:49:06,991 - mmaction - INFO - Epoch [9][100/175]\tlr: 4.379e-02, eta: 0:22:38, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.6317, top5_acc: 0.9867, loss_cls: 0.9587, loss: 0.9587, grad_norm: 2.4777\n",
      "2021-03-29 23:49:58,736 - mmaction - INFO - Epoch [10][100/175]\tlr: 5.061e-02, eta: 0:22:00, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.6717, top5_acc: 0.9850, loss_cls: 0.8731, loss: 0.8731, grad_norm: 2.2906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 62.1 task/s, elapsed: 2s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 23:50:22,056 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 23:50:22,058 - mmaction - INFO - \n",
      "top1_acc\t0.7143\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 23:50:22,059 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 23:50:22,061 - mmaction - INFO - \n",
      "mean_acc\t0.7143\n",
      "2021-03-29 23:50:22,344 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_10.pth.\n",
      "2021-03-29 23:50:22,345 - mmaction - INFO - Best top1_acc is 0.7143 at 10 epoch.\n",
      "2021-03-29 23:50:22,346 - mmaction - INFO - Epoch(val) [10][175]\ttop1_acc: 0.7143, top5_acc: 1.0000, mean_class_accuracy: 0.7143\n",
      "2021-03-29 23:50:52,920 - mmaction - INFO - Epoch [11][100/175]\tlr: 5.753e-02, eta: 0:21:23, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.6600, top5_acc: 0.9900, loss_cls: 0.9106, loss: 0.9106, grad_norm: 2.1179\n",
      "2021-03-29 23:51:44,676 - mmaction - INFO - Epoch [12][100/175]\tlr: 6.439e-02, eta: 0:20:47, time: 0.305, data_time: 0.024, memory: 6231, top1_acc: 0.6900, top5_acc: 0.9900, loss_cls: 0.8372, loss: 0.8372, grad_norm: 1.8632\n",
      "2021-03-29 23:52:05,776 - mmaction - INFO - Saving checkpoint at 12 epochs\n",
      "2021-03-29 23:52:36,558 - mmaction - INFO - Epoch [13][100/175]\tlr: 7.103e-02, eta: 0:20:12, time: 0.305, data_time: 0.024, memory: 6231, top1_acc: 0.6550, top5_acc: 0.9867, loss_cls: 0.9069, loss: 0.9069, grad_norm: 1.7456\n",
      "2021-03-29 23:53:28,424 - mmaction - INFO - Epoch [14][100/175]\tlr: 7.729e-02, eta: 0:19:38, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.6533, top5_acc: 0.9883, loss_cls: 0.8014, loss: 0.8014, grad_norm: 1.7826\n",
      "2021-03-29 23:54:20,157 - mmaction - INFO - Epoch [15][100/175]\tlr: 8.303e-02, eta: 0:19:04, time: 0.305, data_time: 0.024, memory: 6231, top1_acc: 0.6733, top5_acc: 0.9900, loss_cls: 0.8131, loss: 0.8131, grad_norm: 1.6589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 61.8 task/s, elapsed: 2s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 23:54:43,532 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 23:54:43,534 - mmaction - INFO - \n",
      "top1_acc\t0.7698\n",
      "top5_acc\t1.0000\n",
      "2021-03-29 23:54:43,535 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 23:54:43,536 - mmaction - INFO - \n",
      "mean_acc\t0.7698\n",
      "2021-03-29 23:54:43,844 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_15.pth.\n",
      "2021-03-29 23:54:43,845 - mmaction - INFO - Best top1_acc is 0.7698 at 15 epoch.\n",
      "2021-03-29 23:54:43,846 - mmaction - INFO - Epoch(val) [15][175]\ttop1_acc: 0.7698, top5_acc: 1.0000, mean_class_accuracy: 0.7698\n",
      "2021-03-29 23:55:15,191 - mmaction - INFO - Epoch [16][100/175]\tlr: 8.809e-02, eta: 0:18:32, time: 0.313, data_time: 0.024, memory: 6231, top1_acc: 0.7067, top5_acc: 0.9933, loss_cls: 0.7561, loss: 0.7561, grad_norm: 1.5346\n",
      "2021-03-29 23:56:06,946 - mmaction - INFO - Epoch [17][100/175]\tlr: 9.238e-02, eta: 0:17:59, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.7033, top5_acc: 0.9783, loss_cls: 0.7555, loss: 0.7555, grad_norm: 1.3910\n",
      "2021-03-29 23:56:58,699 - mmaction - INFO - Epoch [18][100/175]\tlr: 9.578e-02, eta: 0:17:26, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.7300, top5_acc: 0.9917, loss_cls: 0.7904, loss: 0.7904, grad_norm: 1.5723\n",
      "2021-03-29 23:57:50,441 - mmaction - INFO - Epoch [19][100/175]\tlr: 9.822e-02, eta: 0:16:54, time: 0.305, data_time: 0.023, memory: 6231, top1_acc: 0.6750, top5_acc: 0.9933, loss_cls: 0.8351, loss: 0.8351, grad_norm: 1.6519\n",
      "2021-03-29 23:58:42,276 - mmaction - INFO - Epoch [20][100/175]\tlr: 9.963e-02, eta: 0:16:21, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.7200, top5_acc: 0.9950, loss_cls: 0.7473, loss: 0.7473, grad_norm: 1.3919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 62.1 task/s, elapsed: 2s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-29 23:59:05,631 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-29 23:59:05,632 - mmaction - INFO - \n",
      "top1_acc\t0.7460\n",
      "top5_acc\t0.9921\n",
      "2021-03-29 23:59:05,632 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-29 23:59:05,633 - mmaction - INFO - \n",
      "mean_acc\t0.7460\n",
      "2021-03-29 23:59:05,634 - mmaction - INFO - Epoch(val) [20][175]\ttop1_acc: 0.7460, top5_acc: 0.9921, mean_class_accuracy: 0.7460\n",
      "2021-03-29 23:59:36,248 - mmaction - INFO - Epoch [21][100/175]\tlr: 9.999e-02, eta: 0:15:49, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.7350, top5_acc: 0.9950, loss_cls: 0.6835, loss: 0.6835, grad_norm: 1.3199\n",
      "2021-03-30 00:00:28,007 - mmaction - INFO - Epoch [22][100/175]\tlr: 9.964e-02, eta: 0:15:17, time: 0.306, data_time: 0.023, memory: 6231, top1_acc: 0.7100, top5_acc: 0.9933, loss_cls: 0.7411, loss: 0.7411, grad_norm: 1.3525\n",
      "2021-03-30 00:01:19,817 - mmaction - INFO - Epoch [23][100/175]\tlr: 9.877e-02, eta: 0:14:45, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.6967, top5_acc: 0.9867, loss_cls: 0.7458, loss: 0.7458, grad_norm: 1.3028\n",
      "2021-03-30 00:02:11,521 - mmaction - INFO - Epoch [24][100/175]\tlr: 9.738e-02, eta: 0:14:13, time: 0.305, data_time: 0.024, memory: 6231, top1_acc: 0.7150, top5_acc: 0.9883, loss_cls: 0.7793, loss: 0.7793, grad_norm: 1.4806\n",
      "2021-03-30 00:02:32,692 - mmaction - INFO - Saving checkpoint at 24 epochs\n",
      "2021-03-30 00:03:03,436 - mmaction - INFO - Epoch [25][100/175]\tlr: 9.550e-02, eta: 0:13:41, time: 0.305, data_time: 0.024, memory: 6231, top1_acc: 0.7100, top5_acc: 0.9850, loss_cls: 0.7168, loss: 0.7168, grad_norm: 1.1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 61.6 task/s, elapsed: 2s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 00:03:26,696 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-30 00:03:26,698 - mmaction - INFO - \n",
      "top1_acc\t0.7302\n",
      "top5_acc\t1.0000\n",
      "2021-03-30 00:03:26,699 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-30 00:03:26,700 - mmaction - INFO - \n",
      "mean_acc\t0.7302\n",
      "2021-03-30 00:03:26,701 - mmaction - INFO - Epoch(val) [25][175]\ttop1_acc: 0.7302, top5_acc: 1.0000, mean_class_accuracy: 0.7302\n",
      "2021-03-30 00:03:57,272 - mmaction - INFO - Epoch [26][100/175]\tlr: 9.313e-02, eta: 0:13:10, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.7050, top5_acc: 0.9833, loss_cls: 0.6978, loss: 0.6978, grad_norm: 1.1034\n",
      "2021-03-30 00:04:49,048 - mmaction - INFO - Epoch [27][100/175]\tlr: 9.031e-02, eta: 0:12:38, time: 0.305, data_time: 0.024, memory: 6231, top1_acc: 0.7567, top5_acc: 0.9967, loss_cls: 0.6220, loss: 0.6220, grad_norm: 1.1670\n",
      "2021-03-30 00:05:40,725 - mmaction - INFO - Epoch [28][100/175]\tlr: 8.707e-02, eta: 0:12:07, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.7567, top5_acc: 0.9967, loss_cls: 0.6178, loss: 0.6178, grad_norm: 1.3068\n",
      "2021-03-30 00:06:32,557 - mmaction - INFO - Epoch [29][100/175]\tlr: 8.343e-02, eta: 0:11:35, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.7683, top5_acc: 0.9917, loss_cls: 0.6024, loss: 0.6024, grad_norm: 1.1252\n",
      "2021-03-30 00:07:24,216 - mmaction - INFO - Epoch [30][100/175]\tlr: 7.945e-02, eta: 0:11:04, time: 0.305, data_time: 0.024, memory: 6231, top1_acc: 0.7467, top5_acc: 0.9933, loss_cls: 0.6136, loss: 0.6136, grad_norm: 1.0943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 62.0 task/s, elapsed: 2s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 00:07:47,561 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-30 00:07:47,563 - mmaction - INFO - \n",
      "top1_acc\t0.7857\n",
      "top5_acc\t1.0000\n",
      "2021-03-30 00:07:47,563 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-30 00:07:47,565 - mmaction - INFO - \n",
      "mean_acc\t0.7857\n",
      "2021-03-30 00:07:47,859 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_30.pth.\n",
      "2021-03-30 00:07:47,860 - mmaction - INFO - Best top1_acc is 0.7857 at 30 epoch.\n",
      "2021-03-30 00:07:47,861 - mmaction - INFO - Epoch(val) [30][175]\ttop1_acc: 0.7857, top5_acc: 1.0000, mean_class_accuracy: 0.7857\n",
      "2021-03-30 00:08:18,542 - mmaction - INFO - Epoch [31][100/175]\tlr: 7.515e-02, eta: 0:10:33, time: 0.307, data_time: 0.024, memory: 6231, top1_acc: 0.7867, top5_acc: 0.9967, loss_cls: 0.5664, loss: 0.5664, grad_norm: 1.0673\n",
      "2021-03-30 00:09:11,145 - mmaction - INFO - Epoch [32][100/175]\tlr: 7.059e-02, eta: 0:10:02, time: 0.308, data_time: 0.024, memory: 6231, top1_acc: 0.7950, top5_acc: 0.9950, loss_cls: 0.5198, loss: 0.5198, grad_norm: 1.1285\n",
      "2021-03-30 00:10:03,126 - mmaction - INFO - Epoch [33][100/175]\tlr: 6.581e-02, eta: 0:09:30, time: 0.307, data_time: 0.024, memory: 6231, top1_acc: 0.7500, top5_acc: 0.9900, loss_cls: 0.6420, loss: 0.6420, grad_norm: 1.2504\n",
      "2021-03-30 00:10:55,224 - mmaction - INFO - Epoch [34][100/175]\tlr: 6.087e-02, eta: 0:08:59, time: 0.308, data_time: 0.024, memory: 6231, top1_acc: 0.7750, top5_acc: 0.9967, loss_cls: 0.5468, loss: 0.5468, grad_norm: 1.0756\n",
      "2021-03-30 00:11:47,154 - mmaction - INFO - Epoch [35][100/175]\tlr: 5.581e-02, eta: 0:08:28, time: 0.307, data_time: 0.024, memory: 6231, top1_acc: 0.7967, top5_acc: 0.9917, loss_cls: 0.5353, loss: 0.5353, grad_norm: 1.1149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 61.6 task/s, elapsed: 2s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 00:12:10,560 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-30 00:12:10,562 - mmaction - INFO - \n",
      "top1_acc\t0.7778\n",
      "top5_acc\t1.0000\n",
      "2021-03-30 00:12:10,563 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-30 00:12:10,565 - mmaction - INFO - \n",
      "mean_acc\t0.7778\n",
      "2021-03-30 00:12:10,567 - mmaction - INFO - Epoch(val) [35][175]\ttop1_acc: 0.7778, top5_acc: 1.0000, mean_class_accuracy: 0.7778\n",
      "2021-03-30 00:12:41,260 - mmaction - INFO - Epoch [36][100/175]\tlr: 5.069e-02, eta: 0:07:57, time: 0.307, data_time: 0.024, memory: 6231, top1_acc: 0.8067, top5_acc: 0.9967, loss_cls: 0.5010, loss: 0.5010, grad_norm: 1.1623\n",
      "2021-03-30 00:13:02,501 - mmaction - INFO - Saving checkpoint at 36 epochs\n",
      "2021-03-30 00:13:33,496 - mmaction - INFO - Epoch [37][100/175]\tlr: 4.556e-02, eta: 0:07:26, time: 0.307, data_time: 0.024, memory: 6231, top1_acc: 0.7933, top5_acc: 0.9950, loss_cls: 0.5430, loss: 0.5430, grad_norm: 1.1383\n",
      "2021-03-30 00:14:25,353 - mmaction - INFO - Epoch [38][100/175]\tlr: 4.048e-02, eta: 0:06:55, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.8133, top5_acc: 0.9967, loss_cls: 0.4555, loss: 0.4555, grad_norm: 1.0692\n",
      "2021-03-30 00:15:17,417 - mmaction - INFO - Epoch [39][100/175]\tlr: 3.550e-02, eta: 0:06:24, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.7833, top5_acc: 1.0000, loss_cls: 0.4752, loss: 0.4752, grad_norm: 1.1092\n",
      "2021-03-30 00:16:09,207 - mmaction - INFO - Epoch [40][100/175]\tlr: 3.067e-02, eta: 0:05:53, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.7983, top5_acc: 0.9967, loss_cls: 0.4847, loss: 0.4847, grad_norm: 1.1428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 60.8 task/s, elapsed: 2s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 00:16:32,542 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-30 00:16:32,545 - mmaction - INFO - \n",
      "top1_acc\t0.8095\n",
      "top5_acc\t1.0000\n",
      "2021-03-30 00:16:32,545 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-30 00:16:32,547 - mmaction - INFO - \n",
      "mean_acc\t0.8095\n",
      "2021-03-30 00:16:32,849 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_40.pth.\n",
      "2021-03-30 00:16:32,850 - mmaction - INFO - Best top1_acc is 0.8095 at 40 epoch.\n",
      "2021-03-30 00:16:32,850 - mmaction - INFO - Epoch(val) [40][175]\ttop1_acc: 0.8095, top5_acc: 1.0000, mean_class_accuracy: 0.8095\n",
      "2021-03-30 00:17:03,513 - mmaction - INFO - Epoch [41][100/175]\tlr: 2.605e-02, eta: 0:05:22, time: 0.307, data_time: 0.024, memory: 6231, top1_acc: 0.8267, top5_acc: 0.9933, loss_cls: 0.4550, loss: 0.4550, grad_norm: 1.0917\n",
      "2021-03-30 00:17:55,331 - mmaction - INFO - Epoch [42][100/175]\tlr: 2.168e-02, eta: 0:04:51, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.7883, top5_acc: 0.9950, loss_cls: 0.4869, loss: 0.4869, grad_norm: 1.0203\n",
      "2021-03-30 00:18:47,099 - mmaction - INFO - Epoch [43][100/175]\tlr: 1.760e-02, eta: 0:04:20, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.8133, top5_acc: 0.9950, loss_cls: 0.4431, loss: 0.4431, grad_norm: 1.0156\n",
      "2021-03-30 00:19:38,848 - mmaction - INFO - Epoch [44][100/175]\tlr: 1.387e-02, eta: 0:03:49, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.8183, top5_acc: 0.9933, loss_cls: 0.4181, loss: 0.4181, grad_norm: 1.0424\n",
      "2021-03-30 00:20:30,646 - mmaction - INFO - Epoch [45][100/175]\tlr: 1.052e-02, eta: 0:03:18, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.8350, top5_acc: 0.9950, loss_cls: 0.3830, loss: 0.3830, grad_norm: 0.9963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 59.8 task/s, elapsed: 2s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 00:20:54,118 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-30 00:20:54,120 - mmaction - INFO - \n",
      "top1_acc\t0.8095\n",
      "top5_acc\t1.0000\n",
      "2021-03-30 00:20:54,121 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-30 00:20:54,122 - mmaction - INFO - \n",
      "mean_acc\t0.8095\n",
      "2021-03-30 00:20:54,123 - mmaction - INFO - Epoch(val) [45][175]\ttop1_acc: 0.8095, top5_acc: 1.0000, mean_class_accuracy: 0.8095\n",
      "2021-03-30 00:21:24,717 - mmaction - INFO - Epoch [46][100/175]\tlr: 7.582e-03, eta: 0:02:47, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.8467, top5_acc: 0.9917, loss_cls: 0.3691, loss: 0.3691, grad_norm: 0.9940\n",
      "2021-03-30 00:22:16,425 - mmaction - INFO - Epoch [47][100/175]\tlr: 5.093e-03, eta: 0:02:16, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.8383, top5_acc: 0.9967, loss_cls: 0.3614, loss: 0.3614, grad_norm: 0.9574\n",
      "2021-03-30 00:23:08,294 - mmaction - INFO - Epoch [48][100/175]\tlr: 3.076e-03, eta: 0:01:45, time: 0.306, data_time: 0.024, memory: 6231, top1_acc: 0.8517, top5_acc: 0.9967, loss_cls: 0.3611, loss: 0.3611, grad_norm: 0.9970\n",
      "2021-03-30 00:23:29,546 - mmaction - INFO - Saving checkpoint at 48 epochs\n",
      "2021-03-30 00:24:00,328 - mmaction - INFO - Epoch [49][100/175]\tlr: 1.553e-03, eta: 0:01:14, time: 0.305, data_time: 0.024, memory: 6231, top1_acc: 0.8600, top5_acc: 0.9967, loss_cls: 0.3347, loss: 0.3347, grad_norm: 0.9732\n",
      "2021-03-30 00:24:52,075 - mmaction - INFO - Epoch [50][100/175]\tlr: 5.412e-04, eta: 0:00:44, time: 0.305, data_time: 0.024, memory: 6231, top1_acc: 0.8533, top5_acc: 0.9983, loss_cls: 0.3588, loss: 0.3588, grad_norm: 0.9715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 63.3 task/s, elapsed: 2s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 00:25:15,442 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-03-30 00:25:15,444 - mmaction - INFO - \n",
      "top1_acc\t0.8095\n",
      "top5_acc\t1.0000\n",
      "2021-03-30 00:25:15,445 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-03-30 00:25:15,448 - mmaction - INFO - \n",
      "mean_acc\t0.8095\n",
      "2021-03-30 00:25:15,449 - mmaction - INFO - Epoch(val) [50][175]\ttop1_acc: 0.8095, top5_acc: 1.0000, mean_class_accuracy: 0.8095\n",
      "2021-03-30 00:25:46,192 - mmaction - INFO - Epoch [51][100/175]\tlr: 4.979e-05, eta: 0:00:13, time: 0.307, data_time: 0.024, memory: 6231, top1_acc: 0.8217, top5_acc: 0.9950, loss_cls: 0.3936, loss: 0.3936, grad_norm: 1.1156\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model50e\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-30 01:00:17,769 - mmaction - INFO - These parameters in pretrained checkpoint are not loaded: {'fc.weight', 'fc.bias', 'conv1.weight'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_torchvision loader\n"
     ]
    }
   ],
   "source": [
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "model = pickle.load(open(f\"{cfg.work_dir}/model50e\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 59.5 task/s, elapsed: 2s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.8730\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.8730\n",
      "top1_acc: 0.8730\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.8730\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmaction.models import build_model\n",
    "from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=4,\n",
    "        workers_per_gpu=1,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'], yticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# I3D 96.83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64CW6d_AaT-Q",
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-01 15:05:30--  https://download.openmmlab.com/mmaction/recognition/i3d/i3d_nl_embedded_gaussian_r50_32x2x1_100e_kinetics400_rgb/i3d_nl_embedded_gaussian_r50_32x2x1_100e_kinetics400_rgb_20200813-6e6aef1b.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.254.186.225\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.254.186.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 141906964 (135M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/i3d_nl_embedded_gaussian_r50_32x2x1_100e_kinetics400_rgb_20200813-6e6aef1b.pth’\n",
      "\n",
      "checkpoints/i3d_nl_ 100%[===================>] 135,33M  8,89MB/s    in 15s     \n",
      "\n",
      "2021-04-01 15:05:46 (8,92 MB/s) - ‘checkpoints/i3d_nl_embedded_gaussian_r50_32x2x1_100e_kinetics400_rgb_20200813-6e6aef1b.pth’ saved [141906964/141906964]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/i3d/i3d_nl_embedded_gaussian_r50_32x2x1_100e_kinetics400_rgb/i3d_nl_embedded_gaussian_r50_32x2x1_100e_kinetics400_rgb_20200813-6e6aef1b.pth \\\n",
    "      -O checkpoints/i3d_nl_embedded_gaussian_r50_32x2x1_100e_kinetics400_rgb_20200813-6e6aef1b.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/i3d/i3d_nl_embedded_gaussian_r50_32x2x1_100e_kinetics400_rgb.py')\n",
    "# print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='ResNet3d',\n",
      "        pretrained2d=True,\n",
      "        pretrained='torchvision://resnet50',\n",
      "        depth=50,\n",
      "        conv_cfg=dict(type='Conv3d'),\n",
      "        norm_eval=False,\n",
      "        inflate=((1, 1, 1), (1, 0, 1, 0), (1, 0, 1, 0, 1, 0), (0, 1, 0)),\n",
      "        zero_init_residual=False,\n",
      "        non_local=((0, 0, 0), (0, 1, 0, 1), (0, 1, 0, 1, 0, 1), (0, 0, 0)),\n",
      "        non_local_cfg=dict(\n",
      "            sub_sample=True,\n",
      "            use_scale=False,\n",
      "            norm_cfg=dict(type='BN3d', requires_grad=True),\n",
      "            mode='embedded_gaussian')),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        num_classes=7,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(10, 1e-05),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "total_epochs = 51\n",
      "checkpoint_config = dict(interval=12)\n",
      "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/i3d_nl_embedded_gaussian_r50_32x2x1_100e_kinetics400_rgb_20200813-6e6aef1b.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'RawframeDataset'\n",
      "data_root = 'data/childact_rgb_rawframe/train/'\n",
      "data_root_val = 'data/childact_rgb_rawframe/val/'\n",
      "ann_file_train = 'data/childact_rgb_rawframe/childact_train_rgb_rawframe.txt'\n",
      "ann_file_val = 'data/childact_rgb_rawframe/childact_val_rgb_rawframe.txt'\n",
      "ann_file_test = 'data/childact_rgb_rawframe/childact_test_rgb_rawframe.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(\n",
      "        type='MultiScaleCrop',\n",
      "        input_size=224,\n",
      "        scales=(1, 0.8),\n",
      "        random_crop=False,\n",
      "        max_wh_scale_gap=0),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=10,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='ThreeCrop', crop_size=256),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rgb_rawframe/childact_train_rgb_rawframe.txt',\n",
      "        data_prefix='data/childact_rgb_rawframe/train/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(\n",
      "                type='MultiScaleCrop',\n",
      "                input_size=224,\n",
      "                scales=(1, 0.8),\n",
      "                random_crop=False,\n",
      "                max_wh_scale_gap=0),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ],\n",
      "        start_index=0),\n",
      "    val=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rgb_rawframe/childact_val_rgb_rawframe.txt',\n",
      "        data_prefix='data/childact_rgb_rawframe/val/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        start_index=0),\n",
      "    test=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/childact_rgb_rawframe/childact_test_rgb_rawframe.txt',\n",
      "        data_prefix='data/childact_rgb_rawframe/test/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=10,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='ThreeCrop', crop_size=256),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        start_index=0))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "work_dir = './childact-checkpoints/childact-i3D'\n",
      "omnisource = False\n",
      "momentum_config = dict(\n",
      "    policy='cyclic',\n",
      "    target_ratio=(0.8947368421052632, 1),\n",
      "    cyclic_times=1,\n",
      "    step_ratio_up=0.4)\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/childact-i3D/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'data/childact_rgb_rawframe/train/'\n",
    "cfg.data_root_val = 'data/childact_rgb_rawframe/val/'\n",
    "cfg.ann_file_train = 'data/childact_rgb_rawframe/childact_train_rgb_rawframe.txt'\n",
    "cfg.ann_file_val = 'data/childact_rgb_rawframe/childact_val_rgb_rawframe.txt'\n",
    "cfg.ann_file_test = 'data/childact_rgb_rawframe/childact_test_rgb_rawframe.txt'\n",
    "\n",
    "# cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'data/childact_rgb_rawframe/childact_test_rgb_rawframe.txt'\n",
    "cfg.data.test.data_prefix = 'data/childact_rgb_rawframe/test/'\n",
    "\n",
    "# cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'data/childact_rgb_rawframe/childact_train_rgb_rawframe.txt'\n",
    "cfg.data.train.data_prefix = 'data/childact_rgb_rawframe/train/'\n",
    "\n",
    "# cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'data/childact_rgb_rawframe/childact_val_rgb_rawframe.txt'\n",
    "cfg.data.val.data_prefix = 'data/childact_rgb_rawframe/val/'\n",
    "\n",
    "cfg.data.train.start_index = 0\n",
    "cfg.data.test.start_index = 0\n",
    "cfg.data.val.start_index = 0\n",
    "\n",
    "# cfg.data.test.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# cfg.data.train.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# cfg.data.val.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 7\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = 'checkpoints/i3d_nl_embedded_gaussian_r50_32x2x1_100e_kinetics400_rgb_20200813-6e6aef1b.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/childact-i3D'\n",
    "\n",
    "cfg.lr_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(10, 1e-5),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "cfg.total_epochs = 51\n",
    "\n",
    "cfg.momentum_config = dict(\n",
    "    policy='cyclic',\n",
    "    target_ratio=(0.85 / 0.95, 1),\n",
    "    cyclic_times=1,\n",
    "    step_ratio_up=0.4,\n",
    ")\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 12\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# cfg.img_norm_cfg.mean = [0.485, 0.456, 0.406]\n",
    "# cfg.img_norm_cfg.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# cfg.train_pipeline[6] = dict(type='Normalize', mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], to_bgr=False)\n",
    "# cfg.test_pipeline[4] = dict(type='Normalize', mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], to_bgr=False)\n",
    "# cfg.val_pipeline[4] = dict(type='Normalize', mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], to_bgr=False)\n",
    "\n",
    "# cfg.model.backbone.in_channels = 2\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 15:07:37,615 - mmaction - INFO - load model from: torchvision://resnet50\n",
      "2021-04-01 15:07:37,776 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.g.0\n",
      "2021-04-01 15:07:37,777 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.g.0\n",
      "2021-04-01 15:07:37,778 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.conv_out\n",
      "2021-04-01 15:07:37,779 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.bn_out\n",
      "2021-04-01 15:07:37,780 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.theta\n",
      "2021-04-01 15:07:37,780 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.theta\n",
      "2021-04-01 15:07:37,781 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.phi.0\n",
      "2021-04-01 15:07:37,782 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.phi.0\n",
      "2021-04-01 15:07:37,787 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.g.0\n",
      "2021-04-01 15:07:37,788 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.g.0\n",
      "2021-04-01 15:07:37,789 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.conv_out\n",
      "2021-04-01 15:07:37,790 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.bn_out\n",
      "2021-04-01 15:07:37,790 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.theta\n",
      "2021-04-01 15:07:37,791 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.theta\n",
      "2021-04-01 15:07:37,792 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.phi.0\n",
      "2021-04-01 15:07:37,793 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.phi.0\n",
      "2021-04-01 15:07:37,802 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.g.0\n",
      "2021-04-01 15:07:37,802 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.g.0\n",
      "2021-04-01 15:07:37,803 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.conv_out\n",
      "2021-04-01 15:07:37,804 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.bn_out\n",
      "2021-04-01 15:07:37,805 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.theta\n",
      "2021-04-01 15:07:37,806 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.theta\n",
      "2021-04-01 15:07:37,806 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.phi.0\n",
      "2021-04-01 15:07:37,807 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.phi.0\n",
      "2021-04-01 15:07:37,813 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.g.0\n",
      "2021-04-01 15:07:37,815 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.g.0\n",
      "2021-04-01 15:07:37,816 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.conv_out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_torchvision loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 15:07:37,816 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.bn_out\n",
      "2021-04-01 15:07:37,817 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.theta\n",
      "2021-04-01 15:07:37,818 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.theta\n",
      "2021-04-01 15:07:37,819 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.phi.0\n",
      "2021-04-01 15:07:37,819 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.phi.0\n",
      "2021-04-01 15:07:37,825 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.g.0\n",
      "2021-04-01 15:07:37,826 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.g.0\n",
      "2021-04-01 15:07:37,826 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.conv_out\n",
      "2021-04-01 15:07:37,827 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.bn_out\n",
      "2021-04-01 15:07:37,828 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.theta\n",
      "2021-04-01 15:07:37,828 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.theta\n",
      "2021-04-01 15:07:37,829 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.phi.0\n",
      "2021-04-01 15:07:37,829 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.phi.0\n",
      "2021-04-01 15:07:37,859 - mmaction - INFO - These parameters in the 2d checkpoint are not loaded: {'fc.weight', 'fc.bias'}\n",
      "2021-04-01 15:07:40,390 - mmaction - INFO - load checkpoint from checkpoints/i3d_nl_embedded_gaussian_r50_32x2x1_100e_kinetics400_rgb_20200813-6e6aef1b.pth\n",
      "2021-04-01 15:07:40,391 - mmaction - INFO - Use load_from_local loader\n",
      "2021-04-01 15:07:40,516 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([7, 2048]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([7]).\n",
      "2021-04-01 15:07:40,517 - mmaction - INFO - Start running, host: actrec@actrec-HP-Z4-G4-Workstation, work_dir: /home/actrec/.virtualenvs/mmaction/mmaction2/childact-checkpoints/childact-i3D\n",
      "2021-04-01 15:07:40,518 - mmaction - INFO - workflow: [('train', 1)], max: 51 epochs\n",
      "/home/actrec/.virtualenvs/mmaction/mmaction2/mmaction/core/evaluation/eval_hooks.py:131: UserWarning: runner.meta is None. Creating a empty one.\n",
      "  warnings.warn('runner.meta is None. Creating a empty one.')\n",
      "2021-04-01 15:08:25,428 - mmaction - INFO - Epoch [1][100/132]\tlr: 1.030e-02, eta: 0:49:38, time: 0.449, data_time: 0.045, memory: 6295, top1_acc: 0.5437, top5_acc: 0.9600, loss_cls: 1.1842, loss: 1.1842, grad_norm: 9.0370\n",
      "2021-04-01 15:09:23,051 - mmaction - INFO - Epoch [2][100/132]\tlr: 1.163e-02, eta: 0:41:49, time: 0.446, data_time: 0.048, memory: 6295, top1_acc: 0.6288, top5_acc: 0.9925, loss_cls: 1.0098, loss: 1.0098, grad_norm: 6.3497\n",
      "2021-04-01 15:10:24,014 - mmaction - INFO - Epoch [3][100/132]\tlr: 1.398e-02, eta: 0:40:13, time: 0.484, data_time: 0.069, memory: 6295, top1_acc: 0.6863, top5_acc: 0.9938, loss_cls: 0.8143, loss: 0.8143, grad_norm: 4.8414\n",
      "2021-04-01 15:11:31,591 - mmaction - INFO - Epoch [4][100/132]\tlr: 1.730e-02, eta: 0:39:46, time: 0.519, data_time: 0.091, memory: 6295, top1_acc: 0.6575, top5_acc: 0.9912, loss_cls: 0.8700, loss: 0.8700, grad_norm: 4.7590\n",
      "2021-04-01 15:12:39,894 - mmaction - INFO - Epoch [5][100/132]\tlr: 2.152e-02, eta: 0:39:27, time: 0.537, data_time: 0.093, memory: 6295, top1_acc: 0.6963, top5_acc: 0.9925, loss_cls: 0.8020, loss: 0.8020, grad_norm: 4.3604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.8 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 15:13:00,389 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 15:13:00,391 - mmaction - INFO - \n",
      "top1_acc\t0.7540\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 15:13:00,391 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 15:13:00,392 - mmaction - INFO - \n",
      "mean_acc\t0.7540\n",
      "2021-04-01 15:13:00,807 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
      "2021-04-01 15:13:00,808 - mmaction - INFO - Best top1_acc is 0.7540 at 5 epoch.\n",
      "2021-04-01 15:13:00,809 - mmaction - INFO - Epoch(val) [5][132]\ttop1_acc: 0.7540, top5_acc: 1.0000, mean_class_accuracy: 0.7540\n",
      "2021-04-01 15:13:45,525 - mmaction - INFO - Epoch [6][100/132]\tlr: 2.653e-02, eta: 0:37:45, time: 0.447, data_time: 0.048, memory: 6295, top1_acc: 0.6475, top5_acc: 0.9862, loss_cls: 0.9266, loss: 0.9266, grad_norm: 4.3385\n",
      "2021-04-01 15:14:43,072 - mmaction - INFO - Epoch [7][100/132]\tlr: 3.221e-02, eta: 0:36:20, time: 0.447, data_time: 0.047, memory: 6295, top1_acc: 0.6787, top5_acc: 0.9900, loss_cls: 0.8424, loss: 0.8424, grad_norm: 3.4103\n",
      "2021-04-01 15:15:40,361 - mmaction - INFO - Epoch [8][100/132]\tlr: 3.844e-02, eta: 0:35:05, time: 0.447, data_time: 0.046, memory: 6295, top1_acc: 0.6675, top5_acc: 0.9975, loss_cls: 0.8133, loss: 0.8133, grad_norm: 3.1120\n",
      "2021-04-01 15:16:37,590 - mmaction - INFO - Epoch [9][100/132]\tlr: 4.505e-02, eta: 0:33:57, time: 0.447, data_time: 0.046, memory: 6295, top1_acc: 0.6625, top5_acc: 0.9950, loss_cls: 0.8164, loss: 0.8164, grad_norm: 3.9313\n",
      "2021-04-01 15:17:34,808 - mmaction - INFO - Epoch [10][100/132]\tlr: 5.190e-02, eta: 0:32:53, time: 0.446, data_time: 0.043, memory: 6295, top1_acc: 0.6500, top5_acc: 0.9962, loss_cls: 0.9126, loss: 0.9126, grad_norm: 3.2115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 19.1 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 15:17:54,177 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 15:17:54,178 - mmaction - INFO - \n",
      "top1_acc\t0.7857\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 15:17:54,179 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 15:17:54,179 - mmaction - INFO - \n",
      "mean_acc\t0.7857\n",
      "2021-04-01 15:17:54,613 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_10.pth.\n",
      "2021-04-01 15:17:54,614 - mmaction - INFO - Best top1_acc is 0.7857 at 10 epoch.\n",
      "2021-04-01 15:17:54,615 - mmaction - INFO - Epoch(val) [10][132]\ttop1_acc: 0.7857, top5_acc: 1.0000, mean_class_accuracy: 0.7857\n",
      "2021-04-01 15:18:38,835 - mmaction - INFO - Epoch [11][100/132]\tlr: 5.883e-02, eta: 0:31:52, time: 0.442, data_time: 0.045, memory: 6295, top1_acc: 0.7100, top5_acc: 0.9962, loss_cls: 0.7362, loss: 0.7362, grad_norm: 2.3710\n",
      "2021-04-01 15:19:36,184 - mmaction - INFO - Epoch [12][100/132]\tlr: 6.566e-02, eta: 0:30:55, time: 0.446, data_time: 0.044, memory: 6295, top1_acc: 0.6837, top5_acc: 0.9875, loss_cls: 0.7911, loss: 0.7911, grad_norm: 2.1863\n",
      "2021-04-01 15:19:48,862 - mmaction - INFO - Saving checkpoint at 12 epochs\n",
      "2021-04-01 15:20:34,096 - mmaction - INFO - Epoch [13][100/132]\tlr: 7.225e-02, eta: 0:30:00, time: 0.448, data_time: 0.047, memory: 6295, top1_acc: 0.7100, top5_acc: 0.9962, loss_cls: 0.7568, loss: 0.7568, grad_norm: 2.1244\n",
      "2021-04-01 15:21:31,600 - mmaction - INFO - Epoch [14][100/132]\tlr: 7.842e-02, eta: 0:29:07, time: 0.448, data_time: 0.045, memory: 6295, top1_acc: 0.7462, top5_acc: 0.9988, loss_cls: 0.6335, loss: 0.6335, grad_norm: 2.1381\n",
      "2021-04-01 15:22:29,145 - mmaction - INFO - Epoch [15][100/132]\tlr: 8.404e-02, eta: 0:28:15, time: 0.449, data_time: 0.047, memory: 6295, top1_acc: 0.7013, top5_acc: 0.9950, loss_cls: 0.7674, loss: 0.7674, grad_norm: 1.9936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 19.0 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 15:22:48,508 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 15:22:48,510 - mmaction - INFO - \n",
      "top1_acc\t0.8571\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 15:22:48,511 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 15:22:48,513 - mmaction - INFO - \n",
      "mean_acc\t0.8571\n",
      "2021-04-01 15:22:49,027 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_15.pth.\n",
      "2021-04-01 15:22:49,028 - mmaction - INFO - Best top1_acc is 0.8571 at 15 epoch.\n",
      "2021-04-01 15:22:49,028 - mmaction - INFO - Epoch(val) [15][132]\ttop1_acc: 0.8571, top5_acc: 1.0000, mean_class_accuracy: 0.8571\n",
      "2021-04-01 15:23:33,649 - mmaction - INFO - Epoch [16][100/132]\tlr: 8.897e-02, eta: 0:27:23, time: 0.446, data_time: 0.046, memory: 6295, top1_acc: 0.7050, top5_acc: 0.9938, loss_cls: 0.7669, loss: 0.7669, grad_norm: 2.2776\n",
      "2021-04-01 15:24:30,566 - mmaction - INFO - Epoch [17][100/132]\tlr: 9.309e-02, eta: 0:26:32, time: 0.443, data_time: 0.042, memory: 6295, top1_acc: 0.7375, top5_acc: 0.9938, loss_cls: 0.6668, loss: 0.6668, grad_norm: 1.9338\n",
      "2021-04-01 15:25:28,239 - mmaction - INFO - Epoch [18][100/132]\tlr: 9.632e-02, eta: 0:25:42, time: 0.449, data_time: 0.045, memory: 6295, top1_acc: 0.7238, top5_acc: 0.9962, loss_cls: 0.6543, loss: 0.6543, grad_norm: 1.5301\n",
      "2021-04-01 15:26:27,029 - mmaction - INFO - Epoch [19][100/132]\tlr: 9.856e-02, eta: 0:24:55, time: 0.461, data_time: 0.056, memory: 6295, top1_acc: 0.7600, top5_acc: 0.9938, loss_cls: 0.6179, loss: 0.6179, grad_norm: 1.8083\n",
      "2021-04-01 15:27:25,014 - mmaction - INFO - Epoch [20][100/132]\tlr: 9.978e-02, eta: 0:24:06, time: 0.447, data_time: 0.046, memory: 6295, top1_acc: 0.7300, top5_acc: 0.9975, loss_cls: 0.6331, loss: 0.6331, grad_norm: 1.6047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.9 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 15:27:44,700 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 15:27:44,703 - mmaction - INFO - \n",
      "top1_acc\t0.8492\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 15:27:44,704 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 15:27:44,706 - mmaction - INFO - \n",
      "mean_acc\t0.8492\n",
      "2021-04-01 15:27:44,707 - mmaction - INFO - Epoch(val) [20][132]\ttop1_acc: 0.8492, top5_acc: 1.0000, mean_class_accuracy: 0.8492\n",
      "2021-04-01 15:28:29,267 - mmaction - INFO - Epoch [21][100/132]\tlr: 9.997e-02, eta: 0:23:17, time: 0.446, data_time: 0.042, memory: 6295, top1_acc: 0.7400, top5_acc: 0.9950, loss_cls: 0.6544, loss: 0.6544, grad_norm: 1.6735\n",
      "2021-04-01 15:29:26,443 - mmaction - INFO - Epoch [22][100/132]\tlr: 9.952e-02, eta: 0:22:29, time: 0.445, data_time: 0.043, memory: 6295, top1_acc: 0.7300, top5_acc: 0.9962, loss_cls: 0.6228, loss: 0.6228, grad_norm: 1.5644\n",
      "2021-04-01 15:30:23,664 - mmaction - INFO - Epoch [23][100/132]\tlr: 9.854e-02, eta: 0:21:41, time: 0.444, data_time: 0.043, memory: 6295, top1_acc: 0.7025, top5_acc: 0.9962, loss_cls: 0.7322, loss: 0.7322, grad_norm: 1.7756\n",
      "2021-04-01 15:31:20,436 - mmaction - INFO - Epoch [24][100/132]\tlr: 9.706e-02, eta: 0:20:52, time: 0.441, data_time: 0.039, memory: 6295, top1_acc: 0.7400, top5_acc: 0.9975, loss_cls: 0.6745, loss: 0.6745, grad_norm: 1.6977\n",
      "2021-04-01 15:31:33,174 - mmaction - INFO - Saving checkpoint at 24 epochs\n",
      "2021-04-01 15:32:19,241 - mmaction - INFO - Epoch [25][100/132]\tlr: 9.508e-02, eta: 0:20:06, time: 0.457, data_time: 0.054, memory: 6295, top1_acc: 0.7638, top5_acc: 0.9938, loss_cls: 0.6313, loss: 0.6313, grad_norm: 1.5972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 18.1 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 15:32:39,094 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 15:32:39,095 - mmaction - INFO - \n",
      "top1_acc\t0.8571\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 15:32:39,096 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 15:32:39,096 - mmaction - INFO - \n",
      "mean_acc\t0.8571\n",
      "2021-04-01 15:32:39,097 - mmaction - INFO - Epoch(val) [25][132]\ttop1_acc: 0.8571, top5_acc: 1.0000, mean_class_accuracy: 0.8571\n",
      "2021-04-01 15:33:24,216 - mmaction - INFO - Epoch [26][100/132]\tlr: 9.263e-02, eta: 0:19:19, time: 0.451, data_time: 0.046, memory: 6295, top1_acc: 0.7550, top5_acc: 1.0000, loss_cls: 0.6145, loss: 0.6145, grad_norm: 1.5164\n",
      "2021-04-01 15:34:21,486 - mmaction - INFO - Epoch [27][100/132]\tlr: 8.973e-02, eta: 0:18:32, time: 0.446, data_time: 0.042, memory: 6295, top1_acc: 0.7725, top5_acc: 1.0000, loss_cls: 0.5407, loss: 0.5407, grad_norm: 1.4287\n",
      "2021-04-01 15:35:18,922 - mmaction - INFO - Epoch [28][100/132]\tlr: 8.641e-02, eta: 0:17:45, time: 0.448, data_time: 0.044, memory: 6295, top1_acc: 0.7913, top5_acc: 0.9975, loss_cls: 0.5225, loss: 0.5225, grad_norm: 1.4325\n",
      "2021-04-01 15:36:16,193 - mmaction - INFO - Epoch [29][100/132]\tlr: 8.271e-02, eta: 0:16:58, time: 0.446, data_time: 0.045, memory: 6295, top1_acc: 0.7788, top5_acc: 0.9950, loss_cls: 0.5607, loss: 0.5607, grad_norm: 1.3122\n",
      "2021-04-01 15:37:13,870 - mmaction - INFO - Epoch [30][100/132]\tlr: 7.866e-02, eta: 0:16:12, time: 0.450, data_time: 0.045, memory: 6295, top1_acc: 0.7875, top5_acc: 0.9962, loss_cls: 0.5300, loss: 0.5300, grad_norm: 1.3053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 18.1 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 15:37:33,642 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 15:37:33,644 - mmaction - INFO - \n",
      "top1_acc\t0.8492\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 15:37:33,645 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 15:37:33,647 - mmaction - INFO - \n",
      "mean_acc\t0.8492\n",
      "2021-04-01 15:37:33,648 - mmaction - INFO - Epoch(val) [30][132]\ttop1_acc: 0.8492, top5_acc: 1.0000, mean_class_accuracy: 0.8492\n",
      "2021-04-01 15:38:18,224 - mmaction - INFO - Epoch [31][100/132]\tlr: 7.431e-02, eta: 0:15:25, time: 0.446, data_time: 0.044, memory: 6295, top1_acc: 0.7750, top5_acc: 0.9962, loss_cls: 0.5964, loss: 0.5964, grad_norm: 1.4931\n",
      "2021-04-01 15:39:15,493 - mmaction - INFO - Epoch [32][100/132]\tlr: 6.971e-02, eta: 0:14:39, time: 0.447, data_time: 0.044, memory: 6295, top1_acc: 0.7788, top5_acc: 0.9950, loss_cls: 0.5383, loss: 0.5383, grad_norm: 1.3537\n",
      "2021-04-01 15:40:13,266 - mmaction - INFO - Epoch [33][100/132]\tlr: 6.490e-02, eta: 0:13:53, time: 0.449, data_time: 0.044, memory: 6295, top1_acc: 0.7788, top5_acc: 0.9975, loss_cls: 0.5228, loss: 0.5228, grad_norm: 1.2076\n",
      "2021-04-01 15:41:10,797 - mmaction - INFO - Epoch [34][100/132]\tlr: 5.993e-02, eta: 0:13:07, time: 0.448, data_time: 0.043, memory: 6295, top1_acc: 0.7900, top5_acc: 1.0000, loss_cls: 0.5020, loss: 0.5020, grad_norm: 1.2405\n",
      "2021-04-01 15:42:08,132 - mmaction - INFO - Epoch [35][100/132]\tlr: 5.485e-02, eta: 0:12:21, time: 0.446, data_time: 0.042, memory: 6295, top1_acc: 0.8037, top5_acc: 0.9975, loss_cls: 0.5054, loss: 0.5054, grad_norm: 1.3393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 18.4 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 15:42:27,760 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 15:42:27,762 - mmaction - INFO - \n",
      "top1_acc\t0.8968\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 15:42:27,763 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 15:42:27,764 - mmaction - INFO - \n",
      "mean_acc\t0.8968\n",
      "2021-04-01 15:42:28,203 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_35.pth.\n",
      "2021-04-01 15:42:28,204 - mmaction - INFO - Best top1_acc is 0.8968 at 35 epoch.\n",
      "2021-04-01 15:42:28,205 - mmaction - INFO - Epoch(val) [35][132]\ttop1_acc: 0.8968, top5_acc: 1.0000, mean_class_accuracy: 0.8968\n",
      "2021-04-01 15:43:12,791 - mmaction - INFO - Epoch [36][100/132]\tlr: 4.973e-02, eta: 0:11:35, time: 0.446, data_time: 0.044, memory: 6295, top1_acc: 0.7963, top5_acc: 0.9962, loss_cls: 0.5294, loss: 0.5294, grad_norm: 1.3313\n",
      "2021-04-01 15:43:25,427 - mmaction - INFO - Saving checkpoint at 36 epochs\n",
      "2021-04-01 15:44:10,265 - mmaction - INFO - Epoch [37][100/132]\tlr: 4.461e-02, eta: 0:10:48, time: 0.444, data_time: 0.042, memory: 6295, top1_acc: 0.8075, top5_acc: 0.9988, loss_cls: 0.4733, loss: 0.4733, grad_norm: 1.3203\n",
      "2021-04-01 15:45:07,778 - mmaction - INFO - Epoch [38][100/132]\tlr: 3.954e-02, eta: 0:10:03, time: 0.448, data_time: 0.044, memory: 6295, top1_acc: 0.8213, top5_acc: 1.0000, loss_cls: 0.4606, loss: 0.4606, grad_norm: 1.2695\n",
      "2021-04-01 15:46:05,786 - mmaction - INFO - Epoch [39][100/132]\tlr: 3.459e-02, eta: 0:09:17, time: 0.451, data_time: 0.048, memory: 6295, top1_acc: 0.8150, top5_acc: 0.9988, loss_cls: 0.4444, loss: 0.4444, grad_norm: 1.3014\n",
      "2021-04-01 15:47:03,049 - mmaction - INFO - Epoch [40][100/132]\tlr: 2.979e-02, eta: 0:08:31, time: 0.445, data_time: 0.041, memory: 6295, top1_acc: 0.8063, top5_acc: 1.0000, loss_cls: 0.4404, loss: 0.4404, grad_norm: 1.3876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 18.4 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 15:47:22,618 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 15:47:22,620 - mmaction - INFO - \n",
      "top1_acc\t0.9048\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 15:47:22,620 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 15:47:22,622 - mmaction - INFO - \n",
      "mean_acc\t0.9048\n",
      "2021-04-01 15:47:23,062 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_40.pth.\n",
      "2021-04-01 15:47:23,063 - mmaction - INFO - Best top1_acc is 0.9048 at 40 epoch.\n",
      "2021-04-01 15:47:23,063 - mmaction - INFO - Epoch(val) [40][132]\ttop1_acc: 0.9048, top5_acc: 1.0000, mean_class_accuracy: 0.9048\n",
      "2021-04-01 15:48:07,644 - mmaction - INFO - Epoch [41][100/132]\tlr: 2.521e-02, eta: 0:07:45, time: 0.446, data_time: 0.042, memory: 6295, top1_acc: 0.8237, top5_acc: 1.0000, loss_cls: 0.4076, loss: 0.4076, grad_norm: 1.1360\n",
      "2021-04-01 15:49:04,757 - mmaction - INFO - Epoch [42][100/132]\tlr: 2.089e-02, eta: 0:07:00, time: 0.445, data_time: 0.041, memory: 6295, top1_acc: 0.8125, top5_acc: 0.9975, loss_cls: 0.4707, loss: 0.4707, grad_norm: 1.2669\n",
      "2021-04-01 15:50:02,007 - mmaction - INFO - Epoch [43][100/132]\tlr: 1.688e-02, eta: 0:06:14, time: 0.446, data_time: 0.040, memory: 6295, top1_acc: 0.8337, top5_acc: 0.9988, loss_cls: 0.4407, loss: 0.4407, grad_norm: 1.3302\n",
      "2021-04-01 15:50:59,461 - mmaction - INFO - Epoch [44][100/132]\tlr: 1.322e-02, eta: 0:05:28, time: 0.447, data_time: 0.042, memory: 6295, top1_acc: 0.8200, top5_acc: 0.9962, loss_cls: 0.4568, loss: 0.4568, grad_norm: 1.3236\n",
      "2021-04-01 15:51:56,761 - mmaction - INFO - Epoch [45][100/132]\tlr: 9.941e-03, eta: 0:04:43, time: 0.447, data_time: 0.044, memory: 6295, top1_acc: 0.8438, top5_acc: 0.9962, loss_cls: 0.4182, loss: 0.4182, grad_norm: 1.2218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 18.2 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 15:52:16,493 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 15:52:16,494 - mmaction - INFO - \n",
      "top1_acc\t0.9127\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 15:52:16,495 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 15:52:16,496 - mmaction - INFO - \n",
      "mean_acc\t0.9127\n",
      "2021-04-01 15:52:16,942 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_45.pth.\n",
      "2021-04-01 15:52:16,943 - mmaction - INFO - Best top1_acc is 0.9127 at 45 epoch.\n",
      "2021-04-01 15:52:16,944 - mmaction - INFO - Epoch(val) [45][132]\ttop1_acc: 0.9127, top5_acc: 1.0000, mean_class_accuracy: 0.9127\n",
      "2021-04-01 15:53:01,439 - mmaction - INFO - Epoch [46][100/132]\tlr: 7.086e-03, eta: 0:03:57, time: 0.445, data_time: 0.044, memory: 6295, top1_acc: 0.8225, top5_acc: 0.9975, loss_cls: 0.4624, loss: 0.4624, grad_norm: 1.2670\n",
      "2021-04-01 15:54:00,925 - mmaction - INFO - Epoch [47][100/132]\tlr: 4.683e-03, eta: 0:03:12, time: 0.468, data_time: 0.052, memory: 6295, top1_acc: 0.8413, top5_acc: 0.9988, loss_cls: 0.4094, loss: 0.4094, grad_norm: 1.2148\n",
      "2021-04-01 15:54:58,770 - mmaction - INFO - Epoch [48][100/132]\tlr: 2.757e-03, eta: 0:02:27, time: 0.447, data_time: 0.042, memory: 6295, top1_acc: 0.8550, top5_acc: 0.9962, loss_cls: 0.3797, loss: 0.3797, grad_norm: 1.1767\n",
      "2021-04-01 15:55:11,808 - mmaction - INFO - Saving checkpoint at 48 epochs\n",
      "2021-04-01 15:55:56,690 - mmaction - INFO - Epoch [49][100/132]\tlr: 1.328e-03, eta: 0:01:41, time: 0.445, data_time: 0.041, memory: 6295, top1_acc: 0.8363, top5_acc: 0.9975, loss_cls: 0.3948, loss: 0.3948, grad_norm: 1.2126\n",
      "2021-04-01 15:56:53,899 - mmaction - INFO - Epoch [50][100/132]\tlr: 4.111e-04, eta: 0:00:56, time: 0.446, data_time: 0.042, memory: 6295, top1_acc: 0.8400, top5_acc: 0.9988, loss_cls: 0.4025, loss: 0.4025, grad_norm: 1.2291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 17.9 task/s, elapsed: 7s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 15:57:13,744 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-04-01 15:57:13,746 - mmaction - INFO - \n",
      "top1_acc\t0.9127\n",
      "top5_acc\t1.0000\n",
      "2021-04-01 15:57:13,747 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-04-01 15:57:13,748 - mmaction - INFO - \n",
      "mean_acc\t0.9127\n",
      "2021-04-01 15:57:13,749 - mmaction - INFO - Epoch(val) [50][132]\ttop1_acc: 0.9127, top5_acc: 1.0000, mean_class_accuracy: 0.9127\n",
      "2021-04-01 15:57:58,546 - mmaction - INFO - Epoch [51][100/132]\tlr: 1.656e-05, eta: 0:00:10, time: 0.448, data_time: 0.044, memory: 6295, top1_acc: 0.8550, top5_acc: 0.9988, loss_cls: 0.3664, loss: 0.3664, grad_norm: 1.1114\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model50e\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 16:48:14,393 - mmaction - INFO - load model from: torchvision://resnet50\n",
      "2021-04-01 16:48:14,578 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.g.0\n",
      "2021-04-01 16:48:14,579 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.g.0\n",
      "2021-04-01 16:48:14,580 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.conv_out\n",
      "2021-04-01 16:48:14,581 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.bn_out\n",
      "2021-04-01 16:48:14,582 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.theta\n",
      "2021-04-01 16:48:14,583 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.theta\n",
      "2021-04-01 16:48:14,584 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.phi.0\n",
      "2021-04-01 16:48:14,585 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.1.non_local_block.phi.0\n",
      "2021-04-01 16:48:14,590 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.g.0\n",
      "2021-04-01 16:48:14,591 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.g.0\n",
      "2021-04-01 16:48:14,592 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.conv_out\n",
      "2021-04-01 16:48:14,593 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.bn_out\n",
      "2021-04-01 16:48:14,594 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.theta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_torchvision loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 16:48:14,595 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.theta\n",
      "2021-04-01 16:48:14,595 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.phi.0\n",
      "2021-04-01 16:48:14,596 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer2.3.non_local_block.phi.0\n",
      "2021-04-01 16:48:14,605 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.g.0\n",
      "2021-04-01 16:48:14,606 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.g.0\n",
      "2021-04-01 16:48:14,607 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.conv_out\n",
      "2021-04-01 16:48:14,607 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.bn_out\n",
      "2021-04-01 16:48:14,608 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.theta\n",
      "2021-04-01 16:48:14,608 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.theta\n",
      "2021-04-01 16:48:14,609 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.phi.0\n",
      "2021-04-01 16:48:14,609 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.1.non_local_block.phi.0\n",
      "2021-04-01 16:48:14,613 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.g.0\n",
      "2021-04-01 16:48:14,614 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.g.0\n",
      "2021-04-01 16:48:14,614 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.conv_out\n",
      "2021-04-01 16:48:14,615 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.bn_out\n",
      "2021-04-01 16:48:14,615 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.theta\n",
      "2021-04-01 16:48:14,615 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.theta\n",
      "2021-04-01 16:48:14,615 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.phi.0\n",
      "2021-04-01 16:48:14,616 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.3.non_local_block.phi.0\n",
      "2021-04-01 16:48:14,619 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.g.0\n",
      "2021-04-01 16:48:14,620 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.g.0\n",
      "2021-04-01 16:48:14,620 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.conv_out\n",
      "2021-04-01 16:48:14,620 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.bn_out\n",
      "2021-04-01 16:48:14,621 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.theta\n",
      "2021-04-01 16:48:14,621 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.theta\n",
      "2021-04-01 16:48:14,621 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.phi.0\n",
      "2021-04-01 16:48:14,621 - mmaction - WARNING - Module not exist in the state_dict_r2d: layer3.5.non_local_block.phi.0\n",
      "2021-04-01 16:48:14,644 - mmaction - INFO - These parameters in the 2d checkpoint are not loaded: {'fc.bias', 'fc.weight'}\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "import pickle\n",
    "import mmcv\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "model = pickle.load(open(f\"{cfg.work_dir}/model50e\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 0.9 task/s, elapsed: 139s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.9683\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.9683\n",
      "top1_acc: 0.9683\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.9683\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmaction.models import build_model\n",
    "from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=2,\n",
    "        workers_per_gpu=4,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'], yticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MMAction2 Tutorial.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e05164d-f5e3-4b27-90d6-3c8ac8333984",
   "metadata": {},
   "source": [
    "# Gender recognition from actions with CSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c387a898-e2c2-4f9a-89c5-e5880b99cdb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bf8PpPXtVvmg",
    "outputId": "2c685a33-474b-4e71-8f98-c2533c66095e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n",
      "gcc (Ubuntu 8.4.0-3ubuntu2) 8.4.0\n",
      "Copyright (C) 2018 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check nvcc version\n",
    "!nvcc -V\n",
    "# Check GCC version\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42fcd6f9-e94e-4059-9bbd-a3c34e879624",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5PAJ4ArzV5Ry",
    "outputId": "e48dbf61-fae0-431c-e964-04c7caaee4bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install some optional requirements\n",
    "# !pip install -r requirements/optional.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88f32778-1d0a-4df2-839d-140081efb6e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "No_zZAFpWC-a",
    "outputId": "1d425eea-d44e-434a-991c-01eb15abaab2",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0 True\n",
      "0.16.0\n",
      "10.2\n",
      "GCC 7.3\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMAction2 installation\n",
    "import mmaction\n",
    "print(mmaction.__version__)\n",
    "\n",
    "# Check MMCV installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())\n",
    "\n",
    "import sys\n",
    "# sys.path.append('/home/actrec/.local/lib/python3.6/site-packages/decord-0.5.3-py3.6-linux-x86_64.egg')\n",
    "# import decord\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0a4fa5-0d5b-4420-8a9f-6309f5c90766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/robt427nv/childact\n"
     ]
    }
   ],
   "source": [
    "cd /home/robt427nv/childact/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d25ae8-362a-446e-aaeb-f16769a52115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/robt427nv/childact'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d82e38-156e-4947-be2e-8f7d448387b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;34mage-gender-3split-rgb-frames\u001b[0m/\n",
      " \u001b[01;34mage-gender-3split-vids\u001b[0m/\n",
      " \u001b[01;34mcheckpoints\u001b[0m/\n",
      " ChildAct_age_gender.csv\n",
      " \u001b[34;42mchildact_videos_nosplit\u001b[0m/\n",
      " \u001b[01;34mmmaction2\u001b[0m/\n",
      " \u001b[01;32mmy-mmaction.ipynb\u001b[0m*\n",
      "\u001b[01;32m'Split by Folders and Annotation Files creation.ipynb'\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af24c9-89bf-4e69-88e0-334d26735a45",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# CSN gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "027528db-246f-417a-b543-9281b0ce7f16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64CW6d_AaT-Q",
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-21 17:39:20--  https://download.openmmlab.com/mmaction/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.75.20.25\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.75.20.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 119580180 (114M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth’\n",
      "\n",
      "checkpoints/ircsn_i 100%[===================>] 114,04M  6,78MB/s    in 17s     \n",
      "\n",
      "2021-07-21 17:39:39 (6,87 MB/s) - ‘checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth’ saved [119580180/119580180]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth \\\n",
    "      -O checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91b025c7-4c84-456b-864a-6613a3cd53f1",
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('mmaction2/configs/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c42484-9547-4010-8dd9-d848414e3ad5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='ResNet3dCSN',\n",
      "        pretrained2d=False,\n",
      "        pretrained=\n",
      "        'https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r152_ig65m_20200807-771c4135.pth',\n",
      "        depth=152,\n",
      "        with_pool2=False,\n",
      "        bottleneck_mode='ir',\n",
      "        norm_eval=True,\n",
      "        zero_init_residual=False,\n",
      "        bn_frozen=True),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        num_classes=2,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "checkpoint_config = dict(interval=20)\n",
      "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'RawframeDataset'\n",
      "data_root = 'age-gender-3split-rgb-frames/'\n",
      "data_root_val = 'age-gender-3split-rgb-frames/val/'\n",
      "ann_file_train = 'age-gender-3split-rgb-frames/childact_train_rgb320_gender.txt'\n",
      "ann_file_val = 'age-gender-3split-rgb-frames/childact_val_rgb320_gender.txt'\n",
      "ann_file_test = 'age-gender-3split-rgb-frames/childact_test_rgb320_gender.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=10,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='ThreeCrop', crop_size=256),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/kinetics400/kinetics400_train_list_rawframes.txt',\n",
      "        data_prefix='data/kinetics400/rawframes_train',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/kinetics400/kinetics400_val_list_rawframes.txt',\n",
      "        data_prefix='data/kinetics400/rawframes_val',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='data/kinetics400/kinetics400_val_list_rawframes.txt',\n",
      "        data_prefix='data/kinetics400/rawframes_val',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=10,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='ThreeCrop', crop_size=256),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "optimizer = dict(type='SGD', lr=0.000125, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    step=[32, 48],\n",
      "    warmup='linear',\n",
      "    warmup_ratio=0.1,\n",
      "    warmup_by_epoch=True,\n",
      "    warmup_iters=16)\n",
      "total_epochs = 50\n",
      "work_dir = './childact-checkpoints/CSN-gender'\n",
      "find_unused_parameters = True\n",
      "omnisource = False\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/CSN-gender/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'age-gender-3split-rgb-frames/'\n",
    "cfg.data_root_val = 'age-gender-3split-rgb-frames/val/'\n",
    "cfg.ann_file_train = 'age-gender-3split-rgb-frames/childact_train_rgb320_gender.txt'\n",
    "cfg.ann_file_val = 'age-gender-3split-rgb-frames/childact_val_rgb320_gender.txt'\n",
    "cfg.ann_file_test = 'age-gender-3split-rgb-frames/childact_test_rgb320_gender.txt'\n",
    "\n",
    "# cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'age-gender-3split-rgb-frames/childact_test_rgb320_gender.txt'\n",
    "cfg.data.test.data_prefix = 'age-gender-3split-rgb-frames/test/'\n",
    "\n",
    "# cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'age-gender-3split-rgb-frames/childact_train_rgb320_gender.txt'\n",
    "cfg.data.train.data_prefix = 'age-gender-3split-rgb-frames/train/'\n",
    "\n",
    "# cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'age-gender-3split-rgb-frames/childact_val_rgb320_gender.txt'\n",
    "cfg.data.val.data_prefix = 'age-gender-3split-rgb-frames/val/'\n",
    "\n",
    "# cfg.data.test.modality = 'Flow'\n",
    "# cfg.data.val.modality = 'Flow'\n",
    "# cfg.data.train.modality = 'Flow'\n",
    "\n",
    "# cfg.data.train.start_index = 0\n",
    "# cfg.data.test.start_index = 0\n",
    "# cfg.data.val.start_index = 0\n",
    "\n",
    "# cfg.data.test.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# cfg.data.train.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# cfg.data.val.filename_tmpl = 'flow_{}_{:05d}.jpg'\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 2\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = 'checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/CSN-gender'\n",
    "\n",
    "# cfg.img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
    "\n",
    "\n",
    "# cfg.val_pipeline = [\n",
    "#     dict(\n",
    "#         type='SampleFrames',\n",
    "#         clip_len=32,\n",
    "#         frame_interval=2,\n",
    "#         num_clips=1,\n",
    "#         test_mode=True),\n",
    "#     dict(type='RawFrameDecode'),\n",
    "#     dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='CenterCrop', crop_size=224),\n",
    "# #     dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "# #     dict(type='Flip', flip_ratio=0.5)\n",
    "#     dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "#     dict(type='FormatShape', input_format='NCTHW'),\n",
    "#     dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "#     dict(type='ToTensor', keys=['imgs'])\n",
    "# ]\n",
    "# cfg.test_pipeline = [\n",
    "#     dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=10, test_mode=True),\n",
    "#     dict(type='RawFrameDecode'),\n",
    "#     dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='CenterCrop', crop_size=224),\n",
    "#     dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "#     dict(type='FormatShape', input_format='NCTHW'),\n",
    "#     dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "#     dict(type='ToTensor', keys=['imgs'])\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# cfg.train_pipeline = [\n",
    "#     dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
    "#     dict(type='RawFrameDecode'),\n",
    "#     dict(type='Resize', scale=(-1, 256)),\n",
    "# #     dict(type='RandomCrop', size=224),\n",
    "#     dict(type='RandomResizedCrop'),\n",
    "#     dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "# #     dict(type='Flip', flip_ratio=0.5),\n",
    "#     dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "#     dict(type='FormatShape', input_format='NCTHW'),\n",
    "#     dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "#     dict(type='ToTensor', keys=['imgs', 'label'])\n",
    "# ]\n",
    "\n",
    "# cfg.data.train.pipeline = cfg.train_pipeline\n",
    "# cfg.data.val.pipeline = cfg.val_pipeline\n",
    "# cfg.data.test.pipeline = cfg.test_pipeline\n",
    "\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "# cfg.data.videos_per_gpu = 24\n",
    "# cfg.optimizer.type = 'Adam'\n",
    "# cfg.optimizer.weight_decay=0.0001\n",
    "\n",
    "# cfg.optimizer_config.grad_clip=None\n",
    "# cfg.optimizer.lr = 0.01\n",
    "\n",
    "# cfg.lr_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(10, 1e-5),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "cfg.total_epochs = 50\n",
    "\n",
    "# cfg.momentum_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(0.85 / 0.95, 1),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 20\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.data.videos_per_gpu=8\n",
    "\n",
    "# cfg.model.backbone.in_channels = 2\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "736e5d8f-b95c-4bf9-aa96-7067e715b27e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDBWkdDRk6oz",
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "RawframeDataset: [Errno 2] No such file or directory: 'data/kinetics400/kinetics400_train_list_rawframes.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmaction/datasets/rawframe_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ann_file, pipeline, data_prefix, test_mode, filename_tmpl, with_offset, multi_class, num_classes, start_index, modality, sample_by_class, power, dynamic_length)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             dynamic_length=dynamic_length)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmaction/datasets/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ann_file, pipeline, data_prefix, test_mode, multi_class, num_classes, start_index, modality, sample_by_class, power, dynamic_length)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_infos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_by_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmaction/datasets/rawframe_dataset.py\u001b[0m in \u001b[0;36mload_annotations\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mvideo_infos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mann_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/kinetics400/kinetics400_train_list_rawframes.txt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-be92e24cff32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Build the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Build the recognizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmaction/datasets/builder.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(cfg, default_args)\u001b[0m\n\u001b[1;32m     40\u001b[0m             build_dataset(cfg['dataset'], default_args), cfg['times'])\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_from_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/utils/registry.py\u001b[0m in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Normal TypeError does not print class name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{obj_cls.__name__}: {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: RawframeDataset: [Errno 2] No such file or directory: 'data/kinetics400/kinetics400_train_list_rawframes.txt'"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d6e6a38-2cc6-4eb7-b030-4ff874c7b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model100e_ig65m\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db27ee76-06a0-431d-94f2-c330007ffa8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e77b2-4aef-4fe7-a842-7a26fe9ec792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os.path as osp\n",
    "\n",
    "# from mmaction.datasets import build_dataset\n",
    "# from mmaction.models import build_model\n",
    "# from mmaction.apis import train_model\n",
    "# import pickle\n",
    "# import mmcv\n",
    "# # Build the dataset\n",
    "# datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# # Build the recognizer\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "# model = pickle.load(open(f\"{cfg.work_dir}/model50e\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "176ca9dc-6dea-4e53-b418-603248e4d725",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 126/126, 0.5 task/s, elapsed: 265s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.9683\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.9683\n",
      "top1_acc: 0.9683\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.9683\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "from mmaction.models import build_model\n",
    "from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=4,\n",
    "        workers_per_gpu=1,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80ce555a-19a6-46cc-ba4b-d51ba1c6bb02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'], yticklabels = ['box', 'clap', 'go', 'jog', 'run', 'walk', 'wave'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

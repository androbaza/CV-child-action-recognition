{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e05164d-f5e3-4b27-90d6-3c8ac8333984",
   "metadata": {},
   "source": [
    "# Gender recognition from actions with CSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c387a898-e2c2-4f9a-89c5-e5880b99cdb3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bf8PpPXtVvmg",
    "outputId": "2c685a33-474b-4e71-8f98-c2533c66095e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n",
      "gcc (Ubuntu 8.4.0-3ubuntu2) 8.4.0\n",
      "Copyright (C) 2018 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check nvcc version\n",
    "!nvcc -V\n",
    "# Check GCC version\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42fcd6f9-e94e-4059-9bbd-a3c34e879624",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5PAJ4ArzV5Ry",
    "outputId": "e48dbf61-fae0-431c-e964-04c7caaee4bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install some optional requirements\n",
    "# !pip install -r requirements/optional.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f32778-1d0a-4df2-839d-140081efb6e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "No_zZAFpWC-a",
    "outputId": "1d425eea-d44e-434a-991c-01eb15abaab2",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0 True\n",
      "0.16.0\n",
      "10.2\n",
      "GCC 7.3\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMAction2 installation\n",
    "import mmaction\n",
    "print(mmaction.__version__)\n",
    "\n",
    "# Check MMCV installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())\n",
    "\n",
    "import sys\n",
    "# sys.path.append('/home/actrec/.local/lib/python3.6/site-packages/decord-0.5.3-py3.6-linux-x86_64.egg')\n",
    "# import decord\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0a4fa5-0d5b-4420-8a9f-6309f5c90766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/robt427nv/childact\n"
     ]
    }
   ],
   "source": [
    "cd /home/robt427nv/childact/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d25ae8-362a-446e-aaeb-f16769a52115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/robt427nv/childact'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d82e38-156e-4947-be2e-8f7d448387b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;34mage-gender-3split-rgb-frames\u001b[0m/\n",
      " \u001b[01;34mage-gender-3split-vids\u001b[0m/\n",
      " \u001b[01;34mcheckpoints\u001b[0m/\n",
      " ChildAct_age_gender.csv\n",
      " \u001b[34;42mchildact_videos_nosplit\u001b[0m/\n",
      " \u001b[01;34mmmaction2\u001b[0m/\n",
      " \u001b[01;32mmy-mmaction.ipynb\u001b[0m*\n",
      "\u001b[01;32m'Split by Folders and Annotation Files creation.ipynb'\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af24c9-89bf-4e69-88e0-334d26735a45",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# CSN gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "027528db-246f-417a-b543-9281b0ce7f16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64CW6d_AaT-Q",
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-21 17:39:20--  https://download.openmmlab.com/mmaction/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.75.20.25\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.75.20.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 119580180 (114M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth’\n",
      "\n",
      "checkpoints/ircsn_i 100%[===================>] 114,04M  6,78MB/s    in 17s     \n",
      "\n",
      "2021-07-21 17:39:39 (6,87 MB/s) - ‘checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth’ saved [119580180/119580180]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth \\\n",
    "      -O checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91b025c7-4c84-456b-864a-6613a3cd53f1",
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('mmaction2/configs/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55c42484-9547-4010-8dd9-d848414e3ad5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='ResNet3dCSN',\n",
      "        pretrained2d=False,\n",
      "        pretrained=\n",
      "        'https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r152_ig65m_20200807-771c4135.pth',\n",
      "        depth=152,\n",
      "        with_pool2=False,\n",
      "        bottleneck_mode='ir',\n",
      "        norm_eval=True,\n",
      "        zero_init_residual=False,\n",
      "        bn_frozen=True),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        num_classes=2,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "checkpoint_config = dict(interval=20)\n",
      "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'RawframeDataset'\n",
      "data_root = 'age-gender-3split-rgb-frames/'\n",
      "data_root_val = 'age-gender-3split-rgb-frames/val/'\n",
      "ann_file_train = 'age-gender-3split-rgb-frames/childact_train_rgb320_gender.txt'\n",
      "ann_file_val = 'age-gender-3split-rgb-frames/childact_val_rgb320_gender.txt'\n",
      "ann_file_test = 'age-gender-3split-rgb-frames/childact_test_rgb320_gender.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=10,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='ThreeCrop', crop_size=256),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file=\n",
      "        'age-gender-3split-rgb-frames/childact_train_rgb320_gender.txt',\n",
      "        data_prefix='age-gender-3split-rgb-frames/train/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ],\n",
      "        filename_tmpl='{:03}.jpeg'),\n",
      "    val=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='age-gender-3split-rgb-frames/childact_val_rgb320_gender.txt',\n",
      "        data_prefix='age-gender-3split-rgb-frames/val/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        filename_tmpl='{:03}.jpeg'),\n",
      "    test=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='age-gender-3split-rgb-frames/childact_test_rgb320_gender.txt',\n",
      "        data_prefix='age-gender-3split-rgb-frames/test/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=10,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='ThreeCrop', crop_size=256),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        filename_tmpl='{:03}.jpeg'))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "optimizer = dict(type='SGD', lr=0.000125, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    step=[32, 48],\n",
      "    warmup='linear',\n",
      "    warmup_ratio=0.1,\n",
      "    warmup_by_epoch=True,\n",
      "    warmup_iters=16)\n",
      "total_epochs = 50\n",
      "work_dir = './childact-checkpoints/CSN-gender'\n",
      "find_unused_parameters = True\n",
      "omnisource = False\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/CSN-gender/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'age-gender-3split-rgb-frames/'\n",
    "cfg.data_root_val = 'age-gender-3split-rgb-frames/val/'\n",
    "cfg.ann_file_train = 'age-gender-3split-rgb-frames/childact_train_rgb320_gender.txt'\n",
    "cfg.ann_file_val = 'age-gender-3split-rgb-frames/childact_val_rgb320_gender.txt'\n",
    "cfg.ann_file_test = 'age-gender-3split-rgb-frames/childact_test_rgb320_gender.txt'\n",
    "\n",
    "# cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'age-gender-3split-rgb-frames/childact_test_rgb320_gender.txt'\n",
    "cfg.data.test.data_prefix = 'age-gender-3split-rgb-frames/test/'\n",
    "\n",
    "# cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'age-gender-3split-rgb-frames/childact_train_rgb320_gender.txt'\n",
    "cfg.data.train.data_prefix = 'age-gender-3split-rgb-frames/train/'\n",
    "\n",
    "# cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'age-gender-3split-rgb-frames/childact_val_rgb320_gender.txt'\n",
    "cfg.data.val.data_prefix = 'age-gender-3split-rgb-frames/val/'\n",
    "\n",
    "# cfg.data.test.modality = 'Flow'\n",
    "# cfg.data.val.modality = 'Flow'\n",
    "# cfg.data.train.modality = 'Flow'\n",
    "\n",
    "# cfg.data.train.start_index = 0\n",
    "# cfg.data.test.start_index = 0\n",
    "# cfg.data.val.start_index = 0\n",
    "\n",
    "cfg.data.test.filename_tmpl = '{:03}.jpeg'\n",
    "cfg.data.train.filename_tmpl = '{:03}.jpeg'\n",
    "cfg.data.val.filename_tmpl = '{:03}.jpeg'\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 2\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = 'checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/CSN-gender'\n",
    "\n",
    "# cfg.img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
    "\n",
    "\n",
    "# cfg.val_pipeline = [\n",
    "#     dict(\n",
    "#         type='SampleFrames',\n",
    "#         clip_len=32,\n",
    "#         frame_interval=2,\n",
    "#         num_clips=1,\n",
    "#         test_mode=True),\n",
    "#     dict(type='RawFrameDecode'),\n",
    "#     dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='CenterCrop', crop_size=224),\n",
    "# #     dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "# #     dict(type='Flip', flip_ratio=0.5)\n",
    "#     dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "#     dict(type='FormatShape', input_format='NCTHW'),\n",
    "#     dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "#     dict(type='ToTensor', keys=['imgs'])\n",
    "# ]\n",
    "# cfg.test_pipeline = [\n",
    "#     dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=10, test_mode=True),\n",
    "#     dict(type='RawFrameDecode'),\n",
    "#     dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='CenterCrop', crop_size=224),\n",
    "#     dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "#     dict(type='FormatShape', input_format='NCTHW'),\n",
    "#     dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "#     dict(type='ToTensor', keys=['imgs'])\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# cfg.train_pipeline = [\n",
    "#     dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
    "#     dict(type='RawFrameDecode'),\n",
    "#     dict(type='Resize', scale=(-1, 256)),\n",
    "# #     dict(type='RandomCrop', size=224),\n",
    "#     dict(type='RandomResizedCrop'),\n",
    "#     dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "# #     dict(type='Flip', flip_ratio=0.5),\n",
    "#     dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "#     dict(type='FormatShape', input_format='NCTHW'),\n",
    "#     dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "#     dict(type='ToTensor', keys=['imgs', 'label'])\n",
    "# ]\n",
    "\n",
    "# cfg.data.train.pipeline = cfg.train_pipeline\n",
    "# cfg.data.val.pipeline = cfg.val_pipeline\n",
    "# cfg.data.test.pipeline = cfg.test_pipeline\n",
    "\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "# cfg.data.videos_per_gpu = 24\n",
    "# cfg.optimizer.type = 'Adam'\n",
    "# cfg.optimizer.weight_decay=0.0001\n",
    "\n",
    "# cfg.optimizer_config.grad_clip=None\n",
    "# cfg.optimizer.lr = 0.01\n",
    "\n",
    "# cfg.lr_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(10, 1e-5),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "cfg.total_epochs = 50\n",
    "\n",
    "# cfg.momentum_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(0.85 / 0.95, 1),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 20\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.data.videos_per_gpu=8\n",
    "\n",
    "# cfg.model.backbone.in_channels = 2\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c86064bf-1e1a-4da9-a6f0-ebd7238fffa3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d6e6a38-2cc6-4eb7-b030-4ff874c7b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model50e_ig65m\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e77b2-4aef-4fe7-a842-7a26fe9ec792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os.path as osp\n",
    "\n",
    "# from mmaction.datasets import build_dataset\n",
    "# from mmaction.models import build_model\n",
    "# from mmaction.apis import train_model\n",
    "# import pickle\n",
    "# import mmcv\n",
    "# # Build the dataset\n",
    "# datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# # Build the recognizer\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "# model = pickle.load(open(f\"{cfg.work_dir}/model50e\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "176ca9dc-6dea-4e53-b418-603248e4d725",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 119/119, 0.2 task/s, elapsed: 591s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.9580\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.9608\n",
      "top1_acc: 0.9580\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.9608\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "# from mmaction.models import build_model\n",
    "# from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=1,\n",
    "        workers_per_gpu=1,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80ce555a-19a6-46cc-ba4b-d51ba1c6bb02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "\n",
    "sns.heatmap(cf_mat, annot=True, xticklabels = ['male', 'female'], yticklabels = ['male', 'female'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c09085-a907-4a74-9cf6-b69e7be4172c",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# CSN age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26de9e1-1bc6-4935-81e7-6e0b8763ac22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64CW6d_AaT-Q",
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-21 17:39:20--  https://download.openmmlab.com/mmaction/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.75.20.25\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.75.20.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 119580180 (114M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth’\n",
      "\n",
      "checkpoints/ircsn_i 100%[===================>] 114,04M  6,78MB/s    in 17s     \n",
      "\n",
      "2021-07-21 17:39:39 (6,87 MB/s) - ‘checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth’ saved [119580180/119580180]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth \\\n",
    "      -O checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7aa1f91-3bf8-447b-afaf-ac2fc05de585",
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('mmaction2/configs/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "790d890c-99f2-4b3d-8a3e-3951d8049065",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='ResNet3dCSN',\n",
      "        pretrained2d=False,\n",
      "        pretrained=\n",
      "        'https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r152_ig65m_20200807-771c4135.pth',\n",
      "        depth=152,\n",
      "        with_pool2=False,\n",
      "        bottleneck_mode='ir',\n",
      "        norm_eval=True,\n",
      "        zero_init_residual=False,\n",
      "        bn_frozen=True),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        num_classes=6,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "checkpoint_config = dict(interval=20)\n",
      "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'RawframeDataset'\n",
      "data_root = 'age-gender-3split-rgb-frames/'\n",
      "data_root_val = 'age-gender-3split-rgb-frames/val/'\n",
      "ann_file_train = 'age-gender-3split-rgb-frames/childact_train_rgb320_age.txt'\n",
      "ann_file_val = 'age-gender-3split-rgb-frames/childact_val_rgb320_age.txt'\n",
      "ann_file_test = 'age-gender-3split-rgb-frames/childact_test_rgb320_age.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=10,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='ThreeCrop', crop_size=256),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=4,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='age-gender-3split-rgb-frames/childact_train_rgb320_age.txt',\n",
      "        data_prefix='age-gender-3split-rgb-frames/train/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ],\n",
      "        filename_tmpl='{:03}.jpeg'),\n",
      "    val=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='age-gender-3split-rgb-frames/childact_val_rgb320_age.txt',\n",
      "        data_prefix='age-gender-3split-rgb-frames/val/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        filename_tmpl='{:03}.jpeg'),\n",
      "    test=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='age-gender-3split-rgb-frames/childact_test_rgb320_age.txt',\n",
      "        data_prefix='age-gender-3split-rgb-frames/test/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=10,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='ThreeCrop', crop_size=256),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        filename_tmpl='{:03}.jpeg'))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "optimizer = dict(type='SGD', lr=0.000125, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    step=[32, 48],\n",
      "    warmup='linear',\n",
      "    warmup_ratio=0.1,\n",
      "    warmup_by_epoch=True,\n",
      "    warmup_iters=16)\n",
      "total_epochs = 50\n",
      "work_dir = './childact-checkpoints/CSN-age'\n",
      "find_unused_parameters = True\n",
      "omnisource = False\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/CSN-age/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'age-gender-3split-rgb-frames/'\n",
    "cfg.data_root_val = 'age-gender-3split-rgb-frames/val/'\n",
    "cfg.ann_file_train = 'age-gender-3split-rgb-frames/childact_train_rgb320_age.txt'\n",
    "cfg.ann_file_val = 'age-gender-3split-rgb-frames/childact_val_rgb320_age.txt'\n",
    "cfg.ann_file_test = 'age-gender-3split-rgb-frames/childact_test_rgb320_age.txt'\n",
    "\n",
    "# cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'age-gender-3split-rgb-frames/childact_test_rgb320_age.txt'\n",
    "cfg.data.test.data_prefix = 'age-gender-3split-rgb-frames/test/'\n",
    "\n",
    "# cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'age-gender-3split-rgb-frames/childact_train_rgb320_age.txt'\n",
    "cfg.data.train.data_prefix = 'age-gender-3split-rgb-frames/train/'\n",
    "\n",
    "# cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'age-gender-3split-rgb-frames/childact_val_rgb320_age.txt'\n",
    "cfg.data.val.data_prefix = 'age-gender-3split-rgb-frames/val/'\n",
    "\n",
    "# cfg.data.test.modality = 'Flow'\n",
    "# cfg.data.val.modality = 'Flow'\n",
    "# cfg.data.train.modality = 'Flow'\n",
    "\n",
    "# cfg.data.train.start_index = 0\n",
    "# cfg.data.test.start_index = 0\n",
    "# cfg.data.val.start_index = 0\n",
    "\n",
    "cfg.data.test.filename_tmpl = '{:03}.jpeg'\n",
    "cfg.data.train.filename_tmpl = '{:03}.jpeg'\n",
    "cfg.data.val.filename_tmpl = '{:03}.jpeg'\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 6\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = 'checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/CSN-age'\n",
    "\n",
    "# cfg.img_norm_cfg = dict(mean=[128, 128], std=[128, 128])\n",
    "\n",
    "\n",
    "# cfg.val_pipeline = [\n",
    "#     dict(\n",
    "#         type='SampleFrames',\n",
    "#         clip_len=32,\n",
    "#         frame_interval=2,\n",
    "#         num_clips=1,\n",
    "#         test_mode=True),\n",
    "#     dict(type='RawFrameDecode'),\n",
    "#     dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='CenterCrop', crop_size=224),\n",
    "# #     dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "# #     dict(type='Flip', flip_ratio=0.5)\n",
    "#     dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "#     dict(type='FormatShape', input_format='NCTHW'),\n",
    "#     dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "#     dict(type='ToTensor', keys=['imgs'])\n",
    "# ]\n",
    "# cfg.test_pipeline = [\n",
    "#     dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=10, test_mode=True),\n",
    "#     dict(type='RawFrameDecode'),\n",
    "#     dict(type='Resize', scale=(-1, 256)),\n",
    "#     dict(type='CenterCrop', crop_size=224),\n",
    "#     dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "#     dict(type='FormatShape', input_format='NCTHW'),\n",
    "#     dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "#     dict(type='ToTensor', keys=['imgs'])\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# cfg.train_pipeline = [\n",
    "#     dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
    "#     dict(type='RawFrameDecode'),\n",
    "#     dict(type='Resize', scale=(-1, 256)),\n",
    "# #     dict(type='RandomCrop', size=224),\n",
    "#     dict(type='RandomResizedCrop'),\n",
    "#     dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
    "# #     dict(type='Flip', flip_ratio=0.5),\n",
    "#     dict(type='Normalize', mean=[128, 128], std=[128, 128]),\n",
    "#     dict(type='FormatShape', input_format='NCTHW'),\n",
    "#     dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
    "#     dict(type='ToTensor', keys=['imgs', 'label'])\n",
    "# ]\n",
    "\n",
    "# cfg.data.train.pipeline = cfg.train_pipeline\n",
    "# cfg.data.val.pipeline = cfg.val_pipeline\n",
    "# cfg.data.test.pipeline = cfg.test_pipeline\n",
    "\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "# cfg.data.videos_per_gpu = 24\n",
    "# cfg.optimizer.type = 'Adam'\n",
    "# cfg.optimizer.weight_decay=0.0001\n",
    "\n",
    "# cfg.optimizer_config.grad_clip=None\n",
    "# cfg.optimizer.lr = 0.01\n",
    "\n",
    "# cfg.lr_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(10, 1e-5),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "cfg.total_epochs = 50\n",
    "\n",
    "# cfg.momentum_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(0.85 / 0.95, 1),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 20\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.data.videos_per_gpu=4\n",
    "\n",
    "# cfg.model.backbone.in_channels = 2\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a868ef-295d-4b41-842a-adf22e398367",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dDBWkdDRk6oz",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 22:48:39,763 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r152_ig65m_20200807-771c4135.pth\n",
      "2021-07-21 22:48:39,764 - mmaction - INFO - Use load_from_http loader\n",
      "2021-07-21 22:48:41,828 - mmaction - INFO - load checkpoint from checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth\n",
      "2021-07-21 22:48:41,829 - mmaction - INFO - Use load_from_local loader\n",
      "2021-07-21 22:48:41,983 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([6, 2048]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([6]).\n",
      "2021-07-21 22:48:41,989 - mmaction - INFO - Start running, host: robt427nv@robt427NV, work_dir: /home/robt427nv/childact/childact-checkpoints/CSN-age\n",
      "2021-07-21 22:48:41,990 - mmaction - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) EvalHook                           \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) EvalHook                           \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2021-07-21 22:48:41,990 - mmaction - INFO - workflow: [('train', 1)], max: 50 epochs\n",
      "/home/robt427nv/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/runner/hooks/evaluation.py:190: UserWarning: runner.meta is None. Creating an empty one.\n",
      "  warnings.warn('runner.meta is None. Creating an empty one.')\n",
      "2021-07-21 22:49:54,092 - mmaction - INFO - Epoch [1][100/237]\tlr: 1.544e-05, eta: 2:21:10, time: 0.721, data_time: 0.033, memory: 11051, top1_acc: 0.2650, top5_acc: 0.9025, loss_cls: 1.7592, loss: 1.7592, grad_norm: 49.2296\n",
      "2021-07-21 22:51:02,487 - mmaction - INFO - Epoch [1][200/237]\tlr: 1.840e-05, eta: 2:16:23, time: 0.684, data_time: 0.000, memory: 11051, top1_acc: 0.3500, top5_acc: 0.9725, loss_cls: 1.5581, loss: 1.5581, grad_norm: 40.7654\n",
      "2021-07-21 22:52:39,857 - mmaction - INFO - Epoch [2][100/237]\tlr: 2.247e-05, eta: 2:00:56, time: 0.719, data_time: 0.030, memory: 11051, top1_acc: 0.3700, top5_acc: 0.9800, loss_cls: 1.4840, loss: 1.4840, grad_norm: 37.1420\n",
      "2021-07-21 22:53:48,852 - mmaction - INFO - Epoch [2][200/237]\tlr: 2.544e-05, eta: 2:02:28, time: 0.690, data_time: 0.000, memory: 11051, top1_acc: 0.3425, top5_acc: 0.9850, loss_cls: 1.4951, loss: 1.4951, grad_norm: 36.4495\n",
      "2021-07-21 22:55:25,928 - mmaction - INFO - Epoch [3][100/237]\tlr: 2.950e-05, eta: 1:55:37, time: 0.718, data_time: 0.030, memory: 11051, top1_acc: 0.4300, top5_acc: 0.9800, loss_cls: 1.3998, loss: 1.3998, grad_norm: 38.7504\n",
      "2021-07-21 22:56:34,744 - mmaction - INFO - Epoch [3][200/237]\tlr: 3.247e-05, eta: 1:56:36, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.4075, top5_acc: 0.9800, loss_cls: 1.4127, loss: 1.4127, grad_norm: 39.1491\n",
      "2021-07-21 22:58:11,863 - mmaction - INFO - Epoch [4][100/237]\tlr: 3.653e-05, eta: 1:52:00, time: 0.718, data_time: 0.030, memory: 11051, top1_acc: 0.4450, top5_acc: 0.9750, loss_cls: 1.3275, loss: 1.3275, grad_norm: 41.3019\n",
      "2021-07-21 22:59:20,674 - mmaction - INFO - Epoch [4][200/237]\tlr: 3.950e-05, eta: 1:52:35, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.4675, top5_acc: 0.9850, loss_cls: 1.3715, loss: 1.3715, grad_norm: 47.4040\n",
      "2021-07-21 23:00:57,833 - mmaction - INFO - Epoch [5][100/237]\tlr: 4.356e-05, eta: 1:48:59, time: 0.719, data_time: 0.030, memory: 11051, top1_acc: 0.4500, top5_acc: 0.9725, loss_cls: 1.3856, loss: 1.3856, grad_norm: 40.9756\n",
      "2021-07-21 23:02:06,837 - mmaction - INFO - Epoch [5][200/237]\tlr: 4.653e-05, eta: 1:49:17, time: 0.690, data_time: 0.000, memory: 11051, top1_acc: 0.4275, top5_acc: 0.9850, loss_cls: 1.3536, loss: 1.3536, grad_norm: 40.2228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 19.4 task/s, elapsed: 6s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 23:02:38,281 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-07-21 23:02:38,282 - mmaction - INFO - \n",
      "top1_acc\t0.4915\n",
      "top5_acc\t0.9492\n",
      "2021-07-21 23:02:38,282 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-07-21 23:02:38,283 - mmaction - INFO - \n",
      "mean_acc\t0.3125\n",
      "2021-07-21 23:02:38,601 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
      "2021-07-21 23:02:38,602 - mmaction - INFO - Best top1_acc is 0.4915 at 5 epoch.\n",
      "2021-07-21 23:02:38,603 - mmaction - INFO - Epoch(val) [5][30]\ttop1_acc: 0.4915, top5_acc: 0.9492, mean_class_accuracy: 0.3125\n",
      "2021-07-21 23:03:50,713 - mmaction - INFO - Epoch [6][100/237]\tlr: 5.059e-05, eta: 1:46:16, time: 0.721, data_time: 0.031, memory: 11051, top1_acc: 0.4700, top5_acc: 0.9825, loss_cls: 1.3064, loss: 1.3064, grad_norm: 40.6652\n",
      "2021-07-21 23:04:59,505 - mmaction - INFO - Epoch [6][200/237]\tlr: 5.356e-05, eta: 1:46:19, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.5175, top5_acc: 0.9775, loss_cls: 1.2236, loss: 1.2236, grad_norm: 45.5355\n",
      "2021-07-21 23:06:36,340 - mmaction - INFO - Epoch [7][100/237]\tlr: 5.762e-05, eta: 1:43:34, time: 0.715, data_time: 0.029, memory: 11051, top1_acc: 0.4725, top5_acc: 0.9800, loss_cls: 1.2835, loss: 1.2835, grad_norm: 40.9790\n",
      "2021-07-21 23:07:45,148 - mmaction - INFO - Epoch [7][200/237]\tlr: 6.059e-05, eta: 1:43:29, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.5175, top5_acc: 0.9900, loss_cls: 1.1966, loss: 1.1966, grad_norm: 42.6796\n",
      "2021-07-21 23:09:22,207 - mmaction - INFO - Epoch [8][100/237]\tlr: 6.466e-05, eta: 1:41:01, time: 0.719, data_time: 0.030, memory: 11051, top1_acc: 0.5025, top5_acc: 0.9775, loss_cls: 1.2348, loss: 1.2348, grad_norm: 44.0522\n",
      "2021-07-21 23:10:30,802 - mmaction - INFO - Epoch [8][200/237]\tlr: 6.762e-05, eta: 1:40:46, time: 0.686, data_time: 0.000, memory: 11051, top1_acc: 0.5650, top5_acc: 0.9750, loss_cls: 1.1561, loss: 1.1561, grad_norm: 44.0637\n",
      "2021-07-21 23:12:07,748 - mmaction - INFO - Epoch [9][100/237]\tlr: 7.169e-05, eta: 1:38:28, time: 0.717, data_time: 0.030, memory: 11051, top1_acc: 0.5450, top5_acc: 0.9875, loss_cls: 1.1540, loss: 1.1540, grad_norm: 42.4259\n",
      "2021-07-21 23:13:16,435 - mmaction - INFO - Epoch [9][200/237]\tlr: 7.465e-05, eta: 1:38:09, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.5175, top5_acc: 0.9900, loss_cls: 1.1738, loss: 1.1738, grad_norm: 40.9363\n",
      "2021-07-21 23:14:53,495 - mmaction - INFO - Epoch [10][100/237]\tlr: 7.872e-05, eta: 1:35:58, time: 0.716, data_time: 0.030, memory: 11051, top1_acc: 0.5350, top5_acc: 0.9900, loss_cls: 1.1855, loss: 1.1855, grad_norm: 41.6761\n",
      "2021-07-21 23:16:02,258 - mmaction - INFO - Epoch [10][200/237]\tlr: 8.169e-05, eta: 1:35:35, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.5775, top5_acc: 0.9900, loss_cls: 1.0994, loss: 1.0994, grad_norm: 40.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 19.8 task/s, elapsed: 6s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 23:16:33,546 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-07-21 23:16:33,548 - mmaction - INFO - \n",
      "top1_acc\t0.5932\n",
      "top5_acc\t0.9661\n",
      "2021-07-21 23:16:33,549 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-07-21 23:16:33,551 - mmaction - INFO - \n",
      "mean_acc\t0.4248\n",
      "2021-07-21 23:16:33,900 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_10.pth.\n",
      "2021-07-21 23:16:33,901 - mmaction - INFO - Best top1_acc is 0.5932 at 10 epoch.\n",
      "2021-07-21 23:16:33,902 - mmaction - INFO - Epoch(val) [10][30]\ttop1_acc: 0.5932, top5_acc: 0.9661, mean_class_accuracy: 0.4248\n",
      "2021-07-21 23:17:45,593 - mmaction - INFO - Epoch [11][100/237]\tlr: 8.575e-05, eta: 1:33:31, time: 0.717, data_time: 0.031, memory: 11051, top1_acc: 0.5150, top5_acc: 0.9925, loss_cls: 1.1275, loss: 1.1275, grad_norm: 44.7292\n",
      "2021-07-21 23:18:54,280 - mmaction - INFO - Epoch [11][200/237]\tlr: 8.872e-05, eta: 1:33:03, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.5800, top5_acc: 0.9875, loss_cls: 1.1251, loss: 1.1251, grad_norm: 44.4891\n",
      "2021-07-21 23:20:31,250 - mmaction - INFO - Epoch [12][100/237]\tlr: 9.278e-05, eta: 1:31:04, time: 0.717, data_time: 0.030, memory: 11051, top1_acc: 0.5475, top5_acc: 0.9825, loss_cls: 1.1480, loss: 1.1480, grad_norm: 47.5916\n",
      "2021-07-21 23:21:40,055 - mmaction - INFO - Epoch [12][200/237]\tlr: 9.575e-05, eta: 1:30:34, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.5950, top5_acc: 0.9900, loss_cls: 1.0764, loss: 1.0764, grad_norm: 46.7181\n",
      "2021-07-21 23:23:17,281 - mmaction - INFO - Epoch [13][100/237]\tlr: 9.981e-05, eta: 1:28:40, time: 0.720, data_time: 0.030, memory: 11051, top1_acc: 0.5725, top5_acc: 0.9875, loss_cls: 1.0496, loss: 1.0496, grad_norm: 47.3243\n",
      "2021-07-21 23:24:25,924 - mmaction - INFO - Epoch [13][200/237]\tlr: 1.028e-04, eta: 1:28:06, time: 0.686, data_time: 0.000, memory: 11051, top1_acc: 0.5225, top5_acc: 0.9800, loss_cls: 1.1579, loss: 1.1579, grad_norm: 45.5883\n",
      "2021-07-21 23:26:02,756 - mmaction - INFO - Epoch [14][100/237]\tlr: 1.068e-04, eta: 1:26:15, time: 0.716, data_time: 0.029, memory: 11051, top1_acc: 0.6150, top5_acc: 1.0000, loss_cls: 1.0203, loss: 1.0203, grad_norm: 45.6981\n",
      "2021-07-21 23:27:11,424 - mmaction - INFO - Epoch [14][200/237]\tlr: 1.098e-04, eta: 1:25:39, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.5950, top5_acc: 0.9950, loss_cls: 1.0970, loss: 1.0970, grad_norm: 44.2408\n",
      "2021-07-21 23:28:48,240 - mmaction - INFO - Epoch [15][100/237]\tlr: 1.139e-04, eta: 1:23:50, time: 0.717, data_time: 0.030, memory: 11051, top1_acc: 0.6175, top5_acc: 0.9875, loss_cls: 0.9826, loss: 0.9826, grad_norm: 44.4294\n",
      "2021-07-21 23:29:56,948 - mmaction - INFO - Epoch [15][200/237]\tlr: 1.168e-04, eta: 1:23:12, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.6000, top5_acc: 0.9850, loss_cls: 1.0743, loss: 1.0743, grad_norm: 41.5448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 19.9 task/s, elapsed: 6s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 23:30:28,280 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-07-21 23:30:28,282 - mmaction - INFO - \n",
      "top1_acc\t0.6271\n",
      "top5_acc\t0.9831\n",
      "2021-07-21 23:30:28,282 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-07-21 23:30:28,284 - mmaction - INFO - \n",
      "mean_acc\t0.4442\n",
      "2021-07-21 23:30:28,630 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_15.pth.\n",
      "2021-07-21 23:30:28,631 - mmaction - INFO - Best top1_acc is 0.6271 at 15 epoch.\n",
      "2021-07-21 23:30:28,632 - mmaction - INFO - Epoch(val) [15][30]\ttop1_acc: 0.6271, top5_acc: 0.9831, mean_class_accuracy: 0.4442\n",
      "2021-07-21 23:31:40,185 - mmaction - INFO - Epoch [16][100/237]\tlr: 1.209e-04, eta: 1:21:26, time: 0.715, data_time: 0.030, memory: 11051, top1_acc: 0.6200, top5_acc: 0.9925, loss_cls: 0.9786, loss: 0.9786, grad_norm: 40.6878\n",
      "2021-07-21 23:32:48,690 - mmaction - INFO - Epoch [16][200/237]\tlr: 1.239e-04, eta: 1:20:46, time: 0.685, data_time: 0.000, memory: 11051, top1_acc: 0.6075, top5_acc: 0.9950, loss_cls: 1.0333, loss: 1.0333, grad_norm: 40.3230\n",
      "2021-07-21 23:34:25,759 - mmaction - INFO - Epoch [17][100/237]\tlr: 1.250e-04, eta: 1:19:03, time: 0.719, data_time: 0.032, memory: 11051, top1_acc: 0.6075, top5_acc: 0.9950, loss_cls: 1.0410, loss: 1.0410, grad_norm: 45.8679\n",
      "2021-07-21 23:35:34,506 - mmaction - INFO - Epoch [17][200/237]\tlr: 1.250e-04, eta: 1:18:22, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.6125, top5_acc: 0.9900, loss_cls: 0.9971, loss: 0.9971, grad_norm: 47.9671\n",
      "2021-07-21 23:37:11,602 - mmaction - INFO - Epoch [18][100/237]\tlr: 1.250e-04, eta: 1:16:40, time: 0.717, data_time: 0.030, memory: 11051, top1_acc: 0.6700, top5_acc: 0.9925, loss_cls: 0.8811, loss: 0.8811, grad_norm: 48.6032\n",
      "2021-07-21 23:38:20,443 - mmaction - INFO - Epoch [18][200/237]\tlr: 1.250e-04, eta: 1:15:58, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.6350, top5_acc: 0.9900, loss_cls: 0.9526, loss: 0.9526, grad_norm: 51.5418\n",
      "2021-07-21 23:39:57,506 - mmaction - INFO - Epoch [19][100/237]\tlr: 1.250e-04, eta: 1:14:18, time: 0.718, data_time: 0.030, memory: 11051, top1_acc: 0.6350, top5_acc: 0.9925, loss_cls: 0.9253, loss: 0.9253, grad_norm: 45.8937\n",
      "2021-07-21 23:41:06,447 - mmaction - INFO - Epoch [19][200/237]\tlr: 1.250e-04, eta: 1:13:34, time: 0.689, data_time: 0.000, memory: 11051, top1_acc: 0.6075, top5_acc: 0.9925, loss_cls: 0.9695, loss: 0.9695, grad_norm: 42.6499\n",
      "2021-07-21 23:42:43,505 - mmaction - INFO - Epoch [20][100/237]\tlr: 1.250e-04, eta: 1:11:56, time: 0.718, data_time: 0.029, memory: 11051, top1_acc: 0.6550, top5_acc: 0.9875, loss_cls: 0.9122, loss: 0.9122, grad_norm: 43.3373\n",
      "2021-07-21 23:43:52,333 - mmaction - INFO - Epoch [20][200/237]\tlr: 1.250e-04, eta: 1:11:11, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.6575, top5_acc: 0.9950, loss_cls: 0.9290, loss: 0.9290, grad_norm: 43.3886\n",
      "2021-07-21 23:44:17,637 - mmaction - INFO - Saving checkpoint at 20 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 19.9 task/s, elapsed: 6s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 23:44:23,978 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-07-21 23:44:23,981 - mmaction - INFO - \n",
      "top1_acc\t0.6525\n",
      "top5_acc\t0.9831\n",
      "2021-07-21 23:44:23,981 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-07-21 23:44:23,984 - mmaction - INFO - \n",
      "mean_acc\t0.5234\n",
      "2021-07-21 23:44:24,322 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_20.pth.\n",
      "2021-07-21 23:44:24,323 - mmaction - INFO - Best top1_acc is 0.6525 at 20 epoch.\n",
      "2021-07-21 23:44:24,324 - mmaction - INFO - Epoch(val) [20][30]\ttop1_acc: 0.6525, top5_acc: 0.9831, mean_class_accuracy: 0.5234\n",
      "2021-07-21 23:45:36,299 - mmaction - INFO - Epoch [21][100/237]\tlr: 1.250e-04, eta: 1:09:35, time: 0.720, data_time: 0.030, memory: 11051, top1_acc: 0.6700, top5_acc: 0.9950, loss_cls: 0.8806, loss: 0.8806, grad_norm: 41.3368\n",
      "2021-07-21 23:46:44,863 - mmaction - INFO - Epoch [21][200/237]\tlr: 1.250e-04, eta: 1:08:48, time: 0.686, data_time: 0.000, memory: 11051, top1_acc: 0.6750, top5_acc: 0.9975, loss_cls: 0.9267, loss: 0.9267, grad_norm: 46.1390\n",
      "2021-07-21 23:48:21,865 - mmaction - INFO - Epoch [22][100/237]\tlr: 1.250e-04, eta: 1:07:12, time: 0.718, data_time: 0.029, memory: 11051, top1_acc: 0.7050, top5_acc: 0.9975, loss_cls: 0.7728, loss: 0.7728, grad_norm: 45.4252\n",
      "2021-07-21 23:49:30,659 - mmaction - INFO - Epoch [22][200/237]\tlr: 1.250e-04, eta: 1:06:25, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.6550, top5_acc: 1.0000, loss_cls: 0.9206, loss: 0.9206, grad_norm: 48.6524\n",
      "2021-07-21 23:51:07,469 - mmaction - INFO - Epoch [23][100/237]\tlr: 1.250e-04, eta: 1:04:50, time: 0.716, data_time: 0.030, memory: 11051, top1_acc: 0.6950, top5_acc: 0.9950, loss_cls: 0.8558, loss: 0.8558, grad_norm: 47.0423\n",
      "2021-07-21 23:52:16,092 - mmaction - INFO - Epoch [23][200/237]\tlr: 1.250e-04, eta: 1:04:02, time: 0.686, data_time: 0.000, memory: 11051, top1_acc: 0.6775, top5_acc: 0.9950, loss_cls: 0.8354, loss: 0.8354, grad_norm: 42.2045\n",
      "2021-07-21 23:53:52,744 - mmaction - INFO - Epoch [24][100/237]\tlr: 1.250e-04, eta: 1:02:28, time: 0.714, data_time: 0.028, memory: 11051, top1_acc: 0.6925, top5_acc: 0.9975, loss_cls: 0.7774, loss: 0.7774, grad_norm: 44.8047\n",
      "2021-07-21 23:55:01,389 - mmaction - INFO - Epoch [24][200/237]\tlr: 1.250e-04, eta: 1:01:39, time: 0.686, data_time: 0.000, memory: 11051, top1_acc: 0.7100, top5_acc: 0.9925, loss_cls: 0.8201, loss: 0.8201, grad_norm: 43.8672\n",
      "2021-07-21 23:56:38,288 - mmaction - INFO - Epoch [25][100/237]\tlr: 1.250e-04, eta: 1:00:06, time: 0.717, data_time: 0.031, memory: 11051, top1_acc: 0.7175, top5_acc: 0.9875, loss_cls: 0.7830, loss: 0.7830, grad_norm: 43.3840\n",
      "2021-07-21 23:57:47,655 - mmaction - INFO - Epoch [25][200/237]\tlr: 1.250e-04, eta: 0:59:17, time: 0.694, data_time: 0.000, memory: 11051, top1_acc: 0.7375, top5_acc: 0.9975, loss_cls: 0.7082, loss: 0.7082, grad_norm: 47.9695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 19.6 task/s, elapsed: 6s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 23:58:18,976 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-07-21 23:58:18,978 - mmaction - INFO - \n",
      "top1_acc\t0.6780\n",
      "top5_acc\t1.0000\n",
      "2021-07-21 23:58:18,978 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-07-21 23:58:18,980 - mmaction - INFO - \n",
      "mean_acc\t0.4936\n",
      "2021-07-21 23:58:19,337 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_25.pth.\n",
      "2021-07-21 23:58:19,338 - mmaction - INFO - Best top1_acc is 0.6780 at 25 epoch.\n",
      "2021-07-21 23:58:19,339 - mmaction - INFO - Epoch(val) [25][30]\ttop1_acc: 0.6780, top5_acc: 1.0000, mean_class_accuracy: 0.4936\n",
      "2021-07-21 23:59:30,876 - mmaction - INFO - Epoch [26][100/237]\tlr: 1.250e-04, eta: 0:57:45, time: 0.715, data_time: 0.030, memory: 11051, top1_acc: 0.7475, top5_acc: 0.9975, loss_cls: 0.7710, loss: 0.7710, grad_norm: 49.8894\n",
      "2021-07-22 00:00:39,404 - mmaction - INFO - Epoch [26][200/237]\tlr: 1.250e-04, eta: 0:56:54, time: 0.685, data_time: 0.000, memory: 11051, top1_acc: 0.7000, top5_acc: 0.9950, loss_cls: 0.7735, loss: 0.7735, grad_norm: 43.3181\n",
      "2021-07-22 00:02:16,722 - mmaction - INFO - Epoch [27][100/237]\tlr: 1.250e-04, eta: 0:55:24, time: 0.719, data_time: 0.031, memory: 11051, top1_acc: 0.7100, top5_acc: 0.9975, loss_cls: 0.7708, loss: 0.7708, grad_norm: 46.8690\n",
      "2021-07-22 00:03:25,508 - mmaction - INFO - Epoch [27][200/237]\tlr: 1.250e-04, eta: 0:54:32, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.7100, top5_acc: 0.9800, loss_cls: 0.8031, loss: 0.8031, grad_norm: 45.5912\n",
      "2021-07-22 00:05:02,275 - mmaction - INFO - Epoch [28][100/237]\tlr: 1.250e-04, eta: 0:53:02, time: 0.715, data_time: 0.029, memory: 11051, top1_acc: 0.7225, top5_acc: 0.9900, loss_cls: 0.7528, loss: 0.7528, grad_norm: 41.9233\n",
      "2021-07-22 00:06:11,057 - mmaction - INFO - Epoch [28][200/237]\tlr: 1.250e-04, eta: 0:52:10, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.7300, top5_acc: 0.9975, loss_cls: 0.6726, loss: 0.6726, grad_norm: 46.6711\n",
      "2021-07-22 00:07:47,881 - mmaction - INFO - Epoch [29][100/237]\tlr: 1.250e-04, eta: 0:50:41, time: 0.716, data_time: 0.030, memory: 11051, top1_acc: 0.7775, top5_acc: 0.9975, loss_cls: 0.5959, loss: 0.5959, grad_norm: 39.3218\n",
      "2021-07-22 00:08:56,723 - mmaction - INFO - Epoch [29][200/237]\tlr: 1.250e-04, eta: 0:49:48, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.7550, top5_acc: 0.9950, loss_cls: 0.7252, loss: 0.7252, grad_norm: 42.5519\n",
      "2021-07-22 00:10:33,552 - mmaction - INFO - Epoch [30][100/237]\tlr: 1.250e-04, eta: 0:48:20, time: 0.716, data_time: 0.029, memory: 11051, top1_acc: 0.7175, top5_acc: 0.9950, loss_cls: 0.7369, loss: 0.7369, grad_norm: 40.1155\n",
      "2021-07-22 00:11:42,269 - mmaction - INFO - Epoch [30][200/237]\tlr: 1.250e-04, eta: 0:47:26, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.7575, top5_acc: 0.9975, loss_cls: 0.6359, loss: 0.6359, grad_norm: 43.9489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 20.0 task/s, elapsed: 6s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 00:12:13,478 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-07-22 00:12:13,479 - mmaction - INFO - \n",
      "top1_acc\t0.7373\n",
      "top5_acc\t1.0000\n",
      "2021-07-22 00:12:13,479 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-07-22 00:12:13,480 - mmaction - INFO - \n",
      "mean_acc\t0.6438\n",
      "2021-07-22 00:12:13,820 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_30.pth.\n",
      "2021-07-22 00:12:13,821 - mmaction - INFO - Best top1_acc is 0.7373 at 30 epoch.\n",
      "2021-07-22 00:12:13,821 - mmaction - INFO - Epoch(val) [30][30]\ttop1_acc: 0.7373, top5_acc: 1.0000, mean_class_accuracy: 0.6438\n",
      "2021-07-22 00:13:25,484 - mmaction - INFO - Epoch [31][100/237]\tlr: 1.250e-04, eta: 0:45:58, time: 0.717, data_time: 0.031, memory: 11051, top1_acc: 0.7600, top5_acc: 0.9950, loss_cls: 0.6114, loss: 0.6114, grad_norm: 36.9292\n",
      "2021-07-22 00:14:34,151 - mmaction - INFO - Epoch [31][200/237]\tlr: 1.250e-04, eta: 0:45:04, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.7750, top5_acc: 0.9950, loss_cls: 0.6142, loss: 0.6142, grad_norm: 42.1733\n",
      "2021-07-22 00:16:11,205 - mmaction - INFO - Epoch [32][100/237]\tlr: 1.250e-04, eta: 0:43:37, time: 0.719, data_time: 0.031, memory: 11051, top1_acc: 0.7425, top5_acc: 0.9875, loss_cls: 0.7475, loss: 0.7475, grad_norm: 50.4090\n",
      "2021-07-22 00:17:20,001 - mmaction - INFO - Epoch [32][200/237]\tlr: 1.250e-04, eta: 0:42:43, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.7875, top5_acc: 1.0000, loss_cls: 0.5770, loss: 0.5770, grad_norm: 42.4517\n",
      "2021-07-22 00:18:56,816 - mmaction - INFO - Epoch [33][100/237]\tlr: 1.250e-05, eta: 0:41:16, time: 0.716, data_time: 0.030, memory: 11051, top1_acc: 0.8200, top5_acc: 0.9975, loss_cls: 0.4785, loss: 0.4785, grad_norm: 35.9218\n",
      "2021-07-22 00:20:05,565 - mmaction - INFO - Epoch [33][200/237]\tlr: 1.250e-05, eta: 0:40:21, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.7975, top5_acc: 0.9975, loss_cls: 0.5674, loss: 0.5674, grad_norm: 31.9042\n",
      "2021-07-22 00:21:42,383 - mmaction - INFO - Epoch [34][100/237]\tlr: 1.250e-05, eta: 0:38:55, time: 0.716, data_time: 0.029, memory: 11051, top1_acc: 0.8200, top5_acc: 0.9975, loss_cls: 0.4331, loss: 0.4331, grad_norm: 30.1304\n",
      "2021-07-22 00:22:51,067 - mmaction - INFO - Epoch [34][200/237]\tlr: 1.250e-05, eta: 0:38:00, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.8125, top5_acc: 0.9875, loss_cls: 0.5013, loss: 0.5013, grad_norm: 34.1067\n",
      "2021-07-22 00:24:27,854 - mmaction - INFO - Epoch [35][100/237]\tlr: 1.250e-05, eta: 0:36:34, time: 0.716, data_time: 0.030, memory: 11051, top1_acc: 0.8250, top5_acc: 0.9975, loss_cls: 0.4739, loss: 0.4739, grad_norm: 34.2627\n",
      "2021-07-22 00:25:36,617 - mmaction - INFO - Epoch [35][200/237]\tlr: 1.250e-05, eta: 0:35:38, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.8650, top5_acc: 1.0000, loss_cls: 0.4002, loss: 0.4002, grad_norm: 27.0304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 20.2 task/s, elapsed: 6s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 00:26:07,730 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-07-22 00:26:07,731 - mmaction - INFO - \n",
      "top1_acc\t0.8051\n",
      "top5_acc\t1.0000\n",
      "2021-07-22 00:26:07,732 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-07-22 00:26:07,734 - mmaction - INFO - \n",
      "mean_acc\t0.7871\n",
      "2021-07-22 00:26:08,090 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_35.pth.\n",
      "2021-07-22 00:26:08,091 - mmaction - INFO - Best top1_acc is 0.8051 at 35 epoch.\n",
      "2021-07-22 00:26:08,092 - mmaction - INFO - Epoch(val) [35][30]\ttop1_acc: 0.8051, top5_acc: 1.0000, mean_class_accuracy: 0.7871\n",
      "2021-07-22 00:27:19,764 - mmaction - INFO - Epoch [36][100/237]\tlr: 1.250e-05, eta: 0:34:13, time: 0.717, data_time: 0.031, memory: 11051, top1_acc: 0.8400, top5_acc: 1.0000, loss_cls: 0.4026, loss: 0.4026, grad_norm: 31.7659\n",
      "2021-07-22 00:28:28,515 - mmaction - INFO - Epoch [36][200/237]\tlr: 1.250e-05, eta: 0:33:17, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.8275, top5_acc: 0.9975, loss_cls: 0.4631, loss: 0.4631, grad_norm: 37.4314\n",
      "2021-07-22 00:30:05,342 - mmaction - INFO - Epoch [37][100/237]\tlr: 1.250e-05, eta: 0:31:52, time: 0.717, data_time: 0.031, memory: 11051, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.4345, loss: 0.4345, grad_norm: 34.8362\n",
      "2021-07-22 00:31:14,104 - mmaction - INFO - Epoch [37][200/237]\tlr: 1.250e-05, eta: 0:30:56, time: 0.688, data_time: 0.000, memory: 11051, top1_acc: 0.8350, top5_acc: 0.9975, loss_cls: 0.4178, loss: 0.4178, grad_norm: 31.7098\n",
      "2021-07-22 00:32:50,943 - mmaction - INFO - Epoch [38][100/237]\tlr: 1.250e-05, eta: 0:29:31, time: 0.716, data_time: 0.029, memory: 11051, top1_acc: 0.8575, top5_acc: 0.9975, loss_cls: 0.3995, loss: 0.3995, grad_norm: 33.8003\n",
      "2021-07-22 00:33:59,583 - mmaction - INFO - Epoch [38][200/237]\tlr: 1.250e-05, eta: 0:28:34, time: 0.686, data_time: 0.000, memory: 11051, top1_acc: 0.8475, top5_acc: 0.9900, loss_cls: 0.4688, loss: 0.4688, grad_norm: 35.3535\n",
      "2021-07-22 00:35:36,466 - mmaction - INFO - Epoch [39][100/237]\tlr: 1.250e-05, eta: 0:27:10, time: 0.717, data_time: 0.030, memory: 11051, top1_acc: 0.8675, top5_acc: 1.0000, loss_cls: 0.3652, loss: 0.3652, grad_norm: 32.2661\n",
      "2021-07-22 00:36:45,147 - mmaction - INFO - Epoch [39][200/237]\tlr: 1.250e-05, eta: 0:26:13, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.8100, top5_acc: 0.9950, loss_cls: 0.5076, loss: 0.5076, grad_norm: 39.6020\n",
      "2021-07-22 00:38:21,925 - mmaction - INFO - Epoch [40][100/237]\tlr: 1.250e-05, eta: 0:24:49, time: 0.716, data_time: 0.030, memory: 11051, top1_acc: 0.8075, top5_acc: 1.0000, loss_cls: 0.5364, loss: 0.5364, grad_norm: 36.3389\n",
      "2021-07-22 00:39:30,626 - mmaction - INFO - Epoch [40][200/237]\tlr: 1.250e-05, eta: 0:23:52, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.8700, top5_acc: 0.9975, loss_cls: 0.3931, loss: 0.3931, grad_norm: 28.6016\n",
      "2021-07-22 00:39:55,797 - mmaction - INFO - Saving checkpoint at 40 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 19.6 task/s, elapsed: 6s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 00:40:02,270 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-07-22 00:40:02,271 - mmaction - INFO - \n",
      "top1_acc\t0.8220\n",
      "top5_acc\t1.0000\n",
      "2021-07-22 00:40:02,271 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-07-22 00:40:02,272 - mmaction - INFO - \n",
      "mean_acc\t0.7920\n",
      "2021-07-22 00:40:02,588 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_40.pth.\n",
      "2021-07-22 00:40:02,589 - mmaction - INFO - Best top1_acc is 0.8220 at 40 epoch.\n",
      "2021-07-22 00:40:02,590 - mmaction - INFO - Epoch(val) [40][30]\ttop1_acc: 0.8220, top5_acc: 1.0000, mean_class_accuracy: 0.7920\n",
      "2021-07-22 00:41:14,210 - mmaction - INFO - Epoch [41][100/237]\tlr: 1.250e-05, eta: 0:22:28, time: 0.716, data_time: 0.029, memory: 11051, top1_acc: 0.8375, top5_acc: 0.9975, loss_cls: 0.4445, loss: 0.4445, grad_norm: 34.0161\n",
      "2021-07-22 00:42:22,909 - mmaction - INFO - Epoch [41][200/237]\tlr: 1.250e-05, eta: 0:21:31, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.8775, top5_acc: 1.0000, loss_cls: 0.3147, loss: 0.3147, grad_norm: 29.0035\n",
      "2021-07-22 00:43:59,780 - mmaction - INFO - Epoch [42][100/237]\tlr: 1.250e-05, eta: 0:20:07, time: 0.716, data_time: 0.032, memory: 11051, top1_acc: 0.8550, top5_acc: 1.0000, loss_cls: 0.4157, loss: 0.4157, grad_norm: 35.9832\n",
      "2021-07-22 00:45:08,457 - mmaction - INFO - Epoch [42][200/237]\tlr: 1.250e-05, eta: 0:19:09, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.8450, top5_acc: 0.9925, loss_cls: 0.4213, loss: 0.4213, grad_norm: 32.6398\n",
      "2021-07-22 00:46:45,265 - mmaction - INFO - Epoch [43][100/237]\tlr: 1.250e-05, eta: 0:17:46, time: 0.716, data_time: 0.031, memory: 11051, top1_acc: 0.8275, top5_acc: 0.9975, loss_cls: 0.4393, loss: 0.4393, grad_norm: 39.4379\n",
      "2021-07-22 00:47:53,995 - mmaction - INFO - Epoch [43][200/237]\tlr: 1.250e-05, eta: 0:16:48, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.8650, top5_acc: 0.9975, loss_cls: 0.3601, loss: 0.3601, grad_norm: 29.3267\n",
      "2021-07-22 00:49:30,825 - mmaction - INFO - Epoch [44][100/237]\tlr: 1.250e-05, eta: 0:15:25, time: 0.716, data_time: 0.030, memory: 11051, top1_acc: 0.8350, top5_acc: 1.0000, loss_cls: 0.4207, loss: 0.4207, grad_norm: 36.8876\n",
      "2021-07-22 00:50:39,489 - mmaction - INFO - Epoch [44][200/237]\tlr: 1.250e-05, eta: 0:14:27, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.8225, top5_acc: 0.9950, loss_cls: 0.4808, loss: 0.4808, grad_norm: 33.3859\n",
      "2021-07-22 00:52:16,347 - mmaction - INFO - Epoch [45][100/237]\tlr: 1.250e-05, eta: 0:13:05, time: 0.717, data_time: 0.030, memory: 11051, top1_acc: 0.8675, top5_acc: 0.9950, loss_cls: 0.4052, loss: 0.4052, grad_norm: 35.3830\n",
      "2021-07-22 00:53:25,001 - mmaction - INFO - Epoch [45][200/237]\tlr: 1.250e-05, eta: 0:12:06, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.8575, top5_acc: 0.9975, loss_cls: 0.3713, loss: 0.3713, grad_norm: 31.8305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 20.1 task/s, elapsed: 6s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 00:53:56,143 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-07-22 00:53:56,145 - mmaction - INFO - \n",
      "top1_acc\t0.8136\n",
      "top5_acc\t1.0000\n",
      "2021-07-22 00:53:56,145 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-07-22 00:53:56,147 - mmaction - INFO - \n",
      "mean_acc\t0.8011\n",
      "2021-07-22 00:53:56,147 - mmaction - INFO - Epoch(val) [45][30]\ttop1_acc: 0.8136, top5_acc: 1.0000, mean_class_accuracy: 0.8011\n",
      "2021-07-22 00:55:07,701 - mmaction - INFO - Epoch [46][100/237]\tlr: 1.250e-05, eta: 0:10:44, time: 0.715, data_time: 0.029, memory: 11051, top1_acc: 0.8350, top5_acc: 1.0000, loss_cls: 0.4263, loss: 0.4263, grad_norm: 37.4217\n",
      "2021-07-22 00:56:16,377 - mmaction - INFO - Epoch [46][200/237]\tlr: 1.250e-05, eta: 0:09:45, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.8625, top5_acc: 1.0000, loss_cls: 0.3677, loss: 0.3677, grad_norm: 35.2459\n",
      "2021-07-22 00:57:53,042 - mmaction - INFO - Epoch [47][100/237]\tlr: 1.250e-05, eta: 0:08:23, time: 0.715, data_time: 0.030, memory: 11051, top1_acc: 0.8475, top5_acc: 0.9975, loss_cls: 0.3780, loss: 0.3780, grad_norm: 35.3920\n",
      "2021-07-22 00:59:01,659 - mmaction - INFO - Epoch [47][200/237]\tlr: 1.250e-05, eta: 0:07:24, time: 0.686, data_time: 0.000, memory: 11051, top1_acc: 0.8625, top5_acc: 0.9950, loss_cls: 0.4091, loss: 0.4091, grad_norm: 39.1088\n",
      "2021-07-22 01:00:38,543 - mmaction - INFO - Epoch [48][100/237]\tlr: 1.250e-05, eta: 0:06:02, time: 0.716, data_time: 0.030, memory: 11051, top1_acc: 0.8850, top5_acc: 0.9950, loss_cls: 0.3605, loss: 0.3605, grad_norm: 35.9703\n",
      "2021-07-22 01:01:47,247 - mmaction - INFO - Epoch [48][200/237]\tlr: 1.250e-05, eta: 0:05:03, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.8775, top5_acc: 0.9975, loss_cls: 0.3323, loss: 0.3323, grad_norm: 31.4444\n",
      "2021-07-22 01:03:23,938 - mmaction - INFO - Epoch [49][100/237]\tlr: 1.250e-06, eta: 0:03:42, time: 0.716, data_time: 0.029, memory: 11051, top1_acc: 0.8325, top5_acc: 0.9975, loss_cls: 0.4552, loss: 0.4552, grad_norm: 37.7999\n",
      "2021-07-22 01:04:32,642 - mmaction - INFO - Epoch [49][200/237]\tlr: 1.250e-06, eta: 0:02:42, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.8475, top5_acc: 0.9975, loss_cls: 0.3890, loss: 0.3890, grad_norm: 41.0210\n",
      "2021-07-22 01:06:09,387 - mmaction - INFO - Epoch [50][100/237]\tlr: 1.250e-06, eta: 0:01:21, time: 0.716, data_time: 0.031, memory: 11051, top1_acc: 0.8625, top5_acc: 1.0000, loss_cls: 0.3948, loss: 0.3948, grad_norm: 35.1510\n",
      "2021-07-22 01:07:18,135 - mmaction - INFO - Epoch [50][200/237]\tlr: 1.250e-06, eta: 0:00:21, time: 0.687, data_time: 0.000, memory: 11051, top1_acc: 0.8675, top5_acc: 1.0000, loss_cls: 0.3518, loss: 0.3518, grad_norm: 38.9234\n",
      "2021-07-22 01:07:43,332 - mmaction - INFO - Saving checkpoint at 50 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 118/118, 20.5 task/s, elapsed: 6s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 01:07:49,476 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-07-22 01:07:49,478 - mmaction - INFO - \n",
      "top1_acc\t0.8136\n",
      "top5_acc\t1.0000\n",
      "2021-07-22 01:07:49,479 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-07-22 01:07:49,481 - mmaction - INFO - \n",
      "mean_acc\t0.7959\n",
      "2021-07-22 01:07:49,482 - mmaction - INFO - Epoch(val) [50][30]\ttop1_acc: 0.8136, top5_acc: 1.0000, mean_class_accuracy: 0.7959\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "# CUDA_LAUNCH_BLOCKING=1\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22260f21-82bd-4137-96e2-fb3cee5ff83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model50e_ig65m\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "570b3a4c-bb8d-41eb-808e-25f8febec0cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 09:29:01,780 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r152_ig65m_20200807-771c4135.pth\n",
      "2021-07-22 09:29:01,781 - mmaction - INFO - Use load_from_http loader\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "import pickle\n",
    "import mmcv\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "model = pickle.load(open(f\"{cfg.work_dir}/model50e_ig65m\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "321181a3-e9b3-4218-bf74-af029f81546e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 119/119, 0.7 task/s, elapsed: 163s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.8403\n",
      "top5_acc\t1.0000\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.7495\n",
      "top1_acc: 0.8403\n",
      "top5_acc: 1.0000\n",
      "mean_class_accuracy: 0.7495\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "# from mmaction.models import build_model\n",
    "# from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=1,\n",
    "        workers_per_gpu=2,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "822a20f3-d5d5-45e9-b947-47298f9df391",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "# cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0, as_cmap=True)\n",
    "# /np.sum(cf_mat), fmt='.2%',\n",
    "sns.heatmap(cf_mat, cmap=cmap, annot=True, xticklabels = ['6yo', '7yo', '8yo', '9yo', '10yo', '11yo'], yticklabels = ['6yo', '7yo', '8yo', '9yo', '10yo', '11yo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fad81aee-59ff-4d1c-a357-d27f94aaa538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.226890756302521\n"
     ]
    }
   ],
   "source": [
    "mean_error = (2+4+4+4+3+2+4+1+1+2)/119 #number of all tested videos\n",
    "print(mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc0acd80-bedf-4a0b-b583-d87ac5a6b06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n"
     ]
    }
   ],
   "source": [
    "mean_error = (2+4+4+4+3+2+4+1+1+2)/18 #number of all false classifications\n",
    "print(mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9193e30a-3997-4788-bb2b-ebb0d5401d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  1.  0.  0.  1.  0.]\n",
      " [ 1. 21.  4.  2.  0.  0.]\n",
      " [ 0.  0. 42.  3.  0.  0.]\n",
      " [ 0.  0.  1. 23.  1.  0.]\n",
      " [ 0.  0.  2.  1.  8.  0.]\n",
      " [ 0.  0.  0.  1.  1.  4.]]\n"
     ]
    }
   ],
   "source": [
    "print(cf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8592d54f-9f38-49aa-9a0c-d077292bf92e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0, as_cmap=True)\n",
    "# /np.sum(cf_mat), fmt='.2%',\n",
    "sns.heatmap(cf_mat/np.sum(cf_mat), fmt='.1%', cmap=cmap, annot=True, xticklabels = ['6yo', '7yo', '8yo', '9yo', '10yo', '11yo'], yticklabels = ['6yo', '7yo', '8yo', '9yo', '10yo', '11yo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0abd50b-9cb2-4825-ad6f-de1279db7deb",
   "metadata": {},
   "source": [
    "# CSN age BOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad7c6ac4-d3c0-48d0-accc-682cbf4fe1f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64CW6d_AaT-Q",
    "outputId": "3b284fd8-4ee7-4a34-90d7-5023cd123a04",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-07-21 17:39:20--  https://download.openmmlab.com/mmaction/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.75.20.25\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.75.20.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 119580180 (114M) [application/octet-stream]\n",
      "Saving to: ‘checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth’\n",
      "\n",
      "checkpoints/ircsn_i 100%[===================>] 114,04M  6,78MB/s    in 17s     \n",
      "\n",
      "2021-07-21 17:39:39 (6,87 MB/s) - ‘checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth’ saved [119580180/119580180]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth \\\n",
    "      -O checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be2dac68-e118-449a-8fc8-57e873746542",
   "metadata": {
    "id": "LjCcmCKOjktc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('mmaction2/configs/recognition/csn/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d3bdcf8-fe03-48b2-b6e8-e21585fa57cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tlhu9byjjt-K",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "13d1bb01-f351-48c0-9efb-0bdf2c125d29",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='ResNet3dCSN',\n",
      "        pretrained2d=False,\n",
      "        pretrained=\n",
      "        'https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r152_ig65m_20200807-771c4135.pth',\n",
      "        depth=152,\n",
      "        with_pool2=False,\n",
      "        bottleneck_mode='ir',\n",
      "        norm_eval=True,\n",
      "        zero_init_residual=False,\n",
      "        bn_frozen=True),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        num_classes=6,\n",
      "        in_channels=2048,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5,\n",
      "        init_std=0.01),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(average_clips='prob'))\n",
      "checkpoint_config = dict(interval=20)\n",
      "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'RawframeDataset'\n",
      "data_root = 'age-gender-3split-rgb-frames/'\n",
      "data_root_val = 'age-gender-3split-rgb-frames/val/'\n",
      "ann_file_train = 'age-gender-3split-rgb-frames/childact_train_rgb320_age_box.txt'\n",
      "ann_file_val = 'age-gender-3split-rgb-frames/childact_val_rgb320_age_box.txt'\n",
      "ann_file_test = 'age-gender-3split-rgb-frames/childact_test_rgb320_age_box.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=10,\n",
      "        test_mode=True),\n",
      "    dict(type='RawFrameDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='ThreeCrop', crop_size=256),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=4,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file=\n",
      "        'age-gender-3split-rgb-frames/childact_train_rgb320_age_box.txt',\n",
      "        data_prefix='age-gender-3split-rgb-frames/train/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ],\n",
      "        filename_tmpl='{:03}.jpeg'),\n",
      "    val=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file='age-gender-3split-rgb-frames/childact_val_rgb320_age_box.txt',\n",
      "        data_prefix='age-gender-3split-rgb-frames/val/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        filename_tmpl='{:03}.jpeg'),\n",
      "    test=dict(\n",
      "        type='RawframeDataset',\n",
      "        ann_file=\n",
      "        'age-gender-3split-rgb-frames/childact_test_rgb320_age_box.txt',\n",
      "        data_prefix='age-gender-3split-rgb-frames/test/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=10,\n",
      "                test_mode=True),\n",
      "            dict(type='RawFrameDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='ThreeCrop', crop_size=256),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ],\n",
      "        filename_tmpl='{:03}.jpeg'))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "optimizer = dict(type='SGD', lr=0.000125, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    step=[32, 48],\n",
      "    warmup='linear',\n",
      "    warmup_ratio=0.1,\n",
      "    warmup_by_epoch=True,\n",
      "    warmup_iters=16)\n",
      "total_epochs = 50\n",
      "work_dir = './childact-checkpoints/CSN-age-box'\n",
      "find_unused_parameters = True\n",
      "omnisource = False\n",
      "seed = 42\n",
      "gpu_ids = range(0, 1)\n",
      "output_config = dict(out='./childact-checkpoints/CSN-age-box/results.json')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmcv.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "# cfg.dataset_type = 'VideoDataset'\n",
    "cfg.data_root = 'age-gender-3split-rgb-frames/'\n",
    "cfg.data_root_val = 'age-gender-3split-rgb-frames/val/'\n",
    "cfg.ann_file_train = 'age-gender-3split-rgb-frames/childact_train_rgb320_age_box.txt'\n",
    "cfg.ann_file_val = 'age-gender-3split-rgb-frames/childact_val_rgb320_age_box.txt'\n",
    "cfg.ann_file_test = 'age-gender-3split-rgb-frames/childact_test_rgb320_age_box.txt'\n",
    "\n",
    "# cfg.data.test.type = 'VideoDataset'\n",
    "cfg.data.test.ann_file = 'age-gender-3split-rgb-frames/childact_test_rgb320_age_box.txt'\n",
    "cfg.data.test.data_prefix = 'age-gender-3split-rgb-frames/test/'\n",
    "\n",
    "# cfg.data.train.type = 'VideoDataset'\n",
    "cfg.data.train.ann_file = 'age-gender-3split-rgb-frames/childact_train_rgb320_age_box.txt'\n",
    "cfg.data.train.data_prefix = 'age-gender-3split-rgb-frames/train/'\n",
    "\n",
    "# cfg.data.val.type = 'VideoDataset'\n",
    "cfg.data.val.ann_file = 'age-gender-3split-rgb-frames/childact_val_rgb320_age_box.txt'\n",
    "cfg.data.val.data_prefix = 'age-gender-3split-rgb-frames/val/'\n",
    "\n",
    "# cfg.data.test.modality = 'Flow'\n",
    "# cfg.data.val.modality = 'Flow'\n",
    "# cfg.data.train.modality = 'Flow'\n",
    "\n",
    "# cfg.data.train.start_index = 0\n",
    "# cfg.data.test.start_index = 0\n",
    "# cfg.data.val.start_index = 0\n",
    "\n",
    "cfg.data.test.filename_tmpl = '{:03}.jpeg'\n",
    "cfg.data.train.filename_tmpl = '{:03}.jpeg'\n",
    "cfg.data.val.filename_tmpl = '{:03}.jpeg'\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 6\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = 'checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth'\n",
    "# cfg.resume_from = './childact-mm/latest.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './childact-checkpoints/CSN-age-box'\n",
    "\n",
    "cfg.total_epochs = 50\n",
    "\n",
    "# cfg.momentum_config = dict(\n",
    "#     policy='cyclic',\n",
    "#     target_ratio=(0.85 / 0.95, 1),\n",
    "#     cyclic_times=1,\n",
    "#     step_ratio_up=0.4,\n",
    "# )\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 20\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 42\n",
    "set_random_seed(42, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "cfg.data.videos_per_gpu=4\n",
    "\n",
    "# cfg.model.backbone.in_channels = 2\n",
    "\n",
    "cfg.output_config = dict(out=f'{cfg.work_dir}/results.json')\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "# del cfg.optimizer['momentum']\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eea5200-f323-4690-a363-b301cfa2d9bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDBWkdDRk6oz",
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-10 08:19:33,116 - mmaction - INFO - load model from: https://download.openmmlab.com/mmaction/recognition/csn/ircsn_from_scratch_r152_ig65m_20200807-771c4135.pth\n",
      "2021-08-10 08:19:33,117 - mmaction - INFO - Use load_from_http loader\n",
      "2021-08-10 08:19:35,230 - mmaction - INFO - load checkpoint from checkpoints/ircsn_ig65m_pretrained_bnfrozen_r152_32x2x1_58e_kinetics400_rgb_20200812-9037a758.pth\n",
      "2021-08-10 08:19:35,231 - mmaction - INFO - Use load_from_local loader\n",
      "2021-08-10 08:19:35,407 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([6, 2048]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([6]).\n",
      "2021-08-10 08:19:35,411 - mmaction - INFO - Start running, host: robt427nv@robt427NV, work_dir: /home/robt427nv/childact/childact-checkpoints/CSN-age-box\n",
      "2021-08-10 08:19:35,412 - mmaction - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) EvalHook                           \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) EvalHook                           \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2021-08-10 08:19:35,413 - mmaction - INFO - workflow: [('train', 1)], max: 50 epochs\n",
      "/home/robt427nv/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmcv/runner/hooks/evaluation.py:190: UserWarning: runner.meta is None. Creating an empty one.\n",
      "  warnings.warn('runner.meta is None. Creating an empty one.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 11/11, 9.7 task/s, elapsed: 1s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-10 08:21:45,103 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-08-10 08:21:45,105 - mmaction - INFO - \n",
      "top1_acc\t0.2727\n",
      "top5_acc\t1.0000\n",
      "2021-08-10 08:21:45,105 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-08-10 08:21:45,107 - mmaction - INFO - \n",
      "mean_acc\t0.2500\n",
      "2021-08-10 08:21:45,432 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
      "2021-08-10 08:21:45,433 - mmaction - INFO - Best top1_acc is 0.2727 at 5 epoch.\n",
      "2021-08-10 08:21:45,433 - mmaction - INFO - Epoch(val) [5][3]\ttop1_acc: 0.2727, top5_acc: 1.0000, mean_class_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 11/11, 9.0 task/s, elapsed: 1s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-10 08:23:56,335 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-08-10 08:23:56,337 - mmaction - INFO - \n",
      "top1_acc\t0.1818\n",
      "top5_acc\t1.0000\n",
      "2021-08-10 08:23:56,337 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-08-10 08:23:56,338 - mmaction - INFO - \n",
      "mean_acc\t0.1667\n",
      "2021-08-10 08:23:56,338 - mmaction - INFO - Epoch(val) [10][3]\ttop1_acc: 0.1818, top5_acc: 1.0000, mean_class_accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 11/11, 9.7 task/s, elapsed: 1s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-10 08:26:01,773 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-08-10 08:26:01,775 - mmaction - INFO - \n",
      "top1_acc\t0.2727\n",
      "top5_acc\t1.0000\n",
      "2021-08-10 08:26:01,775 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-08-10 08:26:01,777 - mmaction - INFO - \n",
      "mean_acc\t0.2500\n",
      "2021-08-10 08:26:01,777 - mmaction - INFO - Epoch(val) [15][3]\ttop1_acc: 0.2727, top5_acc: 1.0000, mean_class_accuracy: 0.2500\n",
      "2021-08-10 08:28:08,388 - mmaction - INFO - Saving checkpoint at 20 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 11/11, 9.5 task/s, elapsed: 1s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-10 08:28:09,906 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-08-10 08:28:09,907 - mmaction - INFO - \n",
      "top1_acc\t0.1818\n",
      "top5_acc\t1.0000\n",
      "2021-08-10 08:28:09,908 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-08-10 08:28:09,909 - mmaction - INFO - \n",
      "mean_acc\t0.1333\n",
      "2021-08-10 08:28:09,909 - mmaction - INFO - Epoch(val) [20][3]\ttop1_acc: 0.1818, top5_acc: 1.0000, mean_class_accuracy: 0.1333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 11/11, 9.1 task/s, elapsed: 1s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-10 08:30:15,204 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-08-10 08:30:15,206 - mmaction - INFO - \n",
      "top1_acc\t0.2727\n",
      "top5_acc\t1.0000\n",
      "2021-08-10 08:30:15,207 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-08-10 08:30:15,208 - mmaction - INFO - \n",
      "mean_acc\t0.1833\n",
      "2021-08-10 08:30:15,209 - mmaction - INFO - Epoch(val) [25][3]\ttop1_acc: 0.2727, top5_acc: 1.0000, mean_class_accuracy: 0.1833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 11/11, 9.6 task/s, elapsed: 1s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-10 08:32:21,612 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-08-10 08:32:21,614 - mmaction - INFO - \n",
      "top1_acc\t0.3636\n",
      "top5_acc\t1.0000\n",
      "2021-08-10 08:32:21,615 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-08-10 08:32:21,617 - mmaction - INFO - \n",
      "mean_acc\t0.3125\n",
      "2021-08-10 08:32:21,940 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_30.pth.\n",
      "2021-08-10 08:32:21,941 - mmaction - INFO - Best top1_acc is 0.3636 at 30 epoch.\n",
      "2021-08-10 08:32:21,942 - mmaction - INFO - Epoch(val) [30][3]\ttop1_acc: 0.3636, top5_acc: 1.0000, mean_class_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 11/11, 9.6 task/s, elapsed: 1s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-10 08:34:28,553 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-08-10 08:34:28,554 - mmaction - INFO - \n",
      "top1_acc\t0.2727\n",
      "top5_acc\t1.0000\n",
      "2021-08-10 08:34:28,555 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-08-10 08:34:28,555 - mmaction - INFO - \n",
      "mean_acc\t0.1833\n",
      "2021-08-10 08:34:28,556 - mmaction - INFO - Epoch(val) [35][3]\ttop1_acc: 0.2727, top5_acc: 1.0000, mean_class_accuracy: 0.1833\n",
      "2021-08-10 08:36:37,867 - mmaction - INFO - Saving checkpoint at 40 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 11/11, 9.3 task/s, elapsed: 1s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-10 08:36:39,421 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-08-10 08:36:39,423 - mmaction - INFO - \n",
      "top1_acc\t0.2727\n",
      "top5_acc\t1.0000\n",
      "2021-08-10 08:36:39,423 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-08-10 08:36:39,424 - mmaction - INFO - \n",
      "mean_acc\t0.1833\n",
      "2021-08-10 08:36:39,426 - mmaction - INFO - Epoch(val) [40][3]\ttop1_acc: 0.2727, top5_acc: 1.0000, mean_class_accuracy: 0.1833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 11/11, 9.1 task/s, elapsed: 1s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-10 08:38:50,814 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-08-10 08:38:50,816 - mmaction - INFO - \n",
      "top1_acc\t0.2727\n",
      "top5_acc\t1.0000\n",
      "2021-08-10 08:38:50,817 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-08-10 08:38:50,819 - mmaction - INFO - \n",
      "mean_acc\t0.1833\n",
      "2021-08-10 08:38:50,820 - mmaction - INFO - Epoch(val) [45][3]\ttop1_acc: 0.2727, top5_acc: 1.0000, mean_class_accuracy: 0.1833\n",
      "2021-08-10 08:41:01,028 - mmaction - INFO - Saving checkpoint at 50 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 11/11, 9.5 task/s, elapsed: 1s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-10 08:41:02,547 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2021-08-10 08:41:02,549 - mmaction - INFO - \n",
      "top1_acc\t0.1818\n",
      "top5_acc\t1.0000\n",
      "2021-08-10 08:41:02,550 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2021-08-10 08:41:02,553 - mmaction - INFO - \n",
      "mean_acc\t0.1333\n",
      "2021-08-10 08:41:02,554 - mmaction - INFO - Epoch(val) [50][3]\ttop1_acc: 0.1818, top5_acc: 1.0000, mean_class_accuracy: 0.1333\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# model = build_detector(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "# CUDA_LAUNCH_BLOCKING=1\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8a30974-7783-4e06-9c26-2010b8bb6919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"{cfg.work_dir}/model50e\", 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238b2637-eafb-4c0d-86d7-4587e4652585",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 0.4 task/s, elapsed: 18s, ETA:     0s\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t0.0000\n",
      "top5_acc\t0.8750\n",
      "\n",
      "Evaluating mean_class_accuracy ...\n",
      "\n",
      "mean_acc\t0.0000\n",
      "top1_acc: 0.0000\n",
      "top5_acc: 0.8750\n",
      "mean_class_accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "# from mmaction.models import build_model\n",
    "# from mmaction.datasets import build_dataset\n",
    "\n",
    "# model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=1,\n",
    "        workers_per_gpu=2,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "    \n",
    "output_config = cfg.output_config\n",
    "dataset.dump_results(outputs, **output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65e13ddb-894e-4059-873a-960b34ac7a88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAEACAYAAADsjY5UAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbmklEQVR4nO3dfZQddZ3n8fcnpMUJRBjgEpOgEAWCczQgJDwEUAmgJsGHZYdBNkFEJcphIOyOURE4ezhzdsb4SAZG3AghmYSgAhOH9Yzy1CAPSiQoxIQEiTFqSEcuiGKWWQ3d3/2jqqE7k+6u27duV93i8zqnTm7dW7fr80sl3/796lERgZmZNW9U0QHMzKrCBdXMLCcuqGZmOXFBNTPLiQuqmVlOXFDNzHIyuugAZmZlJWkL8EegG3gpIqYOtrwLqpnZ4E6JiGezLOghv5lZTlxQzcwGFsCdkh6VNG+ohVs+5O/q2t7217auXbuu6AhNmzLlrUVHeNUbP/71RUdoB2r6B0iN1JxPAH0L5eKIWNxn/qSIeFrSgcBdkjZGxP0D/TDvQzWzSpGy1+Senp7FwOKBPo+Ip9M/n5G0CjgWGLCgeshvZpUiKfM0xM/ZS9LY3tfAu4FBh6vuoZpZpTTSQx3COGBV+vNGAysj4vuDfcEF1cwqJa+CGhGbgSMb+Y4LqplVSo491Ia5oJpZpbigmpnlZNSo4o61u6CaWaUU2UP1aVNmZjlxD9XMKsX7UM3MciJ5H6qZWS58UMrMLCce8puZ5cQFdZhWr17NtddeQ3d3D7Nnz2bOnDlFR2rITTctZ/36dYwdO5bLLrui6DjD0u7bAKrRBnuFT5sahu7ubhYtupqFC7/AsmXL6Oy8hy1bthQdqyHHHXc8F154UdExhq0K26AKbbD+8rrb1HC0bUHduHEDEydOZMKECXR0dDBjxgweeujBomM15NBDD2PMmL2KjjFsVdgGVWiD9Vf6giqpQ9Ilkm5Np4sldeSepgH1+rPUage+PF+r1ajXMz1Hy3JShW1QhTZYf0UW1Kz7UK8DOoCvpfPnpu99PPdEZmZNaId9qNMi4ryI6Eyn84FpAy0saZ6kNZLWrFixPJ+ku6jVDqBef+bl+Xq9Tq12QEvWZbtXhW1QhTZYf6Uf8gPdkt7cJ/CbgO6BFo6IxRExNSKmzp17brMZd2vy5CPYunUrXV1d7Ny5k87OTqZPP7El67Ldq8I2qEIbrL92GPIvAO6VtJnkqYQHA+fnnqYBo0ePZv78S1mw4FP09PQwc+YsJk2aVGSkhi1duoRNm55ix44dXHnl5cyaNZsTTphedKzMqrANqtAG66/IIb8isj1xVdKewOR09smI+FOW7/kx0uXgx0gXz4+RzqTpajh+/ITMNaera1uu1TdTD1XSo8ANwM0R8XyeAczM8lTktfxZ13w2MBF4RNI3Jb1HRfarzcwGUPqDUhGxKSIuBw4HVgJLgF9JukrSfrmnMjMbptIX1DTkFOArwBeB24CzgBeAztxTmZm1oUb2of4euB74dET8Of1otSSfY2JmpVHaE/slHSfpdSS90fcBbwFuk7RQ0j4AEXFm62OamWUzatSozFPu6x7i8yXAixGxGbgaeB2wEHgRuDH3NGZmTSrzif2jIuKl9PXUiDg6ff2gpMdyT2Nm1qTSDvmBdZJ6r4h6XNJUAEmHAztbmszMbBjKfJT/48A7Jf0C+CvgR+nlp9/Ad5oysxIq7ZA/Iv4AfCQ9MDUpXX5rRPw29yRmZjko/WOkI+IF4PEWZzEza1qR+1Db+iF9Zma7ckE1M8uJC6qZWU5cUEuuCvcSnTBhfNERmrJtW1fREaxNuKCameUk74IqaQ9gDfB0RJwx2LIuqGZWKS24Rn8+sIHk0vvB1533ms3MipTnif2SDgJmk9xpb0guqGZWKY0UVPV55H06zdvlx10NfBroybJuD/nN7FUrIhYDi3f3maQzgGci4lFJ78ry81xQzaxScjwodSLwfkmzgNcCr5O0IiLmDvQFD/nNrFLyusF0RFwWEQdFxCHAh4DOwYopuIdqZhXj81DNzHLSioIaEfcB9w21nAuqmVWKe6hmZjlxQTUzy4kLqplZTlrxeOjM6y5szWZmFeMeqplViof8w7R69WquvfYaurt7mD17NnPmzCk6UsOq0IZf/vKX/PGPf6S7u5uXXnqJadOmFR2pIVXYBvYKF9Rh6O7uZtGiq/nSl75MrVbjk5/8BCeeeCKHHHJI0dEyq0Ibep1yyik899xzRcdoWJW2gSWKLKhtuw9148YNTJw4kQkTJtDR0cGMGTN46KEHi47VkCq0od15G1RPXpeeDmvdWRaS1CHpEkm3ptPFkjpyT9OAev1ZarUDX56v1WrU688WmKhxVWgDQERw5513smbNGi644IKi4zSkKtvAXpHn/VAblbVEXwccA3wtnY5O39utvvcYXLFiefMprdROOukkjjnmGGbOnMlFF13EySefXHQkexUrsqBm3Yc6LSKO7DPfKenxgRbue4/Brq7t0US+AdVqB1CvP/PyfL1ep1Y7oBWrapkqtAFg27ZtQJJ/1apVHHvssTzwwAMFp8qmKtvAXtEO+1C7Jb25d0bSm4Du1kTKZvLkI9i6dStdXV3s3LmTzs5Opk8/schIDatCG8aMGcPee+/98ut3v/vdrFu3ruBU2VVhG1h/7dBDXQDcK2kzIOBg4Pzc0zRg9OjRzJ9/KQsWfIqenh5mzpzFpEmTiozUsCq0Ydy4caxatQpI2rNy5UruuOOOglNlV4VtYOWhiGwjckl7ApPT2Scj4k9ZvteqIb81ZsKE8UVHaMq2bV1FR2ja+PGvLzpCO2i623jaae/OXHPuvvvOXLupmXqokh4FbgBujojn8wxgZpandtiHejYwEXhE0jclvUdFpjYzG0DpT5uKiE0RcTlwOLASWAL8StJVkvbLPZWZ2TBJozJPecv8EyVNAb4MfBG4DTgLeAHozD2Vmdkwlf4of7oP9fck+1E/2+eA1GpJPsfEzEqjtDdHkXQJsAo4KyI2726ZiDizFcHMzIajzDeY/ntgNbBM0oWSaiOQycysLQ1VUDcDB5EU1qnAE5K+L+k8SWNbns7MrEFlPsofEdETEXdGxMeACSQ3R3kvSbE1MyuVMh+U6rfGiNgJ3A7cLmlM7mnMzJpU2oNSJCf071ZEvJhzFjOzphV5UGrQghoRPx+pIGZmeShzD9XMrK24oJqZ5cQF1cwsJy6oJbd2bfvcgX4gVbifqFkWLqhmZjlxQTUzy4kLqplZTlxQzcxykldBlfRa4H5gT5JaeWtE/M/BvuOCamaVkmMP9U/AjIjYIakDeFDS9yLi4YG+4IJqZpWSV0GN5JHQO9LZjnQa9ImqLqhmVil5XssvaQ/gUeBQ4J8jYvWg685tzWZmJdDI7fskzZO0ps80r+/PiojuiDiK5L7Qx0p662Drdg/VzF61ImIxsDjDcr+XdC/JvaAHvNLHPVQzq5S8bjAtqSZp3/T1XwCnAxsH+457qGZWKTke5R9P8jy9PUg6n9+OiO8O9gUXVDOrlLwOSkXEWuDtjXzHBdXMKsVXSpmZ5cQFdZhWr17NtddeQ3d3D7Nnz2bOnDlFR2rITTctZ/36dYwdO5bLLrui6DjD0u7bAKrRBntFkQW1bY/yd3d3s2jR1Sxc+AWWLVtGZ+c9bNmypehYDTnuuOO58MKLio4xbFXYBlVog/VX5GOk27agbty4gYkTJzJhwgQ6OjqYMWMGDz30YNGxGnLooYcxZsxeRccYtipsgyq0wfpri4Iq6f2SvpRO78s9SYPq9Wep1Q58eb5Wq1GvP1tgolefKmyDKrTB+iuyoGbahyrpH4FjgZvSty6RdEJEfC73RGZmTWiHfaizgdMjYklELCG5/OqMgRbue33sihXL88j5n9RqB1CvP/PyfL1ep1Y7oCXrst2rwjaoQhusv7YY8gP79nm9z2ALRsTiiJgaEVPnzj13WMGGMnnyEWzdupWuri527txJZ2cn06ef2JJ12e5VYRtUoQ3WX+mH/MA/Aj9Nbw4g4B3AZ3NP04DRo0czf/6lLFjwKXp6epg5cxaTJk0qMlLDli5dwqZNT7Fjxw6uvPJyZs2azQknTC86VmZV2AZVaIP1V+SQX8k9VDMsKI0HpqWzP46I7Vm+19W1PdsKSqwKj5GeMmXQu47ZCBg//vVFR2gHTVfDiy++NHPNueaaq3OtvlkPSt0G3AB8NyJ68gxgZpanPG8w3fC6My53HTAHeErS5yVNbmEmM7NhK/1BqYi4OyLmAEcDW4C7Jf1Q0vnpw6vMzEqh9AU1Dbk/8BHg48BPgUUkBfau3FOZmbWhrPtQVwGTgeXAGX0OSH1L0ppWhTMza1RpT+yX9BpJHyZ52t9fAb8GrpB0Ue9QPyKmjkBOM7NMRo0alXnK21A91BvTZcZIOg/YC1gFnEpyKep5uScyM2tCme+H+raImCJpNPA0MCEiuiWtAB5vfTwzs8aUuaCOkvQakp7pGJJLTn8H7An46L6ZlU6ZC+oNJI9N3QO4HLhF0mbgeOCbLc5mZtaw0hbUiPiqpG+lr7dJ+hfgNOAbEfHjkQhoZtaI0hZUSAppn9e/B25tZSAzs2aUuqCambUTF1Qzs5y4oJqZ5cQFteSqcC/Rdr+naxW2gY0MF1Qzs5wUeT9UF1QzqxT3UM3McuKCamaWExdUM7OclPZ+qGZmlp17qGZWKT7Kb2aWEw/5zcxyktdTTyW9QdK9kp6QtF7S/KHW7R6qmVVKjj3Ul4C/i4ifSBoLPCrproh4YqAvuKCaWaXkVVAjogvoSl//UdIGYCIwYEH1kN/MKqWRIb+keZLW9JnmDfAzDwHeDqwebN3uoZpZpTRylD8iFgOLB1tG0t7AbcClEfHCoOvOvGYzs1cZSR0kxfSmiPjXoZZ3D9XMKiWvfahKftANwIaI+EqW77R1QV29ejXXXnsN3d09zJ49mzlz5hQdqWHt3oabblrO+vXrGDt2LJdddkXRcYal3beB9ZfjUf4TgXOBn0l6LH3vcxHx7wN9oW2H/N3d3SxadDULF36BZcuW0dl5D1u2bCk6VkOq0IbjjjueCy+8qOgYw1aFbWD95XUeakQ8GBGKiCkRcVQ6DVhMoY0L6saNG5g4cSITJkygo6ODGTNm8NBDDxYdqyFVaMOhhx7GmDF7FR1j2KqwDay/UaNGZZ5yX3eWhSR1SLpE0q3pdHG6s7Yw9fqz1GoHvjxfq9Wo158tMFHjqtCGdudtUD159VCHI2uJvg44BvhaOh2dvrdbfc/tWrFiefMpzcwyKrKgZj0oNS0ijuwz3ynp8YEW7ntuV1fX9mgi34BqtQOo1595eb5er1OrHdCKVbVMFdrQ7rwNqqcdbo7SLenNvTOS3gR0tyZSNpMnH8HWrVvp6upi586ddHZ2Mn36iUVGalgV2tDuvA2qpx16qAuAeyVtBgQcDJyfe5oGjB49mvnzL2XBgk/R09PDzJmzmDRpUpGRGlaFNixduoRNm55ix44dXHnl5cyaNZsTTphedKzMqrANrDwUkW1ELmlPYHI6+2RE/CnL91o15LfGrF27rugITZky5a1FR2ja+PGvLzpCO2i62/j1r38jc8355CcvyLWbmqmHKulRkisGbo6I5/MMYGaWp3bYh3o2yW2rHpH0TUnvUZGpzcwGUPrTpiJiU0RcDhwOrASWAL+SdJWk/XJPZWY2TKUvqGnIKcBXgC+S3H3lLOAFoDP3VGZmw1T6o/zpPtTfA9cDn+lzQGq1JJ9jYmalUeTeyCELanrO6beAg4BpwD6SVvbeaDUizmxtRDOz7Ip8jPSga5Z0CfB14DXAVGBP4A3Aw5Le1epwZmaNKvOQ/wLgqIjolvQV4N8j4l2S/jfwbyTPWDEzM7LtQx1NcpnpnsDeABHx66LvNmVmtjtl3od6Pcm5p6uBk4GFAJJqwO9anM3MrGGlLagRsUjS3cBbgC9HxMb0/TrwjhHIZ2bWkCIPSg055I+I9cD6EchiZta00vZQzczajQuqmVlOXFDNzHJS6YLqe0CWg7eDvVpUuqCamY0kF1Qzs5y4oJqZ5cQF1cwsJy6oZmY5cUE1M8uJC6qZWU5KfS2/mVk7aYfHSJuZ2RDcQzWzSvE+VDOznHjIb2aWk1GjRmWehiJpiaRnJK3LtO6m05uZlUjOTz1dCrw367o95DezSslzyB8R90s6JOvyLqhmVineh2pmlpNGhvyS5kla02ea18y63UM1s0pppIMaEYuBxXmt2wXVzCrFQ34zs5zkeZRf0s3Aj4DJkrZK+thgy2cqqJIOkrRKUj09J+s2SQcNsvzL+yUWL86tN21mNqQ8C2pEnBMR4yOiIyIOiogbBls+65D/RmAlcFY6Pzd97/QBQvTdLxEZ12Fm1rR2GPLXIuLGiHgpnZYCtRbmMjMblpxP7G9I1oL6nKS5kvZIp7nAc7mnMTNrUjsU1I8CfwNsB7qAvwbOzz2NmVmT8ryWv1FZ96HuiIj35752M7OctcM+1Icl3SJppopMa2Y2hHYY8h9OctT+w8BTkv5B0uG5pzEza2OZCmok7oqIc4ALgPOAH0v6gaQTWprQzKwBRfZQM+1DlbQ/ybmn5wK/BS4GbgeOAm4BJuWezMxsGNrhqac/ApYDH4yIrX3eXyPp6/nHMjMbniIP82QtqJMjYrdXPEXEwhzzmJk1pbRH+SXtI+nzwBOSfifpOUkbJH1e0r4jE9HMLLsyH+X/NvA8cEpE7BcR+wOnpO99O/c0ZmZNKnNBPSQiFkbE9t43ImJ7Osw/OPc0ZmZNKnNB/ZWkT0sa1yfsOEmfAX6TexozsyYVeenpUD/xbGB/4AfpPtTfAfcB+/HKrfzMzIwhjvJHxPPAZ9KpH0nnk9wT1cysNEp7lH8IV+WWwswsJ6W9UkrS2oE+AsYN8JmZWWHKfGL/OOA9JKdJ9SXghy1JZGbWhDJfevpdYO+IeGzXDyTd14pAZmbNKG0PNSIGfGRqRPy3/OOYmTWntAXVzKzduKCameWkXU+bMjOzPtxDNbNKKfNRfjOztuJ9qGZmOXFBNTPLSZEPundBNbNKcQ/VzCwnLqhmZjkp8ii/z0M1M8uJe6hmVike8puZ5cSXnpqZ5STPO/ZLeq+kJyVtkvTZoZZ3D9XMKiWvg1KS9gD+GTgd2Ao8Iun2iHhiwHU3uIK9Je3dXEwzs9bJsYd6LLApIjZHxJ+BbwIfGOwLmXqokt4G/AvJ46MlqQ6cFxHrBlh+HjAvnf1ERCzOsp7hkjSv1etopXbPD25DGbR7fsinDePHvz7zTtRdahXA4j7rnwj8ps9nW4HjBv15EZFlpT8ELo+Ie9P5dwH/EBHTswZvJUlrImJq0TmGq93zg9tQBu2eH8rVBkl/Dbw3Ij6ezp8LHBcRfzvQd7IO+ffqLaYAEXEfsFcTWc3Myu5p4A195g9K3xtQ1oK6WdKVkg5JpyuAzcMMaWbWDh4BDpM0SdJrgA8Btw/2hawF9aNADfhX4DbggPS9smjr/Ua0f35wG8qg3fNDidoQES8BfwvcAWwAvh0R6wf7TtZ9qG+LiJ/lktLMrKKyFtQHgD2BG4GVEfGHVgczM2s3mYb8EXEyMBd4I/CopJWSTm9pMjOzNpP5xP6I+DlwBfAZ4J3AP0naKOnMVoXrJWlfSbem69sg6YRWrzNPkiZLeqzP9IKkS4vO1ShJ/13SeknrJN0s6bVFZ2qEpPlp9vXt8vcvaYmkZySt6/PefpLukvRU+udfFplxKAO04ax0O/RIKsVpUnnIVFAlTZH0VZIdszOA90XEW9LXX21hvl6LgO9HxBHAkWmOthERT0bEURFxFHAM8CKwqthUjZE0EbgEmBoRbwX2IDnq2RYkvRW4gOTqlyOBMyQdWmyqTJYC793lvc8C90TEYcA96XyZLeU/t2EdcCZw/4inaaGsPdRrgJ8AR0bERRHxE4CI2EbSa20ZSfsA7wBuSNf5Z2B/ST/ps8xhvfOSTpX0U0k/S38z7tnKfMNwKvALYHQbtmE08BeSRgNjgG2SvtP7oaTTJa1KX5+T5l8naWExcft5C7A6Il5Mj97+APivZd8GEXE/8Ltd3v4AsCx9vQz4oKRRaY+1BpDOb5JUS0917JS0VtI9kt44gk3YbRsiYkNEPLnrspLul3RUn/kHJR2Z9sq/k7bhYUlTWp+8cVn3ob4zIpZHxH/s5rPl+cfqZxJQB25M/4FfD2wH/tDnL/789PPXkvw2PDsi3kZSAC5scb5GfQi4OSJ+QRu1ISKeBr4E/BroAv4A3AUc0fufmKQNSyRNABaSjGCOAqZJ+uBIZ97FOuBkSftLGgPMIjlRu222QR/jIqIrfb09ne8BVgBz0vdPAx6PiDpJh2hZREwBbgL+aaQDN+AG4CMAkg4HXhsRjwNXAT9N2/A5kkvhS2fYt2WR9L08gwxiNHA0cF1EvB34vyRDnOuB85XcEeZsYCUwGfhlur8Xkt/e7xihnENKTw5+P3BL+lbbtCHdT/cBkl9wE0iulJsDLAfmStoXOAH4HjANuC8i6mlv8CYKbkNEbCAp8ncC3wceA7ppo22wO5GcptN7qs4S4MPp64+SnJUDyXZZmb5eDpw0YgEbdwvJ7pgOkjYsTd8/iSQ7EdFJMkp9XSEJBzFoQZV09ADTMSQ9j5GwFdgaEavT+VtJCuxtwEzgDODRiHhuhPI0Yybwk4j4bTrfTm04jaTI1CNiJ8lFHtNJ/tPOBc4BbkkLaClFxA0RcUxEvAN4Hvg57bUNev1W0niA9M9nACLiN+lnM0j2FY9Upyc3EfEiycjnA8DfkPwybhtD3W3qEZJ9Tbu7e8u+uafZjYjYLuk3kian+1xOBZ6IiP8n6Q7gOuBj6eJPAodIOjQiNgHnkuQvi3OAm3tn2qwNvwaOT4fL/0GyHdZExDZJvfvST0uX/THJWSAHkBSuc0iGnYWSdGBEPJPuQzwTOL7NtkGv24HzgM+nf/5bn8+uJxn6L4+I7vS9H5LsalpOMqp4YOSiDsv1wP8BHoiI59P3HiDJ/vdKbs70bES8UEy8QUTEgBPJfqfDBvjsN4N9N8+JpDe8BlgLfAf4y/T940l6sHv0WfZU4KfAz0iGQHuOVM4h2rAX8Bywzy7vt1MbrgI2pv8ulvfmIvnP+vAuy56T5l8HLCw6e5rpAeAJ4HHg1HbYBiS/gLuAnWnGjwH7kxzdfwq4G9ivz/IdwAvAEX3eOxjoTP//3AO8sQRt+C/p6z8BvwXu2OU7G0nu9NQ7v1/6f38t8DAwpeh/T7ubBr1SSsntq34Wuz8a98GI+M6AXx4Bkj5FUqCuLDJHMyrShmtJDhjcUHSW4ajCNuiVntP51UguxmlL6UHN+0h+KfQUHKchgw75I+LWQT4u9GTi9PScN5McSW5LFWnDoyQHCv+u6CzDUYVt0EvJM48u5JUj/W1H0oeB/wX8j3YrppDxWv7dflH6dUSM6PlsZmZlNmgPVdLagT4CxuUfx8ysfQ11lH8c8B6SI7V9ieTIoZmZpYYqqN8F9o6Ix3b9QNJ9rQhkZtauhr0P1czM+hv2padmZtafC6qZWU5cUM3McuKCamaWExdUM7Oc/H9w7ajD7beIswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from mmaction.core import confusion_matrix \n",
    "\n",
    "gt_labels = [ann['label'] for ann in dataset.load_annotations()]\n",
    "pred = np.argmax(outputs, axis=1)\n",
    "cf_mat = confusion_matrix(pred, gt_labels).astype(float)\n",
    "cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0, as_cmap=True)\n",
    "# /np.sum(cf_mat), fmt='.2%',\n",
    "sns.heatmap(cf_mat, cmap=cmap, annot=True, xticklabels = ['6yo', '7yo', '8yo', '9yo', '10yo', '11yo'], yticklabels = ['6yo', '7yo', '8yo', '9yo', '10yo', '11yo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb55bc95-346e-4e2b-8a99-0d823104a28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.226890756302521\n"
     ]
    }
   ],
   "source": [
    "mean_error = (2+4+4+4+3+2+4+1+1+2)/119 #number of all tested videos\n",
    "print(mean_error)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7ff2a6c-01ae-4f3f-8e98-3f8dbf02e761",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e11aaf-1799-4d50-9138-c5f882fb4d98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
